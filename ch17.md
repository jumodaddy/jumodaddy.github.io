<?xml version="1.0" encoding="UTF-8" standalone="no"?>

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="chapter" title="17. fejezet - Komplex döntések meghozatala"><div class="titlepage"><div><div><h1 class="title"><a id="id711004"/>17. fejezet - Komplex döntések meghozatala</h1></div></div></div><p><span class="emphasis"><em>Ebben a fejezetben olyan módszereket vizsgálunk meg, amelyekkel eldönthetjük, hogy mit tegyünk a mai napon, feltételezve, hogy holnap is lehetőségünk lesz a cselekvésre.</em></span></p><p>Ebben a fejezetben a döntéshozatalhoz kapcsolódó számítási kérdéseket tárgyaljuk meg. Míg a 16. fejezetben egyszeri vagy epizodikus döntési problémákkal foglalkoztunk, ahol az egyes cselekvések kimeneteleinek a hasznossága jól ismert volt, a 17. fejezetben <span class="strong"><strong>szekvenciális döntési problémá</strong></span>kkal (<span class="strong"><strong>sequential decision problem</strong></span>s) fogunk foglalkozni, ahol az ágens hasznossága a döntések sorozatától függ. A szekvenciális döntési problémák, amelyek hasznosságot, bizonytalanságot és érzékelést is magukban foglalnak, a keresés és tervezés problémáját általánosítják, melyeket a II., illetve a IV. részben<span class="emphasis"><em> </em></span>írtunk le. A 17.1. alfejezet kifejti, hogyan definiálhatunk szekvenciális döntési problémákat, a 17.2. és a 17.3. alfejezet elmagyarázza ezek megoldását, hogy optimális viselkedést eredményezzenek, amely kiegyensúlyozza a bizonytalan környezetben meghozott cselekvések kockázatát és jutalmát. A 17.4. alfejezet kiterjeszti ezeket az ötleteket a részlegesen megfigyelhető környezetekre, és a 17.5. alfejezet egy teljes tervezési módot fejleszt ki részlegesen megfigyelhető környezetben lévő döntéselméleti ágensek tervezésére, összekapcsolva a dinamikus Bayes-hálókat a 15. fejezetből a 16. fejezetbeli döntési hálókkal.</p><p>A fejezet második része többágenses környezeteket tárgyal. Ilyen környezetekben az optimális viselkedés fogalma sokkal bonyolultabbá válik az ágensek közötti interakció miatt. A 17.6. alfejezet ismerteti a <span class="strong"><strong>játékelmélet</strong></span> (<span class="strong"><strong>game theory</strong></span>) alapötleteit, ideértve azt az elképzelést is, hogy egy racionális ágensnek lehet, hogy véletlenszerűen kell viselkednie. A 17.7. alfejezet azt vizsgálja meg, hogyan tervezhetők olyan többágenses rendszerek, amelyekben az ágensek egy közös célt tudnak megvalósítani.</p><div class="section" title="Szekvenciális döntési problémák"><div class="titlepage"><div><div><h1 class="title"><a id="id711040"/>Szekvenciális döntési problémák</h1></div></div></div><div class="section" title="Egy példa"><div class="titlepage"><div><div><h2 class="title"><a id="id711044"/>Egy példa</h2></div></div></div><p>Tételezzük fel, hogy egy ágens a 17.1. (a) ábrán látható 4 × 3-as környezetben helyezkedik el. A kezdő állapotból indulva minden időpontban választania kell egy cselekvést. A környezettel való interakció leáll, ha az ágens eléri a +1-gyel vagy a –1-gyel jelölt állapotot. Az egyes helyzetekben az elérhető cselekvések nevei: <span class="emphasis"><em>Fel</em></span>,<span class="emphasis"><em> Le</em></span>,<span class="emphasis"><em> Balra</em></span>, <span class="emphasis"><em>Jobbra</em></span>. Egyelőre feltételezzük, hogy a környezet <span class="strong"><strong>teljesen megfigyelhető</strong></span> (<span class="strong"><strong>fully observable</strong></span>), azaz az ágens mindig ismeri a helyzetét.</p><div class="figure"><a id="id711074"/><p class="title"><strong>17.1. ábra - (a) Egy egyszerű 4 × 3-as környezet, ami az ágens számára szekvenciális döntési probléma. (b) A környezet állapotátmenet-modelljének illusztrálása: a „szándékolt” kimenetel 0,8 valószínűséggel következik be, de 0,2 valószínűséggel az ágens oldalra mozdul a szándékolt irányhoz képest. A fallal való ütközéskor nincsen mozgás. A két végállapot jutalma a jelzett +1 és –1, az összes többi állapot jutalma –0,04.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/17-01.png" alt="(a) Egy egyszerű 4 × 3-as környezet, ami az ágens számára szekvenciális döntési probléma. (b) A környezet állapotátmenet-modelljének illusztrálása: a „szándékolt” kimenetel 0,8 valószínűséggel következik be, de 0,2 valószínűséggel az ágens oldalra mozdul a szándékolt irányhoz képest. A fallal való ütközéskor nincsen mozgás. A két végállapot jutalma a jelzett +1 és –1, az összes többi állapot jutalma –0,04."/></div></div></div><p class="Tartalom3">Ha a probléma determinisztikus volna, a megoldás könnyű lenne: [<span class="emphasis"><em>Fel</em></span>, <span class="emphasis"><em>Fel, Jobbra</em></span>, <span class="emphasis"><em>Jobbra</em></span>, <span class="emphasis"><em>Jobbra</em></span>]. Sajnos a környezet nem maradna mindig szinkronban ezzel a megoldással, mivel a cselekvések megbízhatatlanok. A véletlenszerű mozgás egy általunk elfogadott modelljét a 17.1. (b)<span class="emphasis"><em> </em></span>ábra mutatja be. Minden cselekvés 0,8 valószínűséggel éri el a kívánt hatását, de a maradék esetben a cselekvések az ágenst a kívánt iránytól jobbra mozgatják. Továbbá, ha az ágens falba ütközik, akkor ugyanazon a mezőn marad. Például ha az (1, 1) kezdő négyzeten áll, a <span class="emphasis"><em>Fel</em></span> cselekvés az ágenst az (1, 2)-re mozgatja 0,8 valószínűséggel, de 0,1 valószínűséggel a (2, 1)-re kerül, és 0,1 valószínűséggel balra megy, ahol is falnak ütközik és (1, 1)-en marad. Egy ilyen környezetben a [<span class="emphasis"><em>Fel</em></span>, <span class="emphasis"><em>Fel</em></span>,<span class="emphasis"><em> Jobbra</em></span>, <span class="emphasis"><em>Jobbra</em></span>, <span class="emphasis"><em>Jobbra</em></span>] sorozat 0,8<sup>5</sup> = 0,32768 valószínűséggel kerüli meg az akadályokat, és éri el a (4, 3) célállapotot. Igen kis eséllyel az is megtörténhet, hogy a célt a másik úton keresztül éri el, 0,1<sup>4</sup> × 0,8, ami összességében 0,32776 valószínűséget jelent (lásd 17.1. feladat).</p><p class="Tartalom3">Az egyes állapotokban végrehajtott egyes akcióknak a kimeneti valószínűségeit <span class="strong"><strong>állapotátmenet-modell</strong></span>nek (<span class="strong"><strong>transition model</strong></span>) nevezzük, (vagy csak „modell”-nek, ha nem értelemzavaró). A <span class="emphasis"><em>T</em></span>(<span class="emphasis"><em>s</em></span>,<span class="emphasis"><em> a</em></span>, <span class="emphasis"><em>s</em></span>′<span class="emphasis"><em>)</em></span> jelölést fogjuk használni annak a valószínűségnek a jelölésére, hogy az <span class="emphasis"><em>s </em></span>állapotban az <span class="emphasis"><em>a</em></span> cselekvés végrehajtása <span class="emphasis"><em>s</em></span>′<span class="emphasis"><em> </em></span>állapotot eredményez. Feltesszük, hogy az átmenetek teljesítik a 15. fejezetben megfogalmazott <span class="strong"><strong>Markov-tulajdonság</strong></span>ot, azaz, hogy <span class="emphasis"><em>s</em></span>′ elérése <span class="emphasis"><em>s</em></span>-ből csak <span class="emphasis"><em>s</em></span>-től függ, más korábbi állapotoktól már nem. Egyelőre a <span class="emphasis"><em>T</em></span>(<span class="emphasis"><em>s</em></span>,<span class="emphasis"><em> a</em></span>,<span class="emphasis"><em> s</em></span>′)<span class="emphasis"><em>-</em></span>t<span class="emphasis"><em> </em></span>tekinthetjük a<span class="emphasis"><em> </em></span>valószínűségek egy<span class="emphasis"><em> </em></span>nagy háromdimenziós táblázatának. Később, a 17.5. alfejezetben látni fogjuk, hogy az állapotátmenet-modell reprezentálható <span class="strong"><strong>dinamikus Bayes-háló</strong></span>kkal (<span class="strong"><strong>dynamic Bayesian network</strong></span>), csakúgy mint a 15. fejezetben.</p><p class="Tartalom3">Hogy teljessé tegyük a feladat környezetének a definiálását, meg kell adnunk az ágens hasznosságfüggvényét. Mivel a döntési probléma szekvenciális, a hasznosságfüggvény az állapotok sorozatától – a <span class="strong"><strong>környezeti történet</strong></span>től (<span class="strong"><strong>environment history</strong></span>) –  fog függni, nem pedig egyetlen állapottól. A fejezetben később megvizsgáljuk az ilyen hasznosságfüggvények általános megadását; egyelőre egyszerűen kikötjük, hogy az ágens minden <span class="emphasis"><em>s</em></span> állapotban egy <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) <span class="strong"><strong>jutalmat</strong></span> (<span class="strong"><strong>reward</strong></span>) kap, ami lehet pozitív vagy negatív, de mindenképpen korlátos. A konkrét példánkban a jutalom minden állapotban –0,04, kivéve a végállapotokat (ahol +1 vagy –1). Egy környezeti történet hasznossága (egyelőre) egyszerűen a kapott jutalmak <span class="emphasis"><em>összege</em></span>. Például ha az ágens a +1 állapotot 10 lépés után éri el, akkor az összhasznossága 0,6 lesz. A –0,04 negatív jutalom arra ösztönzi az ágenst, hogy minél gyorsabban érje el a (4, 3)-at, így ez a probléma a 3. fejezetbeli keresési problémák egy sztochasztikus általánosítása. Ez más megfogalmazásban úgy hangzik, hogy az ágens nem élvezi az életet ebben a környezetben, és olyan gyorsan ki akar kerülni, amilyen gyorsan csak lehet.</p><p class="Tartalom3">Egy teljesen megfigyelhető környezetben megadott szekvenciális döntési problémát Markov-állapotátmenet-modelljével és additív jutalmakkal <span class="strong"><strong>Markov döntési folyamat</strong></span>nak neveznek (<span class="strong"><strong>MDF</strong></span>) (<span class="strong"><strong>Markov decision process</strong></span>). Egy MDF-et a következő három összetevő határoz meg:</p><p>Kezdőállapot: <span class="emphasis"><em>S</em></span><sub>0</sub></p><p>Állapotátmenet-modell: <span class="emphasis"><em>T</em></span>(<span class="emphasis"><em>s</em></span>,<span class="emphasis"><em> a</em></span>,<span class="emphasis"><em> s</em></span>′)</p><p>Jutalomfüggvény:<sup>[<a id="id711315" href="#ftn.id711315" class="footnote">171</a>]</sup> <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>)</p><p>A következő kérdés az, hogyan néz ki egy megoldás a problémára? Azt már láttuk, hogy egy rögzített cselekvéssorozat nem oldja meg a problémát, mivel az ágens végül más állapotba jut a célállapot helyett. Ezért egy megoldásnak minden, az ágens által elérhető állapotra elő kell írnia, hogy az ágens mit tegyen. Egy ilyenfajta megoldás az <span class="strong"><strong>eljárásmód</strong></span> (<span class="strong"><strong>policy</strong></span>). Egy eljárásmódot általában π-vel jelölünk, és a π eljárásmód az <span class="emphasis"><em>s</em></span> állapotban a π (<span class="emphasis"><em>s</em></span>) cselekvést javasolja. Ha az ágens egy teljes eljárásmóddal rendelkezik, akkor függetlenül attól, hogy egy cselekvésnek mi is a kimenetele, az ágens mindig tudni fogja, mit tegyen a következő alkalommal.</p><p>Egy adott eljárásmód kezdőállapotból induló végrehajtása minden alkalommal egy különböző környezeti történetet eredményez a környezet sztochasztikus volta miatt. Egy eljárásmód minőségét ezért az adott eljárásmód generálta lehetséges környezeti történetek várható hasznosságával mérik. Az <span class="strong"><strong>optimális eljárásmód</strong></span> (<span class="strong"><strong>optimal policy</strong></span>) az az eljárásmód, ami a legnagyobb várható hasznosságot eredményezi. Az optimális eljárásmódot π<sup> *</sup>-gal jelöljük. A π<sup> *</sup> ismeretében az ágens úgy dönti el, hogy mit tegyen, hogy figyelembe veszi az aktuális érzékelését, ami az aktuális <span class="emphasis"><em>s</em></span> állapotot közli vele, majd végrehajtja a π<sup>*</sup>(<span class="emphasis"><em>s</em></span>) cselekvést. Az eljárásmód az ágens függvényét explicit módon reprezentálja, és ezért az voltaképpen egy egyszerű reflexágens leírása, amit egy hasznosságalapú ágens által használt információkból számítunk ki.</p><p>A 17.1. ábrán mutatott világ optimális eljárását a 17.2. (a) ábra mutatja. Látható, hogy mivel egy lépés költsége meglehetősen kicsi ahhoz a büntetéshez viszonyítva, hogy véletlenül a (4, 2) pozícióra kerülünk, az optimális eljárásmód a (3, 1) állapot esetén óvatos. Inkább egy hosszú kerülő út megtételét javasolja, mint a rövid átvágást a (4, 2) kockáztatásával.</p><p>A kockázat és a jutalom egyensúlyának megváltozása függ az <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) értékétől a nem végső állapotoknál. A 17.2. (b) ábrán az <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) értékének négy különböző intervallumához tartozó optimális eljárásmódot találhatunk. Ha <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) ≤ –1,6284, akkor az élet anynyira elviselhetetlen, hogy az ágens egyenesen a legközelebbi kijárathoz tart, annak ellenére, hogy ez –1 értékű. Amikor –0,4278 ≤<span class="emphasis"><em> R</em></span>(<span class="emphasis"><em>s</em></span>) ≤ –0,0850, az élet elég kellemetlen; az ágens a +1 állapothoz vezető utat választja, vállalva annak kockázatát, hogy esetleg a –1 állapotba kerül. Nevezetesen az ágens a (3, 1)-ben választja az átvágást. Amikor az élet csak kevéssé bánatos (–0,0221 &lt; <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) &lt; 0), az optimális eljárásmód nem vállal <span class="emphasis"><em>semmilyen kockázatot</em></span>. A (4, 1) és (3, 2) állapotokban az ágens teljesen elkerüli a –1 állapotot, így nem tud véletlenül beleesni, még ha ez azt is jelenti, hogy elég sokszor beveri a fejét a falba. Végül, ha <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) &gt; 0, akkor az élet kifejezetten élvezhető, és az ágens <span class="emphasis"><em>mindkét</em></span> kijáratot elkerüli. Mindaddig, amíg a (4, 1), (3, 2) és (3, 3) állapotokban a cselekvések azok, amelyek az ábrán láthatók, minden eljárásmód optimális, és az ágens végtelen teljes jutalmat ér el, mivel soha nem lép be a végállapotba. Meglepő módon megmutatható, hogy hat más optimális eljárásmód is létezik az <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) különböző intervallumaira. A 17.7. feladat kéri majd ezek megkeresését.</p><div class="figure"><a id="id711458"/><p class="title"><strong>17.2. ábra - (a) Egy optimális eljárásmód a sztochasztikus környezetre <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) = –0,04 esetén nem végállapotoknál. (b) Optimális eljárásmódok <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>) négy különböző értéktartománya esetén.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/17-02.png" alt="(a) Egy optimális eljárásmód a sztochasztikus környezetre R(s) = –0,04 esetén nem végállapotoknál. (b) Optimális eljárásmódok R(s) négy különböző értéktartománya esetén."/></div></div></div><p>A kockázat és a jutalom óvatos egyensúlyozása az MDF-ek egy olyan meghatározó tulajdonsága, ami nem jelentkezik determinisztikus keresési problémáknál; másfelől ez meghatározó tulajdonsága számos valósvilág-beli döntési problémának. Emiatt az MDF-eket számos tudományterületen tanulmányozzák, ideértve az MI-t, az operációkutatást, a közgazdaságtant és a szabályozáselméletet. Algoritmusok tucatjait javasolták optimális eljárásmódok kiszámítására. A 17.2. és 17.3. alfejezetben leírunk a legfontosabb algoritmuscsaládok közül kettőt. Először azonban be kell fejeznünk a hasznosságok és eljárásmódok vizsgálatát a szekvenciális döntési problémák esetében.</p></div><div class="section" title="Optimalitás szekvenciális döntési problémákban"><div class="titlepage"><div><div><h2 class="title"><a id="id711484"/>Optimalitás szekvenciális döntési problémákban</h2></div></div></div><p>A 17.1. ábrán látható MDF-példában az ágens teljesítményét a meglátogatott állapotokban kapott jutalmak összege mérte. Ez a teljesítménymérték nem önkényes, de nem is az egyetlen lehetőség. Ez az alfejezet a lehetséges alternatív teljesítménymértékeket vizsgálja – azaz alternatív hasznosságfüggvényeket a környezeti történéseken, amit úgy jelölünk, hogy <span class="emphasis"><em>U<sub>h</sub></em></span>([<span class="emphasis"><em>s</em></span><sub>0</sub>, ..., <span class="emphasis"><em>s<sub>n</sub></em></span>]). Az alfejezet a 16. fejezetből származó ötleteken alapul, és a technikai részleteket is bemutatja; a főbb pontokat a végén összegezzük.</p><div class="important" title="Fontos" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Fontos</h3><p>Az első megválaszolandó kérdés az, hogy <span class="strong"><strong>véges horizont</strong></span> (<span class="strong"><strong>finite horizon</strong></span>) vagy <span class="strong"><strong>végtelen horizont</strong></span> (<span class="strong"><strong>infinite horizon</strong></span>) van a döntéshozatalnál. A véges horizont azt jelenti, hogy létezik egy <span class="emphasis"><em>rögzített</em></span> <span class="emphasis"><em>N</em></span> idő, ami után semmi nem érdekes – a játéknak vége, mondhatni. Így <span class="emphasis"><em>U<sub>h</sub></em></span>([<span class="emphasis"><em>s</em></span><sub>0</sub>, ...,<span class="emphasis"><em> s</em></span><sub><span class="emphasis"><em>N</em></span>+<span class="emphasis"><em>k</em></span></sub>]) = <span class="emphasis"><em>U<sub>h</sub></em></span>([<span class="emphasis"><em>s</em></span><sub>0</sub>, ..., <span class="emphasis"><em>s<sub>N</sub></em></span>]) minden <span class="emphasis"><em>k</em></span> &gt; 0 esetén. Például tegyük fel, hogy az ágens (3, 1)-ből indul a 17.1. ábra 4 × 3-as világában, és tegyük fel, hogy <span class="emphasis"><em>N</em></span> = 3. Ekkor, hogy a +1 állapot elérésének legalább az esélye meglegyen, az ágensnek egyenesen felé kell tartani, és az optimális cselekvés a <span class="emphasis"><em>Fel</em></span>. Ezzel szemben, ha <span class="emphasis"><em>N</em></span> = 100, akkor bőségesen van idő a biztonságos utat követni <span class="emphasis"><em>Balra </em></span>menve. Azaz, <span class="emphasis"><em>véges horizont esetében az optimális cselekvés egy adott állapotban idővel változhat</em></span>. Azt mondjuk, hogy az optimális eljárásmód véges horizont esetében <span class="strong"><strong>nem</strong></span><span class="strong"><strong>-</strong></span><span class="strong"><strong> stacionárius</strong></span> (<span class="strong"><strong>nonstationary</strong></span>). Rögzített időkorlát hiányában ezzel szemben nincs ok különböző viselkedésre ugyanabban az állapotban más és más időpontokban. Így az optimális cselekvés csak az aktuális állapottól függ, és az optimális eljárásmód <span class="strong"><strong>stacionárius</strong></span> (<span class="strong"><strong>stationary</strong></span>). A végtelen horizontú esethez tartozó eljárásmódok ezért egyszerűbbek, mint a véges horizontú esethez tartozók, és ebben a fejezetben mi főként a végtelen horizontú esettel foglalkozunk.<sup>[<a id="id711627" href="#ftn.id711627" class="footnote">172</a>]</sup> Vegyük észre, hogy a „végtelen horizont” nem jelenti szükségszerűen azt, hogy az összes állapotsorozat végtelen; mindössze annyit jelent, hogy nincs egy rögzített határ. Nevezetesen, egy végtelen horizontú MDF-ben lehetnek végállapotot tartalmazó véges állapotsorozatok.</p></div><p>A következő eldöntendő kérdés az állapotsorozatok hasznosságának a kiszámítása. Tekinthetjük ezt a kérdést a <span class="strong"><strong>többattribútumú hasznosságelmélet</strong></span> (<span class="strong"><strong>multiattribute utility theory</strong></span>) egy kérdésének (lásd 16.4. alfejezet) azzal, hogy minden <span class="emphasis"><em>s<sub>i</sub></em></span> állapotot az [<span class="emphasis"><em>s</em></span><sub>0</sub>, <span class="emphasis"><em>s</em></span><sub>1</sub>, <span class="emphasis"><em>s</em></span><sub>2</sub>, ...] állapotsorozat egy attribútumának veszünk. Egy egyszerű kifejezés eléréséhez, ami az attribútumokból épül fel, fel kell tételeznünk valamilyen preferenciafüggetlenséget. A legtermészetesebb feltevés az, hogy az ágens preferenciái az állapotsorozatok között <span class="strong"><strong>stacionárius</strong></span>ok (<span class="strong"><strong>stationary</strong></span>). A preferenciákra vonatkozó stacionaritás a következőket jelenti: ha két állapotsorozat, [<span class="emphasis"><em>s</em></span><sub>0</sub>, <span class="emphasis"><em>s</em></span><sub>1</sub>, <span class="emphasis"><em>s</em></span><sub>2</sub>,…] és <span class="inlinemediaobject"><img src="math/mi-17-0001.gif" alt="Optimalitás szekvenciális döntési problémákban"/></span>, ugyanazzal az állapottal kezdődik (például <span class="inlinemediaobject"><img src="math/mi-17-0002.gif" alt="Optimalitás szekvenciális döntési problémákban"/></span>), akkor a két sorozat a preferencia-sorrendjének ugyanannak kell lennie, mint az [<span class="emphasis"><em>s</em></span><sub>1</sub>, <span class="emphasis"><em>s</em></span><sub>2</sub>,…] és az <span class="inlinemediaobject"><img src="math/mi-17-0003.gif" alt="Optimalitás szekvenciális döntési problémákban"/></span> sorozatoknak. Ez tehát azt jelenti, hogy ha egy holnaptól kezdődő lehetséges jövőbeli eseménysort egy másik eseménysorral szemben preferálunk, akkor ez nem változhat, ha az eseménysor a mai naptól kezdődne. A stacionaritás egy meglehetősen ártalmatlannak tűnő feltevés, nagyon erős következményekkel: bizonyítható, hogy stacionaritás esetén a sorozatokhoz csak kétféle módon rendelhetők hasznosságok:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p><span class="strong"><strong>Additív jutalmak</strong></span> (<span class="strong"><strong>additive reward</strong></span>s): egy állapotsorozat hasznossága ekkor</p></li></ol></div><p><code class="code"><em><span class="remark">	U<sub>h</sub></span></em>([<em><span class="remark">s</span></em><sub>0</sub>, <em><span class="remark">s</span></em><sub>1</sub>, <em><span class="remark">s</span></em><sub>2</sub>,...]) = <em><span class="remark">R</span></em>(<em><span class="remark">s</span></em><sub>0</sub>) + <em><span class="remark">R</span></em>(<em><span class="remark">s</span></em><sub>1</sub>) + <em><span class="remark">R</span></em>(<em><span class="remark">s</span></em><sub>2</sub>) + …</code></p><p>	A 17.1. ábra 4 × 3-as világa additív jutalmakat használ. Vegyük észre, hogy az additivitást hallgatólagosan kihasználtuk az utak költségfüggvényeinek felhasználásakor a heurisztikus keresési algoritmusokban (4. fejezet).</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p><span class="strong"><strong>Leszámítolt jutalmak </strong></span>(<span class="strong"><strong>discounted reward</strong></span>s): egy állapotsorozat hasznossága ekkor</p></li></ol></div><p><code class="code"><em><span class="remark">	U<sub>h</sub></span></em>([<em><span class="remark">s</span></em><sub>0</sub>, <em><span class="remark">s</span></em><sub>1</sub>, <em><span class="remark">s</span></em><sub>2</sub>,...]) = <em><span class="remark">R</span></em>(<em><span class="remark">s</span></em><sub>0</sub>) + <em><span class="remark">γR</span></em>(<em><span class="remark">s</span></em><sub>1</sub>) + <em><span class="remark">γ</span></em><sup>2</sup> <em><span class="remark">R</span></em>(<em><span class="remark">s</span></em><sub>2</sub>) + …</code></p><p>	ahol a <span class="emphasis"><em>γ</em></span> <span class="strong"><strong>leszámítolási tényező</strong></span> (<span class="strong"><strong>discount factor</strong></span>) egy 0 és 1 közötti szám. A leszámítolási tényező fejezi ki egy ágens preferenciáját a jelenlegi és a jövőbeli jutalmak között. Amikor <span class="emphasis"><em>γ </em></span>közel 0, akkor a távoli jövőbeli jutalmakat jelentéktelennek tekinti. Amikor <span class="emphasis"><em>γ </em></span>értéke 1, akkor a leszámítolt jutalmak pontosan megegyeznek az additív jutalmakkal, így az additív jutalmak a leszámítolt jutalmak speciális esetei. A leszámítolás jó modellnek tűnik mind az állati, mind az emberi időbeli preferenciákra. Egy <span class="emphasis"><em>γ </em></span>leszámítolási tényező ekvivalens egy (1/<span class="emphasis"><em> γ</em></span>) – 1<span class="emphasis"><em> </em></span>kamatlábbal.</p><p class="Tartalom3">A fejezet hátralevő részében leszámítolt jutalmakat fogunk feltételezni, aminek okai hamarosan világosak lesznek, bár néha megengedjük a <span class="emphasis"><em>γ</em></span> = 1<span class="emphasis"><em> </em></span>értéket.</p><p>A végtelen horizont elfogadása mögött azonban rejlik egy probléma: ha a környezet nem tartalmaz egy végállapotot, vagy ha az ágens soha nem jut végállapotba, akkor az összes környezettörténet végtelen hosszú lesz, és a hasznosságok additív jutalmakkal általában végtelenek lesznek. Abban egyetérthetünk, hogy a +∞ jobb, mint a –∞, de két +∞ hasznosságú állapotsorozat összehasonlítása már bonyolultabb. Három megoldás kínálkozik, amelyek közül kettőt már láttunk:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Leszámítolt jutalmakkal egy végtelen sorozat hasznossága <span class="emphasis"><em>véges.</em></span> Valójában, ha a jutalmakra létezik egy <span class="emphasis"><em>R</em></span><sub>max</sub> korlát és <span class="emphasis"><em>γ</em></span> &lt; 1, akkor azt kapjuk, hogy</p><p><span class="inlinemediaobject"><img src="math/mi-17-0004.gif" alt="Optimalitás szekvenciális döntési problémákban"/></span></p></li></ol></div><p>felhasználva a végtelen mértani sorozat összegképletét.</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Ha a környezet tartalmaz végállapotokat, <span class="emphasis"><em>és ha garantált, hogy az ágens végül bekerül az egyikbe,</em></span> akkor soha nem lesz szükségünk végtelen sorozatok összehasonlítására. Egy eljárásmódot, ami garantáltan végállapotba juttat, <span class="strong"><strong>véges eljárásmód</strong></span>nak (<span class="strong"><strong>proper policy</strong></span>) nevezünk. Véges eljárásmódoknál használhatjuk a <span class="emphasis"><em>γ</em></span> = 1-t (azaz az additív jutalmakat). A 17.2. (b) ábrán látható első három eljárásmód véges, a negyedik azonban nem. Egy nem véges eljárásmód végtelen teljes jutalmat ér el a végállapotoktól való távolmaradással, amikor a nem végállapotok jutalma pozitív. A nem véges eljárásmódokra additív jutalmaknál nem mindig működnek az MDF-eket megoldó alapalgoritmusok, ami jó ok a leszámítolt jutalmak használatára. </p></li><li class="listitem"><p>Végtelen sorozatok összehasonlítására egy másik lehetőség az időegységenkénti <span class="strong"><strong>átlagjutalom</strong></span> (<span class="strong"><strong>average reward</strong></span>) felhasználása. Tegyük fel, hogy a 4 × 3-as világban az (1, 1) mező jutalma 0,1, míg más nem végállapotoké 0,01. Ekkor egy olyan eljárásmódnak, ami minden tőle telhetőt megtesz, hogy az (1, 1)-ben maradjon, nagyobb lesz az átlagos jutalma, mint annak, amelyik máshol marad. Az átlagos jutalom hasznos kritérium bizonyos problémákra, de az átlagjutalomra tervezett algoritmusok meghaladják e könyv kereteit.</p></li></ol></div><p>Összegezve, a leszámítolt jutalmak használata jár a legkevesebb bonyodalommal az állapotsorozatok kiértékelésében. A végső lépés annak megmutatása, hogyan válasszunk az eljárásmódok között, észben tartva azt, hogy egy adott π eljárásmód nem egyetlen állapotsorozatot generál, hanem a legkülönfélébb lehetséges állapotsorozatokat, mindegyiket egy adott valószínűséggel, amit a környezet állapotátmenet-modellje határoz meg. Így egy eljárásmód értéke a (sorozatonként) elért leszámítolt jutalmak <span class="emphasis"><em>várható</em></span> értéke, ahol a várható érték képzése az összes állapotsorozat felett történik, ami az eljárás végrehajtása esetén előfordulhat. Egy π<sup>*</sup> optimális eljárásmód ekkor</p><a id="ID_713_oldal"/><p><span class="inlinemediaobject"><img src="math/mi-17-0005.gif" alt="Optimalitás szekvenciális döntési problémákban"/></span></p><p>A következő két alfejezet algoritmusokat ír le az optimális eljárásmódok megtalálására.</p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id711315" href="#id711315" class="para">171</a>] </sup> Az MDF egyes definíciói megengedik, hogy a jutalom függjön a cselekvéstől és a kimeneteltől is, így a jutalomfüggvény <span class="emphasis"><em>R</em></span>(<span class="emphasis"><em>s</em></span>,<span class="emphasis"><em> a</em></span>,<span class="emphasis"><em> s</em></span>′)<span class="emphasis"><em> </em></span>alakú. Ez néhány környezet leírását egyszerűsíti, de a problémát alapvetően nem változtatja meg.</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id711627" href="#id711627" class="para">172</a>] </sup> Ez a teljesen megfigyelhető környezetekre igaz. Látni fogjuk, hogy a részlegesen megfigyelhető környezetekben a végtelen horizont esete nem annyira egyszerű.</p></div></div></div></body></html>
