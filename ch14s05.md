<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="section" title="Közelítő következtetés Bayes-hálókban"><div class="titlepage"><div><div><h1 class="title"><a id="id681219"/>Közelítő következtetés Bayes-hálókban</h1></div></div></div><p class="Tartalom3">Az egzakt következtetés nagy, többszörösen összekötött hálókban való kezelhetetlensége miatt, elengedhetetlen közelítő következtetési módszerek átgondolása. Ez a fejezet véletlen mintavételi, <span class="strong"><strong>Monte Carlo</strong></span>-módszereknek is nevezett, eljárásokat ír le, amelyek közelítő válaszokat nyújtanak, ahol a pontosság a generált minták számától függ. </p><p>Az utóbbi években a Monte Carlo-algoritmusok széles körben elterjedtek a számítástudományban olyan mennyiségek megbecslésére, amelyeket nehéz egzakt módon kiszámolni. Például a 4. fejezetben leírt szimulált lehűtés algoritmus egy Monte Carlo-eljárás optimalizációs problémákra. Ebben a fejezetben a mintavételezésnek az a posteriori valószínűségek kiszámításában történő alkalmazásában vagyunk érdekeltek. Algoritmusok két nagy családját írjuk le: a közvetlen mintavételezést és a Markov-láncos mintavételezést. Két másik megközelítést – a variációs módszert és a „hurkos” („loopy”) terjesztést – a fejezet végi megjegyzésekben említjük meg.</p><div class="section" title="Közvetlen mintavételezési módszerek"><div class="titlepage"><div><div><h2 class="title"><a id="id681233"/>Közvetlen mintavételezési módszerek</h2></div></div></div><p class="Tartalom3">Az alapelem minden mintavételi algoritmusban a minták generálása egy ismert valószínűség-eloszlásból. Például egy szabályos érme felfogható egy <span class="emphasis"><em>Érme</em></span> valószínűségi változónak 〈<span class="emphasis"><em>fej</em></span>,<span class="emphasis"><em>írás</em></span>〉 értékekkel és <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Érme</em></span>) = 〈0,5, 0,5〉<span class="emphasis"><em> </em></span>a priori eloszlással. A mintavétel ebből az eloszlásból pontosan megfelel egy érme dobálásának: 0,5 valószínűséggel <span class="emphasis"><em>fej</em></span>-et ad, és 0,5 valószínűséggel <span class="emphasis"><em>írás</em></span>-t. Ha rendelkezésre áll a [0, 1] tartományba eső véletlen számoknak egy forrása, akkor bármely egyváltozós eloszlásból egyszerű dolog mintavételezni (lásd 14.9. feladat).</p><p class="Tartalom3">A véletlen mintavételezési folyamat legegyszerűbb fajtája Bayes-hálók esetén a hálóból generál olyan eseményeket, amelyekhez nem kapcsolódik bizonyíték. Az ötlet az, hogy mintavételezzünk minden változót egymás után, topológiai sorrendben. A valószínűség-eloszlás, amiből az értéket mintavételezzük, feltételesen függ a változó szüleihez már hozzárendelt értékektől. Ez az algoritmus látható a 14.12. ábrán. A működését a 14.11. (a) ábrán látható hálón szemléltetjük, feltételezve egy [<span class="emphasis"><em>Felhős</em></span>,<span class="emphasis"><em> Locsoló</em></span>,<span class="emphasis"><em> Eső</em></span>,<span class="emphasis"><em> VizesPázsit</em></span>] sorrendezést:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Sorsoljunk a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Felhős</em></span>) = 〈0,5, 0,5〉 eloszlásból; tegyük fel, hogy <span class="emphasis"><em>igaz</em></span>-at kapunk<span class="emphasis"><em>.</em></span></p></li><li class="listitem"><p>Sorsoljunk a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Locsoló</em></span>∣<span class="emphasis"><em>Felhős</em></span> = <span class="emphasis"><em>igaz</em></span>) = 〈0,1, 0,9〉 eloszlásból; tegyük fel, hogy <span class="emphasis"><em>hamis</em></span>-at kapunk.</p></li><li class="listitem"><p>Sorsoljunk a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Eső</em></span>∣<span class="emphasis"><em>Felhős</em></span> = <span class="emphasis"><em>igaz</em></span>) = 〈0,8, 0,2〉 eloszlásból; tegyük fel, hogy <span class="emphasis"><em>igaz</em></span>-at kapunk.</p></li><li class="listitem"><p>Sorsoljunk a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>VizesPázsit</em></span>∣<span class="emphasis"><em>Locsoló</em></span> = <span class="emphasis"><em>hamis</em></span>, <span class="emphasis"><em>Felhős</em></span> = <span class="emphasis"><em>igaz</em></span>) = 〈0,9, 0,1〉 eloszlásból; tegyük fel, hogy <span class="emphasis"><em>igaz</em></span>-at kapunk.</p></li></ol></div><p>Ebben az esetben a <code class="code">PRIOR-MINTA</code> a következő eseményt adja [<span class="emphasis"><em>igaz</em></span>,<span class="emphasis"><em> hamis</em></span>,<span class="emphasis"><em> igaz</em></span>,<span class="emphasis"><em> igaz</em></span>].</p><p class="Tartalom3">Könnyen látható, hogy a <code class="code">PRIOR-MINTA</code> a háló által meghatározott a priori együttes eloszlásból generál mintákat. Először, legyen <span class="emphasis"><em>S<sub>PS</sub></em></span>(<span class="emphasis"><em>x</em></span><sub>1</sub>, …, <span class="emphasis"><em>x<sub>n</sub></em></span>) annak a valószínűsége, hogy egy adott eseményt legenerál a <code class="code">PRIOR-MINTA</code> algoritmus. <span class="emphasis"><em>Pusztán a mintavételi folyamat alapján</em></span> felírható, hogy</p><p><span class="inlinemediaobject"><img src="math/mi-14-0021.gif" alt="Közvetlen mintavételezési módszerek"/></span></p><p>mivel minden mintavételi lépés a szülő értékektől függ.</p><div class="figure"><a id="id681451"/><p class="title"><strong>14.12. ábra - Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/14-12.png" alt="Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból"/></div></div></div><p>Ez a kifejezés ismerős, mivel – ahogy ezt a (14.1) egyenlet kimondja – ez egyben a valószínűsége is az együttes eloszlás Bayes-hálós reprezentációja szerinti eseménynek is. Arra jutottunk tehát, hogy</p><p class="Tartalom3"><code class="code"><em><span class="remark">S<sub>PS</sub></span></em>(<em><span class="remark">x</span></em><sub>1</sub>…<em><span class="remark">x<sub>n</sub></span></em>) = <em><span class="remark">P</span></em>(<em><span class="remark">x</span></em><sub>1</sub>…<em><span class="remark">x<sub>n</sub></span></em>)</code></p><p>Ez az egyszerű tény nagyon könnyűvé teszi lekérdezések – minták felhasználásával történő – megválaszolását.</p><p>Bármilyen mintavételi algoritmusban a válasz kiszámítása a generálás során előálló minták megszámlálása alapján történik. Tételezzük fel, hogy <span class="emphasis"><em>N</em></span> teljes mintánk van, és jelölje <span class="emphasis"><em>N</em></span>(<span class="emphasis"><em>x</em></span><sub>1</sub>, …, <span class="emphasis"><em>x<sub>n</sub></em></span>) az <span class="emphasis"><em>x</em></span><sub>1</sub>, …, <span class="emphasis"><em>x<sub>n</sub></em></span> esemény gyakoriságát. Azt várjuk, hogy ez a gyakoriság határértékben konvergáljon a várható értékéhez a mintavételi valószínűség szerint:</p><p><span class="inlinemediaobject"><img src="math/mi-14-0022.gif" alt="Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból"/></span></p><p>Például gondoljuk meg az előbb generált eseményt: [<span class="emphasis"><em>igaz</em></span>,<span class="emphasis"><em> hamis</em></span>,<span class="emphasis"><em> igaz</em></span>,<span class="emphasis"><em> igaz</em></span>]. Ennek az eseménynek a mintavételi valószínűsége:</p><p><code class="code"><em><span class="remark">S<sub>PS</sub></span></em>(<em><span class="remark">igaz</span></em>, <em><span class="remark">hamis</span></em>, <em><span class="remark">igaz</span></em>,<em><span class="remark"> igaz</span></em>) = 0,5 × 0,9 × 0,8 × 0,9 = 0,324</code></p><p>Így, <span class="emphasis"><em>N</em></span> nagy értékeinél azt várjuk, hogy a minták 32,4%-a ez az esemény legyen.</p><p>A következőkben, amikor a közelítő egyenlőség jelet („≈”) használjuk, pontosan ilyen értelemben használjuk – azaz a becsült valószínűség egzakttá válik a nagy mintaszámú határesetben. Az ilyen becsléseket <span class="strong"><strong>konzisztens</strong></span>nek (<span class="strong"><strong>consistent</strong></span>) nevezzük. Például bármely részlegesen meghatározott <span class="emphasis"><em>x</em></span><sub>1</sub>,<span class="emphasis"><em> …</em></span>, <span class="emphasis"><em>x<sub>m</sub></em></span> esemény valószínűségének egy konzisztens becslése a következőképpen kapható meg, ha <span class="emphasis"><em>m</em></span> ≤ <span class="emphasis"><em>n</em></span>:</p><p><code class="code"><em><span class="remark">P</span></em>(<em><span class="remark">x</span></em><sub>1</sub>,…, <em><span class="remark">x<sub>m</sub></span></em>) ≈ <em><span class="remark">N<sub>PS</sub></span></em>(<em><span class="remark">x</span></em><sub>1</sub><em><span class="remark">,…</span></em>, <em><span class="remark">x<sub>m</sub></span></em>)/<em><span class="remark">N	</span></em>				(14.5)</code></p><p>Azaz, az esemény valószínűsége megbecsülhető a mintavételi folyamat által generált összes teljes esemény azon hányadával, amelyek illeszkednek a részlegesen meghatározott eseményre. Például ha generálunk 1000 mintát a locsolós hálóból, és 511-ben közülük az <span class="emphasis"><em>Eső</em></span> = <span class="emphasis"><em>igaz</em></span>, akkor az eső becsült valószínűsége <span class="inlinemediaobject"><img src="math/mi-14-0023.gif" alt="Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból"/></span>.</p><p><span class="strong"><strong>Elutasító mintavételezés Bayes-hálókban</strong></span></p><p class="Tartalom3">Az <span class="strong"><strong>elutasító mintavételezés</strong></span> (<span class="strong"><strong>rejection sampling</strong></span>) általános módszer minták előállítására egy nehezen mintavételezhető eloszlásból, felhasználva egy könnyen mintavételezhető eloszlást. Legegyszerűbb formájában feltételes valószínűségek kiszámítására – azaz <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>X</em></span>∣<span class="strong"><strong>e</strong></span>) meghatározására használható fel. Az <code class="code">ELUTASÍTÓ-MINTAVÉTELEZÉS</code> algoritmusa a 14.13. ábrán látható. Először a háló által megadott a priori eloszlásból generál mintákat, majd elutasítja azokat, amelyek nem illeszkednek a bizonyítékhoz. Végül, a <span class="inlinemediaobject"><img src="math/mi-14-0024.gif" alt="Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból"/></span> becslés megkapható az <span class="emphasis"><em>X</em></span> = <span class="emphasis"><em>x</em></span> előfordulásainak megszámlálásával a megmaradt mintában.</p><p>Legyen <span class="inlinemediaobject"><img src="math/mi-14-0025.gif" alt="Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból"/></span> az algoritmus által kiadott becsült eloszlás. Az algoritmus definíciója szerint fennáll, hogy</p><p><span class="inlinemediaobject"><img src="math/mi-14-0026.gif" alt="Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból"/></span></p><p>A 14.5 egyenletből kapjuk, hogy</p><p><span class="inlinemediaobject"><img src="math/mi-14-0027.gif" alt="Egy mintavételező algoritmus, amely eseményeket generál egy Bayes-hálóból"/></span></p><p>Azaz az elutasító mintavétel az igazi valószínűség konzisztens becslését adja.</p><div class="figure"><a id="id681769"/><p class="title"><strong>14.13. ábra - Az elutasító mintavétel algoritmusa, ami Bayes-hálós lekérdezéseket válaszol meg bizonyítékok esetén</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/14-13.png" alt="Az elutasító mintavétel algoritmusa, ami Bayes-hálós lekérdezéseket válaszol meg bizonyítékok esetén"/></div></div></div><p class="Tartalom3">Folytatva a 14.11. (a) ábra szerinti példánkat, tételezzük fel, hogy meg szeretnénk becsülni a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Eső</em></span>∣<span class="emphasis"><em>Locsoló</em></span> = <span class="emphasis"><em>igaz</em></span>)-t, 100 minta felhasználásával. A 100 általunk generált mintából, tegyük fel, hogy 73-ban teljesül, hogy <span class="emphasis"><em>Locsoló</em></span> = <span class="emphasis"><em>hamis</em></span>, és így elutasított, míg 27-ben fennáll, hogy <span class="emphasis"><em>Locsoló</em></span> = <span class="emphasis"><em>igaz</em></span>; a 27-ből 8-ban <span class="emphasis"><em>Eső</em></span> = <span class="emphasis"><em>igaz</em></span>, 19-ben pedig <span class="emphasis"><em>Eső</em></span> = <span class="emphasis"><em>hamis.</em></span> Így a</p><p><code class="code"><em><span class="remark">P</span></em>(<em><span class="remark">Eső</span></em>∣<em><span class="remark">Locsoló</span></em> = <em><span class="remark">igaz</span></em>) ≈ Normalizál(〈8, 19〉) = 〈0,296, 0,704〉</code></p><p>A helyes érték 〈0,3, 0,7〉. A begyűjtött minták szaporodásával a becslés konvergálni fog a helyes értékhez. A becslés szórása az egyes valószínűségeknél arányos lesz <span class="inlinemediaobject"><img src="math/mi-14-0028.gif" alt="Az elutasító mintavétel algoritmusa, ami Bayes-hálós lekérdezéseket válaszol meg bizonyítékok esetén"/></span>-nel, ahol <span class="emphasis"><em>n</em></span> a becsléshez felhasznált minták száma.</p><p>Az elutasító mintavétel legnagyobb hibája, hogy nagyon sok mintát utasít el! Az <span class="strong"><strong>e</strong></span> bizonyítékkal konzisztens minták aránya exponenciálisan egyre kevesebb, ahogy a bizonyítékváltozók száma nő, így az eljárás egyszerűen használhatatlan komplex problémákban.</p><p>Vegyük észre, hogy az elutasító mintavétel nagyon hasonló a feltételes valószínűségek becsléséhez, ha közvetlenül a valódi világból történik a becslés. Például a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>Eső</em></span>∣<span class="emphasis"><em>VörösAzÉgEste </em></span>= <span class="emphasis"><em>igaz</em></span>) becslésénél egyszerűen megszámoljuk, milyen gyakran esik az után, hogy az előző este az ég vörös volt – figyelmen kívül hagyva azokat az estéket, amikor az ég nem volt vörös. (Itt a világ maga játssza a mintageneráló algoritmus szerepét.) Nyilvánvalóan, ha az ég nagyon ritkán vörös, akkor ez hosszú időt vehet igénybe, és ez az, ami az elutasító mintavétel gyengesége.</p><p><span class="strong"><strong>Valószínűségi súlyozás</strong></span></p><p class="Tartalom3">A <span class="strong"><strong>valószínűségi súlyozás</strong></span> (<span class="strong"><strong>likelihood weighting</strong></span>) elkerüli az elutasító mintavételezés gyengeségét azáltal, hogy csak az <span class="strong"><strong>e</strong></span> bizonyítékkal konzisztens eseményeket generál. Az algoritmus működésének a leírásával kezdjük; majd megmutatjuk, hogy helyesen működik – azaz, hogy konzisztens valószínűség becsléseket generál. A <code class="code">VALÓSZÍNŰSÉGI-SÚLYOZÁS</code> (lásd 14.14. ábra) rögzíti az <span class="strong"><strong>E</strong></span> bizonyítékváltozók értékeit, és csak a maradék <span class="emphasis"><em>X</em></span> és <span class="strong"><strong>Y</strong></span> változókat mintavételezi. Ez garantálja, hogy minden generált esemény konzisztens a bizonyítékkal. Azonban nem minden esemény egyenlő. Mielőtt megállapítanánk a számlálási eredményeket a célváltozó eloszlásában, minden eseményt súlyozunk azzal a valószínűséggel, amely megadja, hogy az esemény mennyire van összhangban a bizonyítékkal. Ezt a valószínűséget az egyes bizonyítékváltozók feltételes valószínűségeinek a szorzatával mérjük, a szüleik ismeretében. Szemléletesen, azoknak az eseményeknek, ahol a bizonyíték valószínűtlennek tűnik, kisebb súlyt kell adni.</p><p>Alkalmazzuk az algoritmust a 14.11. (a) ábrán látható háló esetén a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Eső</em></span>∣<span class="emphasis"><em>Locsoló </em></span>= <span class="emphasis"><em>igaz</em></span>, <span class="emphasis"><em>VizesPázsit</em></span> = <span class="emphasis"><em>igaz</em></span>) kérdésre. A folyamat a következőképpen halad: először a <span class="emphasis"><em>w</em></span> súlyt 1,0-ra állítjuk. Aztán generálunk egy eseményt:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Sorsoljunk a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Felhős</em></span>) = 〈0,5, 0,5〉 eloszlásból; tegyük fel, hogy <span class="emphasis"><em>igaz</em></span>-at kapunk<span class="emphasis"><em>.</em></span></p></li><li class="listitem"><p>A <span class="emphasis"><em>Locsoló</em></span> egy bizonyítékváltozó <span class="emphasis"><em>igaz</em></span> értékkel. Ezért beállítjuk, hogy</p></li></ol></div><p class="Tartalom3"><code class="code"><em><span class="remark">w </span></em>← <em><span class="remark">w</span></em> × <em><span class="remark">P</span></em>(<em><span class="remark">Locsoló</span></em> = <em><span class="remark">igaz</span></em>∣<em><span class="remark">Felhős</span></em> = <em><span class="remark">igaz</span></em>) = 0,1</code></p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Sorsoljunk a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Eső</em></span>∣<span class="emphasis"><em>Felhős</em></span> = <span class="emphasis"><em>igaz</em></span>) = 〈0,8, 0,2〉 eloszlásból; tegyük fel, hogy <span class="emphasis"><em>igaz</em></span>-at kapunk<span class="emphasis"><em>.</em></span></p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>A <span class="emphasis"><em>VizesPázsit </em></span>egy<span class="emphasis"><em> </em></span>bizonyítékváltozó<span class="emphasis"><em> igaz </em></span>értékkel. Ezért beállítjuk, hogy</p></li></ol></div></li></ol></div><p class="Tartalom3"><code class="code"><em><span class="remark">	w </span></em>← <em><span class="remark">w</span></em> × <em><span class="remark">P</span></em>(<em><span class="remark">VizesPázsit</span></em> = <em><span class="remark">igaz</span></em>∣<em><span class="remark">Locsoló</span></em> = <em><span class="remark">igaz</span></em>, <em><span class="remark">Eső</span></em> = <em><span class="remark">igaz</span></em>) = 0,099</code></p><p>Itt a <code class="code">SÚLYOZOTT-MINTA</code> az [<span class="emphasis"><em>igaz</em></span>,<span class="emphasis"><em> igaz</em></span>,<span class="emphasis"><em> igaz</em></span>,<span class="emphasis"><em> igaz</em></span>] eseményt adja ki 0,099 súllyal, és ezt az <span class="emphasis"><em>Eső </em></span>= <span class="emphasis"><em>igaz</em></span> esetnél vesszük számításba. A súly alacsony, mivel az esemény egy felhős napot ír le, amikor valószínűtlen, hogy a locsoló be van kapcsolva.</p><p>Hogy megértsük, miért is működik a valószínűségi súlyozás, azzal kezdjük, hogy megvizsgáljuk a <code class="code">SÚLYOZOTT-MINTA</code> <span class="emphasis"><em>S<sub>WS</sub></em></span> mintavételi eloszlását. Emlékezzünk, hogy az <span class="strong"><strong>E</strong></span> bizonyítékváltozók értéke (<span class="strong"><strong>e</strong></span>) rögzített. A többi változót <span class="strong"><strong>Z</strong></span>-vel jelöljük, azaz <span class="strong"><strong>Z</strong></span> = {X} ∪ <span class="strong"><strong>Y</strong></span>. Az algoritmus <span class="strong"><strong>Z</strong></span> minden változóját mintavételezi, szülei adott értékei mellett:</p><p><span class="inlinemediaobject"><img src="math/mi-14-0029.gif" alt="Az elutasító mintavétel algoritmusa, ami Bayes-hálós lekérdezéseket válaszol meg bizonyítékok esetén"/></span></p><p>Vegyük észre, hogy a <span class="emphasis"><em>Szülők</em></span>(<span class="emphasis"><em>Z<sub>i</sub></em></span>) tartalmazhat mind rejtett, mind bizonyítékváltozókat is. A <span class="emphasis"><em>P</em></span>(<span class="strong"><strong>z</strong></span>) a priori eloszlástól eltérően az <span class="emphasis"><em>S<sub>WS</sub></em></span> eloszlás szentel valamennyi figyelmet a bizonyítéknak is: a mintavételezett értékeket minden <span class="emphasis"><em>Z<sub>i</sub></em></span> esetén befolyásolják a <span class="emphasis"><em>Z<sub>i</sub></em></span> ősei között levő bizonyítékok. Másfelől, <span class="emphasis"><em>S<sub>WS</sub></em></span> kevesebb figyelmet szentel a bizonyítékoknak, mint a <span class="emphasis"><em>P</em></span>(<span class="strong"><strong>z</strong></span>∣ <span class="strong"><strong>e</strong></span>) valódi a posteriori eloszlás, mivel a mintavételezett értékek minden <span class="emphasis"><em>Z<sub>i</sub></em></span> esetén <span class="emphasis"><em>figyelmen kívül hagyják</em></span> azokat a bizonyítékokat, amelyek <span class="emphasis"><em>Z<sub>i</sub></em></span>-nek nem ősei.<sup>[<a id="id682250" href="#ftn.id682250" class="footnote">150</a>]</sup></p><p>A <span class="emphasis"><em>w</em></span> valószínűségi súly pótolja ki a különbséget a valódi és a kívánt mintavételi eloszlás között. Egy adott <span class="strong"><strong>z-</strong></span>ből és <span class="strong"><strong>e-</strong></span>ből álló <span class="bold"><strong>x<span class="emphasis"><em> </em></span></strong></span>minta súlya az összes bizonyítékváltozó valószínűségének szorzata a szülei értékei mellett (amelyek közül néhány vagy akár az összes a <span class="emphasis"><em>Z<sub>i</sub>-</em></span>k között lehet):</p><p><span class="inlinemediaobject"><img src="math/mi-14-0030.gif" alt="Az elutasító mintavétel algoritmusa, ami Bayes-hálós lekérdezéseket válaszol meg bizonyítékok esetén"/></span></p><p>A (14.6) és (14.7) egyenleteket összeszorozva láthatjuk, hogy egy minta <span class="emphasis"><em>súlyozott</em></span> valószínűsége különösen kényelmes alakú</p><p><span class="inlinemediaobject"><img src="math/mi-14-0031.gif" alt="Az elutasító mintavétel algoritmusa, ami Bayes-hálós lekérdezéseket válaszol meg bizonyítékok esetén"/></span></p><p>mivel a két szorzat lefedi az összes változót a hálóban, lehetővé téve, hogy az együttes valószínűségre a (14.1) egyenletet használjuk.</p><div class="figure"><a id="id682323"/><p class="title"><strong>14.14. ábra - A valószínűségi súlyozás algoritmusa Bayes-hálóban történő következtetéshez</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/14-14.png" alt="A valószínűségi súlyozás algoritmusa Bayes-hálóban történő következtetéshez"/></div></div></div><p class="Tartalom3">Most már könnyen megmutatható, hogy a valószínűségi súlyozásos mintavétel konzisztens. Az <span class="emphasis"><em>X</em></span> bármely konkrét <span class="emphasis"><em>x</em></span> értékére a becsült a posteriori valószínűség a következőképpen számítható ki:</p><p><span class="inlinemediaobject"><img src="math/mi-14-0032.gif" alt="A valószínűségi súlyozás algoritmusa Bayes-hálóban történő következtetéshez"/></span></p><p>Így a valószínűségi súlyozás konzisztens becsléseket szolgáltat.</p><p>Mivel a valószínűségi súlyozás az összes generált mintát felhasználja, sokkal hatékonyabb lehet, mint az elutasításos mintavétel. Azonban a teljesítménye leromlik, amint a bizonyítékváltozók száma növekszik. Ez azért következik be, mert a legtöbb mintának nagyon kis súlya lesz, és így a súlyozott becslést főként a minták azon csekély töredéke határozza meg, amelyek egy elenyésző valószínűségnél jobban illeszkednek a bizonyítékokhoz. A probléma még erőteljesebben jelentkezik, ha a bizonyítékváltozók később fordulnak elő a változó sorrendben, mivel ekkor a minták olyan szimulációk, amelyek kevés hasonlóságot mutatnak a bizonyítékok által sugalmazott valósághoz.</p></div><div class="section" title="Következtetés Markov-lánc szimulációval"><div class="titlepage"><div><div><h2 class="title"><a id="id682357"/>Következtetés Markov-lánc szimulációval</h2></div></div></div><p class="Tartalom3">Ebben a fejezetben a <span class="strong"><strong>Markov lánc Monte Carlo</strong></span> (<span class="strong"><strong>MCMC</strong></span>, <span class="strong"><strong>Markov chain Monte </strong></span><span class="strong"><strong>Carlo</strong></span>) algoritmust ismertetjük, hogy Bayes-hálókban következtethessünk. Először leírjuk, mit is csinál az algoritmus, majd elmagyarázzuk, hogy miért is működik, és miért van ilyen bonyolult neve.</p><p><span class="strong"><strong>Az MCMC algoritmus</strong></span></p><p class="Tartalom3">Az előző két mintavételi algoritmustól eltérően, amelyek az egyes eseményeket a semmiből generálják, az MCMC minden eseményt az azt megelőző esemény véletlen módosításával generál. Ezért a hálót hasznos úgy elképzelni, mint aminek van egy konkrét <span class="emphasis"><em>jelenlegi állapota,</em></span> ami minden változóra meghatároz egy értéket. A következő állapot generálása egy <span class="emphasis"><em>X<sub>i</sub></em></span> nem bizonyítékváltozóhoz tartozó érték véletlenszerű mintavételezésével történik,<span class="emphasis"><em> az X<sub>i</sub> Markov-takarójába tartozó változók jelenlegi értékeinek feltétele mellett</em></span>. (Emlékezzünk vissza az <a class="xref" href="ch14s02.md#ID_586_oldal">„Feltételes függetlenségi relációk Bayes-hálókban”</a> részre: egy változó Markov-takarója a szüleiből, gyermekeiből és gyermekei szüleiből áll.) Az MCMC így véletlen bolyongást végez az állapottérben – a lehetséges teljes érték hozzárendelések terében –, egyszerre egy változót billentve át, de rögzítetten tartva a bizonyítékváltozókat.</p><p class="Tartalom3">Gondoljuk meg a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Eső</em></span>∣<span class="emphasis"><em>Locsoló</em></span> = <span class="emphasis"><em>igaz</em></span>, <span class="emphasis"><em>VizesPázsit</em></span> = <span class="emphasis"><em>igaz</em></span>) kérdést a 14.11. (a) ábrán látható háló esetén. A <span class="emphasis"><em>Locsoló </em></span>és<span class="emphasis"><em> </em></span>a <span class="emphasis"><em>VizesPázsit</em></span> bizonyítékváltozók rögzítettek a megfigyelt értékeikre, míg a rejtett <span class="emphasis"><em>Felhős</em></span> és <span class="emphasis"><em>Eső</em></span> változók véletlenszerűen inicializáltak – mondjuk az egyik <span class="emphasis"><em>igaz</em></span>-ra, a másik <span class="emphasis"><em>hamis</em></span>-ra. Így a kezdeti állapot [<span class="emphasis"><em>igaz</em></span>,<span class="emphasis"><em> igaz</em></span>,<span class="emphasis"><em> hamis</em></span>,<span class="emphasis"><em> igaz</em></span>]. Ekkor a következő lépéseket hajtjuk végre ismétlődően:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>A <span class="emphasis"><em>Felhős</em></span>-t mintavételezzük a Markov-takarójába eső változók jelenlegi értékeinek ismeretében: ebben az esetben a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Felhős</em></span>∣<span class="emphasis"><em>Locsoló</em></span> = <span class="emphasis"><em>igaz</em></span>,<span class="emphasis"><em> Eső</em></span> = <span class="emphasis"><em>hamis</em></span>)<span class="emphasis"><em> </em></span>szerint mintavételezünk. (Hamarosan megmutatjuk, hogyan számítható ki ez az eloszlás.) Tegyük fel, hogy az eredmény <span class="emphasis"><em>Felhős</em></span> = <span class="emphasis"><em>hamis.</em></span> Ekkor az új állapot [<span class="emphasis"><em>hamis</em></span>, <span class="emphasis"><em>igaz</em></span>, <span class="emphasis"><em>hamis</em></span>,<span class="emphasis"><em> igaz</em></span>].</p></li><li class="listitem"><p>Az <span class="emphasis"><em>Eső-</em></span>t mintavételezzük a Markov-takarójába eső változók jelenlegi értékeinek ismeretében: ebben az esetben a <span class="strong"><strong>P</strong></span>(<span class="emphasis"><em>Eső</em></span>∣<span class="emphasis"><em>Felhős </em></span>= <span class="emphasis"><em>hamis</em></span>,<span class="emphasis"><em> Locsoló</em></span> = <span class="emphasis"><em>igaz</em></span>,<span class="emphasis"><em> VizesPázsit</em></span> = <span class="emphasis"><em>igaz</em></span>)<span class="emphasis"><em> </em></span>szerint mintavételezünk. Tegyük fel, hogy ennek eredménye <span class="emphasis"><em>Eső</em></span> = <span class="emphasis"><em>igaz.</em></span> Ekkor az új állapot [<span class="emphasis"><em>hamis</em></span>, <span class="emphasis"><em>igaz</em></span>,<span class="emphasis"><em> igaz</em></span>,<span class="emphasis"><em> igaz</em></span>].</p></li></ol></div><p class="Tartalom3">A folyamat során meglátogatott minden egyes állapot egy olyan minta, ami hozzájárul az <span class="emphasis"><em>Eső</em></span> célváltozó megbecsléséhez. Ha a folyamat 20 állapotot látogatott meg, ahol az <span class="emphasis"><em>Eső</em></span> igaz, és 61 állapotot, ahol az <span class="emphasis"><em>Eső</em></span> hamis, akkor a kérdésre a választ a <code class="code">NORMALIZÁL</code> (〈20, 60〉) = 〈0,25, 0,75〉<span class="emphasis"><em> </em></span>adja<span class="emphasis"><em>. </em></span>A<span class="emphasis"><em> </em></span>teljes algoritmus a 14.15. ábrán látható.</p><p><span class="strong"><strong>Miért működik az MCMC?</strong></span></p><div class="important" title="Fontos" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Fontos</h3><p class="Tartalom3">Most megmutatjuk, hogy az MCMC konzisztens becsléseket szolgáltat az a posteriori valószínűségekre. A fejezet anyaga eléggé technikai jellegű, de az alapállítás egyszerű: <span class="emphasis"><em>a mintavételi folyamat egy olyan „dinamikus egyensúlyban” állapodik meg, amelyben az egyes állapotokban töltött idő hosszú távon számolt hányada pontosan az a posteriori valószínűséggel arányos. </em></span>Ez a figyelemre méltó tulajdonság a speciális <span class="strong"><strong>átmenetvalószínűség</strong></span> (<span class="strong"><strong>transition probability</strong></span>) miatt áll fent, amely szerint a folyamat egyik állapotból a másikba lép át, ahogyan ezt a feltételes eloszlást a mintavételezett változó Markov-takarója meghatározza.</p></div><div class="figure"><a id="id682995"/><p class="title"><strong>14.15. ábra - Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/14-15.png" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></div></div></div><a id="ID_605_oldal"/><p>Legyen <span class="emphasis"><em>q</em></span>(<span class="strong"><strong>x</strong></span>⟶<span class="strong"><strong>x</strong></span>′) az a valószínűség, hogy a folyamat <span class="strong"><strong>x</strong></span> állapotból <span class="strong"><strong>x</strong></span>′ állapotba lép át. Ez az átmenet-valószínűség definiálja az úgynevezett <span class="strong"><strong>Markov-lánc</strong></span>ot (<span class="strong"><strong>Markov chain</strong></span>) az állapottéren. (A Markov-láncok a 15. és 17. fejezetben is kiemelkedő szerepet játszanak.)</p><p>Tegyük fel most, hogy <span class="emphasis"><em>t</em></span> lépésnyit futtatjuk a Markov-láncot, és legyen π<sub>t</sub>(<span class="strong"><strong>x</strong></span>) annak a valószínűsége, hogy a rendszer a <span class="emphasis"><em>t</em></span> időpillanatban az <span class="strong"><strong>x</strong></span> állapotban van. Hasonlóan, legyen π<sub><span class="emphasis"><em>t</em></span>=1</sub>(<span class="strong"><strong>x</strong></span>′) annak a valószínűsége, hogy a rendszer <span class="emphasis"><em>t</em></span> = 1 időpillanatban <span class="strong"><strong>x</strong></span>′ állapotban van. Ismerve π<sub>t</sub>(<span class="strong"><strong>x</strong></span>)-et a π<sub><span class="emphasis"><em>t</em></span>=1</sub>(<span class="strong"><strong>x</strong></span>′) kiszámítható úgy, hogy minden olyan állapotra, amiben a rendszer <span class="emphasis"><em>t</em></span> időpillanatban lehet, összegezzük az állapot valószínűségének és az ebből az állapotból az <span class="strong"><strong>x</strong></span>′-be való átlépés valószínűségének szorzatát:</p><p><span class="inlinemediaobject"><img src="math/mi-14-0033.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span></p><p>Akkor mondjuk, hogy egy lánc elérte a <span class="strong"><strong>stacionárius eloszlás</strong></span>át (<span class="strong"><strong>stationary distribution</strong></span>), ha π<sub>t</sub> = π<sub><span class="emphasis"><em>t+</em></span>1</sub>. Jelöljük ezt a stacionárius eloszlást π<span class="emphasis"><em>-</em></span>vel; az ezt definiáló egyenlet így</p><p><span class="inlinemediaobject"><img src="math/mi-14-0034.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span></p><p>Ha a <span class="emphasis"><em>q</em></span> átmenet-valószínűség eloszlás eleget tesz néhány alapvető feltevésnek,<sup>[<a id="id683161" href="#ftn.id683161" class="footnote">151</a>]</sup> akkor bármely <span class="emphasis"><em>q</em></span> esetén pontosan egyetlen π eloszlás elégíti ki ezt az egyenletet.</p><p>A (14.9) egyenlet úgy tekinthető, mint ami azt állítja, hogy az egyes állapotokból a „kilépések” várható értéke (azaz a jelenlegi „populáció”) egyenlő az összes állapotbóli „belépések” várható értékével. Ez a kapcsolat nyilvánvalóan teljesíthető, ha a várható átlépések mindkét irányban ugyanakkorák bármely állapotpár esetén. Ez a tulajdonság a <span class="strong"><strong>teljes egyensúly</strong></span> (<span class="strong"><strong>detailed balance</strong></span>):</p><p><code class="code"><em><span class="remark">π</span></em>(<em><span class="remark">x</span></em>)<em><span class="remark">q</span></em>(<em><span class="remark">x</span></em>⟶<em><span class="remark">x</span></em>′) = <em><span class="remark">π</span></em> (<em><span class="remark">x</span></em>′)<em><span class="remark">q</span></em>(<em><span class="remark">x</span></em>⟶<em><span class="remark">x</span></em>′)<em><span class="remark">		</span></em>minden <em><span class="remark">x</span></em>, <em><span class="remark">x</span></em>′-re			(14.10)</code></p><p>Megmutathatjuk, hogy a teljes egyensúly maga után vonja a stacionaritást, egyszerűen az <span class="strong"><strong>x</strong></span>-ek felett összegezve a (14.10) egyenletben. Azt kapjuk, hogy</p><p><span class="inlinemediaobject"><img src="math/mi-14-0035.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span></p><p>ahol az utolsó lépés abból következik, hogy <span class="strong"><strong>x</strong></span>′-ből biztosan történik átmenet.</p><p>Most megmutatjuk, hogy az <code class="code">MCMC-KÉRDEZ</code> mintavételi lépésében megadott <span class="emphasis"><em>q</em></span>(<span class="strong"><strong>x</strong></span>⟶<span class="strong"><strong>x</strong></span>′)<span class="emphasis"><em> </em></span>átmenet-valószínűség eleget tesz a teljes egyensúly egyenletének, ahol a stacionárius eloszlás a <span class="emphasis"><em>P</em></span>(<span class="strong"><strong>x</strong></span>∣<span class="strong"><strong>e</strong></span>), a rejtett változók valódi a posteriori eloszlása. Ezt két lépésben teszszük meg. Először, egy Markov-láncot definiálunk, amelyben minden változót az <span class="emphasis"><em>öszszes</em></span> többi változóval feltételesen mintavételezünk, és megmutatjuk, hogy ez eleget tesz a teljes egyensúly egyenletének. Majd egyszerűen megállapítjuk, hogy Bayes-hálóknál ez ekvivalens azzal a feltételes mintavételezéssel, hogy a feltétel a változó Markov-takarója (lásd <a class="xref" href="ch14s02.md#ID_586_oldal">„Feltételes függetlenségi relációk Bayes-hálókban”</a> részben).</p><p>Legyen <span class="emphasis"><em>X<sub>i</sub></em></span> a mintavételezett változó, és jelölje <span class="inlinemediaobject"><img src="math/mi-14-0036.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span> az összes többi rejtett változót. A jelenlegi állapotban az értékük <span class="emphasis"><em>x<sub>i</sub></em></span> és <span class="inlinemediaobject"><img src="math/mi-14-0037.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span>. Ha az <span class="emphasis"><em>X<sub>i</sub></em></span>-nek új <span class="emphasis"><em>x<sub>i</sub></em></span>′ értéket mintavételezünk feltételesen az összes többi változóval, beleértve a bizonyítékot is, akkor</p><p><span class="inlinemediaobject"><img src="math/mi-14-0038.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span></p><p>Ezt az átmenet-valószínűséget nevezik <span class="strong"><strong>Gibbs-mintavételező</strong></span>nek (<span class="strong"><strong>Gibbs sampler</strong></span>), ami az MCMC egy nagyon kényelmes alakja.</p><p>Most megmutatjuk, hogy a Gibbs-mintavételező teljes egyensúlyban van a helyes a posteriori eloszlása szerint:</p><p><span class="inlinemediaobject"><img src="math/mi-14-0039.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span></p><p>Ahogy az <a class="xref" href="ch14s02.md#ID_586_oldal">„Feltételes függetlenségi relációk Bayes-hálókban”</a> részben kimondtuk, egy változó független az összes többi változótól a Markov-takarójának a feltételében; így:</p><p><span class="inlinemediaobject"><img src="math/mi-14-0040.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span></p><p>ahol <span class="emphasis"><em>mb</em></span>(<span class="emphasis"><em>X<sub>i</sub></em></span>) jelöli az <span class="emphasis"><em>X<sub>i</sub> </em></span>Markov-takarójában, <span class="emphasis"><em>MB</em></span>(<span class="emphasis"><em>X<sub>i</sub></em></span>)-ben lévő változók értékeit. Amint a 14.10. feladat mutatja, egy változó valószínűsége a Markov-takarójának ismeretében arányos a változó szüleivel vett feltételes valószínűségének és az egyes gyermekek azok szüleivel vett feltételes valószínűségeinek a szorzatával:</p><p><span class="inlinemediaobject"><img src="math/mi-14-0041.gif" alt="Az MCMC algoritmus Bayes-hálóban történő közelítő következtetéshez"/></span></p><p>Így egy változó átléptetéséhez az <span class="emphasis"><em>X<sub>i</sub> </em></span>gyermekeinek számával megegyező számú szorzás szükséges.</p><p>Itt csupán az MCMC-nek egy egyszerű változatát tárgyaltuk, nevezetesen a Gibbs-mintavételezőt. Legáltalánosabb formájában az MCMC hatékony módszer valószínűségi modellekkel való számolásra, és számos változatát fejlesztették ki, közöttük a 4. fejezetben bemutatott szimulált lehűtés algoritmust, a 7. fejezetben a sztochasztikus kielégíthetőség algoritmust, valamint a 15. fejezetben a Metropolis–Hastings-mintavételezőt.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id682250" href="#id682250" class="para">150</a>] </sup> Ideálisan, a <span class="emphasis"><em>P</em></span>(<span class="strong"><strong>z</strong></span>∣<span class="strong"><strong>e</strong></span>) valódi a posteriori eloszlással megegyező mintavételi eloszlást szeretnénk használni, hogy az összes bizonyítékot figyelembe vegyük. Ez azonban nem tehető meg hatékonyan. Ha lehetne, akkor a kívánt valószínűséget tetszőleges pontossággal közelíthetnénk polinomiális számú mintával. Megmutatható, hogy nem létezhet ilyen polinom idejű közelítő séma.</p></div><div class="footnote"><p><sup>[<a id="ftn.id683161" href="#id683161" class="para">151</a>] </sup> A <span class="emphasis"><em>q</em></span> által definiált Markov-láncnak <span class="strong"><strong>ergodikus</strong></span>nak (<span class="strong"><strong>ergodic</strong></span>) kell lennie – azaz lényegében, minden állapotnak elérhetőnek kell lennie bármely másik állapotból, és nem lehetnek szigorúan periodikus ciklusok.</p></div></div></div></body></html>
