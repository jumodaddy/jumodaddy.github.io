<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="chapter" title="26. fejezet - Filozófiai alapok"><div class="titlepage"><div><div><h1 class="title"><a id="id796974"/>26. fejezet - Filozófiai alapok</h1></div></div></div><p><span class="emphasis"><em>Ebben a fejezetben arról esik szó, hogy mit jelent gondolkozni, vajon képesek-e erre a mesterséges tárgyak, és szeretnénk-e, ha képesek lennének rá.</em></span></p><p>Ahogyan az 1. fejezetben említettük, a filozófusok sokkal régebb óta vannak jelen, mint a számítógépek, és folyamatosan próbálnak válaszokat találni néhány olyan kérdésre, amely a mesterséges intelligenciához kötődik: Hogyan működik az elme? Képesek-e gépek intelligensen cselekedni; és ha igen, lenne-e elméjük? Milyen etikai következményei lehetnek az intelligens gépeknek? A könyv eddigi huszonöt fejezetében a mesterséges intelligencia saját kérdéseiről volt szó, most egy fejezet erejéig a filozófusok témáival foglalkozunk.</p><p>Először néhány elnevezés: a filozófiában <span class="strong"><strong>gyenge MI</strong></span>-hipotézisnek (<span class="strong"><strong>weak AI</strong></span>) nevezik azt az állítást, miszerint a gépek valószínűleg képesek intelligensen cselekedni (vagy jobban mondva, képesek úgy cselekedni, <span class="emphasis"><em>mintha</em></span> intelligensek lennének), míg azt az állítást, hogy a gépek <span class="emphasis"><em>valóban</em></span> intelligensen cselekszenek, <span class="strong"><strong>erős MI</strong></span>-hipotézisnek (<span class="strong"><strong>strong AI</strong></span>) hívják.</p><p>A legtöbb MI-kutató elfogadja a gyenge MI-hipotézist, az erőssel pedig nem törődik: amíg a program működik, az nem érdekes, hogy az intelligencia szimulációjának nevezik-e vagy valós intelligenciának. Minden MI-kutatónak foglalkoznia kellene munkája etikai következményeivel.</p><div class="section" title="Gyenge MI: Tudnak-e a gépek intelligensen cselekedni?"><div class="titlepage"><div><div><h1 class="title"><a id="id797015"/>Gyenge MI: Tudnak-e a gépek intelligensen cselekedni?</h1></div></div></div><p>Néhány filozófus megpróbálta bebizonyítani, hogy a mesterséges intelligencia nem lehetséges, azaz a gépek valószínűleg nem tudnak intelligensen cselekedni. Néhányan az MI-kutatás leállítását szeretnék elérni érveikkel:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p><span class="emphasis"><em>A számításorientált megközelítés kultuszának részeként űzött</em></span> mesterséges intelligenciának még esélye sincsen arra, hogy tartós eredményeket érjen el (…) itt az ideje, hogy az MI-kutatók erőfeszítéseit – és a támogatásukra szánt hatalmas pénzeket – máshova tereljük, mint a számításorientált megközelítés.</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">(Sayre, 1993)</span></td></tr></table></div><p>A mesterséges intelligencia lehetséges mivolta nyilván azon múlik, miként definiáljuk. Lényegét tekintve a mesterséges intelligencia egy adott architektúrához a legjobb ágensprogramot keresi. Ebben a megfogalmazásban már a definíció szerint is lehetséges az MI: bármely <span class="emphasis"><em>k</em></span> tárbitet tartalmazó digitális architektúrához pontosan 2<sup>k</sup> ágensprogram tartozik; ahhoz pedig, hogy megtaláljuk a legjobbat, egyszerűen csak egyesével fel kell sorolni és tesztelni az ágenseket. Ez ugyan nem lenne praktikus nagy <span class="emphasis"><em>k</em></span> esetén, de a filozófia az elmélettel, nem pedig a gyakorlattal foglalkozik.</p><p>A mesterséges intelligenciára adott definíciónk jól működik a mérnöki probléma esetében is, ahol egy adott architektúrához tartozó jó ágenst kell találni. Nagy a kísértés tehát, hogy befejezzük itt ezt a szakaszt, és igenlő választ adjunk a címben feltett kérdésre. A filozófusok azonban két architektúrát akarnak összehasonlítani: az embert és a gépet. Ráadásul a hagyományosan feltett kérdés így hangzik: „<span class="strong"><strong>Tudnak-e a gépek gondolkodni?</strong></span>” Sajnos ez egy helytelenül feltett kérdés. Hogy megértsük, miért, nézzük az alábbi kérdéseket:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Tudnak a gépek repülni?</p></li><li class="listitem"><p>Tudnak a gépek úszni?</p></li></ul></div><p>A legtöbb angolul beszélő ember<sup>[<a id="id797064" href="#ftn.id797064" class="footnote">277</a>]</sup><sup> </sup>egyetért abban, hogy az első kérdésre igennel kell felelni: a repülőgépek tudnak repülni; de a második kérdésre az angolban a válasz nemleges: a hajók és a tengeralattjárók haladnak ugyan a vízben, de az angolban ezt nem nevezik úszásnak. Sem ezeknek a kérdéseknek persze, sem a válaszoknak nincsen semmilyen hatása a tengerészek, a tengerészeti mérnökök vagy az ezekkel a dolgokkal bármilyen kapcsolatba kerülők mindennapi munkájára. A válaszoknak alig van közük a repülőgépek és tengeralattjárók tervezéséhez és képességeihez; inkább arról szólnak, hogy a szavak használatának milyen módjait választottuk ki. Úgy alakult, hogy az „úszni” szó az angolban azt jelenti, hogy ’testrészeinek mozgásával előrehalad a vízben’, míg a „repülni” szó jelentése az angolban nem határozza meg a helyváltoztatás módját.<sup>[<a id="id797076" href="#ftn.id797076" class="footnote">278</a>]</sup> A „gondolkodó gépek” gyakorlati lehetősége még csak mintegy ötven éve jelent meg, és ez az idő nem volt elég az angolul beszélőknek, hogy a „gondolkodni” szó az angolban új jelentést kapjon. </p><p>Alan Turing azt javasolta <span class="emphasis"><em>Computing Machinery and Intelligence </em></span>c. híres cikkében (Turing, 1950), hogy ne azt kérdezzük, tudnak-e a gépek gondolkodni, hanem azt vizsgáljuk, hogy átmennek-e a gépek egy viselkedési intelligenciateszten, amelyet később Turing-tesztnek neveztek el. A teszt szerint a programnak öt percen át kell (gépelt online üzenetekkel) beszélgetnie egy kérdezővel. A kérdezőnek ezután választania kell, hogy egy programmal vagy egy személlyel beszélgetett-e, és egy program akkor felel meg a teszten, ha az idő 30%-ában megtéveszti a kérdezőt. Turing azt a sejtést fogalmazta meg, hogy 2000-re egy 10<sup>9</sup> táregységből álló számítógépet be lehet úgy programozni, hogy megfeleljen a teszten, ámde nem lett igaza. Az ugyan <span class="emphasis"><em>megtörtént</em></span> már, hogy néhány embert öt percig becsaptak; például az <code class="code">ELIZA</code> program és az <code class="code">MGONZ</code> internetes csevegőrobot becsapott olyan embereket, akik nem gondoltak arra, hogy talán egy programmal beszélhetnek, és az <code class="code">ALICE</code> program becsapott egy zsűritagot a 2001-es Loebner-díjért zajló versenyben. De egyetlenegy program sem került annak közelébe, hogy 30%-ot érjen el képzett zsűrivel szemben, és az MI-kutatás egésze nem is szentel túl nagy figyelmet a Turing-teszteknek.</p><p>Turing az intelligens gépek lehetősége ellen felhozható érvek széles választékát is megvizsgálta, beleértve szinte minden olyan ellenérvet, amely a cikk megjelenése óta eltelt fél évszázadban felmerült. A következőkben ezek közül nézünk meg néhányat.</p><div class="section" title="A képesség hiányából vett érv"><div class="titlepage"><div><div><h2 class="title"><a id="id797112"/>A képesség hiányából vett érv</h2></div></div></div><p>A „képesség hiányából vett érv” azzal a követeléssel lép fel, hogy „a gépek sohasem képesek <span class="emphasis"><em>X</em></span>-et tenni”. Az <span class="emphasis"><em>X</em></span>-ekre Turing a következő példákat hozza: </p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p>Kedvesnek, találékonynak, szépnek és barátságosnak lenni, kezdeményezni, humorérzéket mutatni, megkülönböztetni a helyest a helytelentől, hibákat követni el, szerelmesnek lenni, élvezni a tejszínes epret, elérni, hogy valaki szerelmes legyen belé, tapasztalatból tanulni, helyesen használni a szavakat, saját gondolatai alanyának lenni, annyira változatosan viselkedni, mint az ember, valami igazán újat tenni.</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">Turing</span></td></tr></table></div><p>Turingnak az intuícióját kellett használnia, hogy megsejtse, mi válhat lehetségessé a jövőben, mi azonban abban a kényelmes helyzetben vagyunk, hogy visszanézhetünk a számítógépek eddigi teljesítményére. Senki sem tagadja, hogy a számítógépek ma sok olyan dolgot megtesznek, amely korábban kizárólag az emberekhez tartozott. A programok sakkoznak, dámát vagy más játékokat játszanak, alkatrészeket vizsgálnak gyártósorokon, a szövegszerkesztéskor ellenőrzik a helyesírást, helikoptereket és autókat irányítanak, betegségeket diagnosztizálnak és több száz más tevékenységet végeznek éppolyan jól, vagy még jobban, mint az emberek. A számítógépek kicsiny, de jelentős felfedezéseket tettek a csillagászatban, a matematikában, a kémiában, az ásványtanban, a biológiában, a számítástudományban és más területeken. Ezekhez a felfedezésekhez az emberi szakértőhöz hasonló szintű teljesítményekre volt szükség.</p><p>Annak fényében, amit most tudunk a számítógépekről, nem meglepő, hogy jól teljesítenek a sakkhoz hasonló kombinatorikai problémákban. De az algoritmusok az emberhez mérhető szinten hajtanak végre olyan tevékenységeket is, amelyek látszólag emberi döntést igényelnek, amelyek során, mint Turing mondta, képesnek kell lenni a „tapasztalatból tanulni” és „megkülönböztetni a helyest a helytelentől”. Még egészen korán, 1955-ben Paul Meehl (lásd még Grove és Meehl, 1996) képzett szakértők döntéshozatali folyamatát tanulmányozta olyan szubjektív esetekben, mint például hogy egy diák elvégez-e egy képzési programot, vagy egy bűnöző visszaesik-e. A megvizsgált 20 eset közül 19-nél Meehl azt találta, hogy egyszerű statisztikai tanulási algoritmusok (mint például a lineáris regresszió vagy a naiv Bayes-tanulás) jobb előrejelzéseket adnak, mint az emberi szakértők. Az Educational Testing Service a GMAT-vizsga esszékérdéseinek millióit osztályozza 1999 óta egy automatizált programmal. A program osztályzata az osztályzást végző emberek minősítésével az esetek 97%-ában egyezik meg, és ez az arány hasonló ahhoz, amennyire a különböző emberek által adott minősítések megegyeznek (Burstein és társai, 2001). </p><p>Világos, hogy sok mindent, köztük olyan dolgokat is, amelyekhez általános meggyőződésünk szerint komoly emberi éleselméjűség és értelem szükséges, a számítógépek ugyanolyan jól el tudnak végezni, mint az emberek, vagy akár még jobban is. Ez persze nem jelenti azt, hogy a számítógépek éleselméjűséget és értelmet tanúsítanának az ilyen dolgok végrehajtásakor: ezek nem részei <span class="emphasis"><em>viselkedésüknek</em></span> (erről a kérdésről majd máshol beszélünk), hanem inkább arról van szó, hogy gyakran téves az első feltételezésünk az adott tevékenység elvégzéséhez szükséges mentális folyamatról. Ugyanakkor az is igaz, hogy számtalan feladatban a számítógépek (finoman szólva) nem járnak az élen, és ilyen Turing feladata, a nyíltvégű beszélgetések folytatása is.</p></div><div class="section" title="A matematikai ellenvetés"><div class="titlepage"><div><div><h2 class="title"><a id="id797142"/>A matematikai ellenvetés</h2></div></div></div><p>Turing (Turing, 1936) és Gödel (Gödel, 1931) munkássága révén közismert, hogy egyes matematikai kérdések elviekben is megválaszolhatatlanok bizonyos formális rendszerekben. A leghíresebb példa erre Gödel nemteljességi tétele (lásd 9.5. alfejezet). Ez, röviden összefoglalva, azt mondja ki, hogy bármely <span class="emphasis"><em>F</em></span> formális rendszerben, amelyben az aritmetika megfogalmazható, lehetséges egy <span class="emphasis"><em>G</em></span>(<span class="emphasis"><em>F</em></span>) Gödel-mondatot konstruálni, amelyre igaz, hogy</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><span class="emphasis"><em>G</em></span>(<span class="emphasis"><em>F</em></span>) egy mondat<span class="emphasis"><em> F</em></span>-ben, de <span class="emphasis"><em>F</em></span>-en belül nem bizonyítható.</p></li><li class="listitem"><p>Ha <span class="emphasis"><em>F</em></span> konzisztens, akkor <span class="emphasis"><em>G</em></span>(<span class="emphasis"><em>F</em></span>) igaz.</p></li></ul></div><p>Egyes filozófusok, mint például J. R. Lucas (Lucas, 1961) állítása szerint ez a tétel azt bizonyítja, hogy a gépek mentálisan alsóbbrendűek az embereknél, mert a gépeket mint formális rendszereket korlátozza a nemteljességi tétel (nem tudják megállapítani a saját Gödel-mondatuk igazságát), az embereket viszont ilyesmi nem korlátozza. Ez az állítás évtizedes, sok könyvet felölelő vitát keltett, például a matematikus Sir Roger Penrose két könyvében (Penrose, 1989; 1994) képviseli ezt az állítást kicsit megcsavarva (például azzal a feltételezéssel, hogy az emberek azért különböznek, mert agyukat a kvantumgravitáció működteti). Három problémát fogunk az állítással kapcsolatban megvizsgálni.</p><p>Először is Gödel nemteljességi tétele csak olyan formális rendszerekre vonatkozik, amelyek elég erősek az aritmetikához. Ezek közé tartozik a Turing-gép is, és Lucas állítása részben azon a feltételezésen alapul, hogy a számítógépek Turing-gépek. Ez jó közelítés, ám nem teljesen igaz. A Turing-gépek végtelenek, a számítógépek azonban végesek, és ezért bármely számítógépet le lehet írni egy nagyon nagy logikai állításrendszerrel, amelyre már nem vonatkozik Gödel nemteljességi tétele.</p><p>Másodszor is egy ágensnek nem kell túlzottan szégyenkeznie amiatt, hogy egyes állítások igazságát, másoktól eltérően, ő nem tudja eldönteni. Nézzük például a következő mondatot:</p><p>J. R. Lucas nem tudja konzisztensen azt állítani, hogy ez a mondat igaz.</p><p>Lucas ellentmondana önmagának, ha azt állítaná, hogy a fenti (teljes) mondat igaz, tehát Lucas nem tudja ezt a mondatot konzisztensen állítani, tehát a mondat mindenképpen igaz. (A mondat nem lehet hamis, mert ha hamis volna, akkor Lucas nem tudná konzisztensen állítani, tehát igaz lenne.) Bebizonyítottuk tehát, hogy van egy mondat, amelyet Lucas nem tud konzisztensen állítani, mások viszont (beleértve a gépeket is) igen. De ez előttünk semmit sem von le Lucas értékéből. Egyetlenegy ember sem tudja, hogy egy másik példát vegyünk, élete során kiszámítani tízmilliárd tízjegyű szám összegét, egy számítógép viszont másodpercek alatt megteszi ezt. Mégsem tartjuk ezt az emberi gondolkodási képesség alapvető korlátjának. Évezredeken át, mielőtt felfedezték volna a matematikát, az emberek ugyanúgy intelligens viselkedést tanúsítottak, nem valószínű hát, hogy a matematika a periferiálisnál fontosabb szerepet játszana az intelligencia meghatározásában.</p><p>Harmadszor és legfőképpen, még ha el is fogadjuk, hogy a számítógépek bizonyítási képessége korlátozott, semmi sem bizonyítja, hogy az emberek mentesek lennének az ilyen korlátozásoktól. Túlzottan is egyszerű szigorúan bebizonyítani, hogy egy formális rendszer képtelen <span class="emphasis"><em>X</em></span>-re, majd minden további bizonyíték nélkül azt állítani, hogy az emberek a maguk nem formális módján <span class="emphasis"><em>képesek</em></span> erre az <span class="emphasis"><em>X</em></span>-re. Azt, hogy az emberek nincsenek alávetve Gödel nemteljességi tételének, valóban lehetetlen bebizonyítani, mert bármely szigorú bizonyításnak tartalmaznia kellene az állítás szerint formalizálhatatlan emberi tehetség egy formalizálását, tehát a bizonyítás önmagát cáfolná meg. Lehet még fellebbezni az intuícióhoz, miszerint az emberek valamilyen módon képesek a matematikai belátás emberfeletti cselekedeteire. Ezt a fordulatot fejezik ki az olyan érvek, mint például „feltételeznünk kell önnön konzisztenciánkat, hogy a gondolkodás egyáltalán lehetséges legyen” (Lucas, 1976). De ha bármiről is, akkor az emberi gondolkodásról mindenképpen tudjuk, hogy inkonzisztens. Ez egyértelműen igaz a mindennapi érvelésünkre, de vonatkozik még az elővigyázatos matematikai gondolkodásra is. Híres példa erre a négyszín-probléma. 1879-ben Alfred Kempe közzétett egy bizonyítást, amelyet széles körben elfogadtak, és amely hozzájárult, hogy a Royal Society tagjává választották. 1890-ben azonban Percy Heawood egy hibát fedezett fel a bizonyításban, és egészen 1977-ig senki nem tudta a tételt bebizonyítani.</p></div><div class="section" title="A meghatározatlanságból vett érv"><div class="titlepage"><div><div><h2 class="title"><a id="id797220"/>A meghatározatlanságból vett érv</h2></div></div></div><p>A mesterséges intelligencia vállalkozásának legnagyobb hatású és legmakacsabb kritikáját Turing úgy mutatta be, mint „a viselkedés meghatározatlanságából származó érvet”. Az állítás lényege az, hogy az emberi viselkedés túl komplex ahhoz, hogy egy szabálykészlettel le lehessen írni, és mivel a számítógépek semmi másra nem képesek, csak szabályok követésére, ezért nem tudnak az emberekhez hasonló intelligens viselkedést létrehozni. Azt, hogy logikai szabályok egy halmazával képtelenség mindent leírni, a mesterséges intelligenciában <span class="strong"><strong>kvalifikációs problémá</strong></span>nak (<span class="strong"><strong>qualification problem</strong></span>) nevezik (lásd 10. fejezet).</p><p>Ezt a nézetet főként a filozófus Hubert Dreyfus képviselte, aki számos befolyásos MI-kritika szerzője: <span class="emphasis"><em>What Computers Can’t Do </em></span>(Dreyfus, 1972); <span class="emphasis"><em>What Computers Still Can’t Do </em></span>(Dreyfus, 1992), valamint a testvérével, Stuarttal, közösen írt <span class="emphasis"><em>Mind Over Machine</em></span> (Dreyfus és Dreyfus, 1986).</p><p>Azt az álláspontot, amit kritizáltak, Haugeland (Haugeland, 1985) nyomán elkezdték „Jófajta, régivágású MI”-nek nevezni (angol rövidítéssel: <code class="code">GOFAI</code>). A <code class="code">GOFAI</code> azt feltételezné, hogy minden intelligens viselkedés megragadható egy olyan rendszerrel, amely a tárgyterületet leíró tények és szabályok halmazaiból kiindulva logikai következtetést végez. Ezért a <code class="code">GOFAI</code> a 7. fejezetben<span class="emphasis"><em> </em></span>leírt legegyszerűbb logikai ágensnek felel meg. Dreyfusnak igaza van abban, hogy a logikai ágensek ki vannak téve a kvalifikációs probléma veszélyének. Amint a 13. fejezetben láttuk, a nyílt tárgyterületekhez sokkalta megfelelőbbek a valószínűségi következtető rendszerek. Dreyfus kritikája tehát nem <span class="emphasis"><em>per se</em></span> a számítógépek, hanem csak a programozás egy meghatározott módja ellen irányul. Okkal feltételezhetjük persze, hogy nem lenne túl nagy hatású egy könyv <span class="emphasis"><em>Amire az elsőrendű logikai szabályalapú, nem tanuló rendszerek képtelenek</em></span> címmel.</p><p>Dreyfus nézete szerint az emberi szakértelemnek ugyan része néhány szabály ismerete, de ezek csak „holisztikus kontextust” vagy „hátteret” alkotnak az emberi tevékenységhez. Példaként az ajándék adásakor és fogadásakor illő társas viselkedést hozza fel: „Általában az ember a megfelelő körülmények között úgy reagál, hogy egy megfelelő ajándékot ad.” Az embernek láthatólag „közvetlen érzéke van ahhoz, hogy miként történnek a dolgok, és mit lehet elvárni.” Hasonló állítást tehetünk a sakkjáték vonatkozásában is: „Egy átlagos sakkmesternek lehet, hogy gondolkodnia kell azon, mit tegyen, de egy nagymester látja, hogy a tábla egy bizonyos lépést követel (…) a helyes reakció egyszerűen csak beugrik a fejébe.” Minden bizonnyal igaz, hogy egy ajándékozó vagy egy sakknagymester gondolati folyamata azon a szinten zajlik, amely rejtett a tudatos elme önismerete elől. Ez azonban nem jelenti, hogy ez a gondolati folyamat nem létezik. Lényeges, hogy Dreyfus nem válaszolja meg azt, hogy a helyes lépés <span class="emphasis"><em>miként</em></span> kerül a nagymester fejébe. Mindez Daniel Dennett (Dennett, 1984) megjegyzésére emlékeztet:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p>Ez olyan, mintha a filozófusok azt tartanák magukról, hogy szakértő magyarázói a színpadi bűvészek trükkjeinek, aztán, amikor megkérdezzük tőlük, hogy milyen trükköt használnak a bűvészek a nő kettéfűrészelésénél, akkor azt a magyarázatot adják, hogy mindez nagyon is világos: a bűvész nem fűrészeli ketté a nőt, ezt csak színleli. Ha azt kérdezzük azonban: „Mégis <span class="emphasis"><em>hogyan</em></span> színleli?”, a filozófusok ezt felelik: „Nem ránk tartozik.”</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">Daniel Dennett</span></td></tr></table></div><p>A két Dreyfus (Dreyfus és Deyfus, 1986) vázolja a szakértelem ötlépcsős elsajátításának folyamatát, kiindulva a hasonló szabályalapú feldolgozásból (ahogyan az a <code class="code">GOFAI</code>-ban is szerepel) eljutva a helyes reakció azonnali kiválasztásának képességéhez. A szerzők ezzel a javaslattal tulajdonképpen az MI kritikusaiból az MI elméletalkotóivá válnak: egy „eset-könyvtárakba” szervezett neurálisháló-architektúrát vázolnak fel, azonban rámutatnak néhány problémára is. Ezeket a problémákat szerencsére már mind célba vette az MI-kutatás néhányukat részleges, másokat pedig teljes sikerrel oldva meg. Nézzünk néhány ilyen problémát:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Háttértudás nélkül nem lehet jól példákból általánosítani. Azt állítják, senki sem tudja, miként lehetne a háttértudást beépíteni a neuronhálók tanítási folyamatába. Pedig, amint a 19. fejezetben mi is láttuk, léteznek módszerek az a priori tudás felhasználására a tanítási folyamat során. Ezek a módszerek persze a tudás explicit megadásán alapulnak, amelynek lehetőségét a szerzőpáros elszántan tagadja. Nézetünk szerint ez a probléma erős indok a neurális feldolgozás jelenlegi modelljeinek olyan újratervezésére, amely már a többi tanuló algoritmushoz hasonlóan <span class="emphasis"><em>képes lesz</em></span> felhasználni a korábban megtanult tudást. </p></li><li class="listitem"><p>A neurális hálók tanulása a felügyelt tanulás egyik formája (lásd 18. fejezet), amely igényli, hogy előzetesen azonosítsuk a releváns bemeneteket, valamint a megfelelő kimeneteket. Ezért azt állítják, hogy nem is képesek ezek a hálózatok autonóm módon, emberi betanítás nélkül üzemelni. Valójában a <span class="strong"><strong>nem ellenőrzött tanulás</strong></span> (<span class="strong"><strong>unsu</strong></span><span class="strong"><strong>pervi</strong></span><span class="strong"><strong>sed learning</strong></span>) (lásd 20. fejezet) és a <span class="strong"><strong>megerősítéses tanulás</strong></span> (<span class="strong"><strong>reinforcement learning</strong></span>) (lásd 21. fejezet) éppen a tanító nélküli tanulást teszi lehetővé.</p></li><li class="listitem"><p>A tanuló algoritmusok nem teljesítenek jól sok jellemző esetén, viszont ha kijelöljük a jellemzők egy halmazát, „nem ismeretes olyan módszer, amellyel új jellemzőket illeszthetünk be, ha a jelenlegiek nem lennének elegendők a megtanult tényekhez”, valójában új eljárások, mint például a szupport vektor gépek, jól megbirkóznak a nagy jellemzőhalmazokkal is. A 19. fejezetben pedig láthattuk, hogy alapjaikat tekintve léteznek módszerek az új jellemzők bevezetésére, habár még sok tennivaló akad ezen a területen.</p></li><li class="listitem"><p>Az agy képes a szenzorait releváns információk keresésére irányítani, és képes kinyerni az információkból azt, ami releváns az adott szituációban. Ezzel szemben „jelenleg egyetlen részletét sem értjük ennek a működésmódnak – állítják –, és még csak olyan hipotézist sem tudunk alkotni róluk, amely útmutatásul szolgálhatna az MI-kutatóknak”. Valójában az aktív látás területe, amelyet az információérték-elmélet (lásd 16. fejezet) alapoz meg, éppen hogy a szenzorok irányításának problémájával foglalkozik, és az elért elméleti eredmények egy részét már át is ültették robotmegvalósításokba.</p></li></ol></div><p>Összegezve azt mondhatjuk, hogy számos olyan kérdés, melyet Dreyfus felvetett – a köznapi háttértudás, a kvalifikáció probléma, a bizonytalanság kezelése, a tanulás, a döntéshozatal előre lefordított módjai, annak fontossága, hogy ne testetlen következtetőgépeket tekintsünk, hanem szituációjukba ágyazott ágenseket –, ma már bekerült az intelligens ágensek tervezésének szokványos menetébe. Véleményünk szerint mindez tehát nem a mesterséges intelligencia lehetetlenségét, hanem éppen a fejlődését bizonyítja.</p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id797064" href="#id797064" class="para">277</a>] </sup> A kérdések eredeti formája és így az elemzés tárgya az angol nyelv. (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id797076" href="#id797076" class="para">278</a>] </sup> Az orosz nyelvben az „úszni” megfelelője hajókra is vonatkozik. A magyar „úszni” ige is vonatkozhat hajókra, sőt, ismét csak az angoltól eltérően, még felhőkre is. (<span class="emphasis"><em>A ford.</em></span>)</p></div></div></div></body></html>
