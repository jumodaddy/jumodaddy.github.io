<?xml version="1.0" encoding="UTF-8" standalone="no"?>

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="section" title="Információkeresés"><div class="titlepage"><div><div><h1 class="title"><a id="id774251"/>Információkeresés</h1></div></div></div><p>Az <span class="strong"><strong>információkeresés</strong></span> (<span class="strong"><strong>information retrieval</strong></span>) feladata olyan dokumentumok megtalálása, amelyek relevánsak a felhasználó információigényére nézve. Az információkereső rendszerek legjobban ismert példái a világháló keresőgépei. A felhasználó megadhat egy lekérdezést – mint például [MI-könyv] – a keresőgépnek, majd megnézheti a releváns oldalak listáját. Ebben az alfejezetben bemutatjuk, hogyan épülnek fel ezek a rendszerek. Egy információkereső (ezentúl IR-) rendszer a következő módokon jellemezhető:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>Dokumentumgyűjtemény.</strong></span> Minden rendszernek el kell döntenie, hogy mit kezel dokumentumként: egy bekezdést, egy oldalt vagy egy többoldalas szöveget.</p></li><li class="listitem"><p><span class="strong"><strong>Lekérdezőnyelven megadott kérdés.</strong></span> A <span class="strong"><strong>lekérdezés</strong></span> (<span class="strong"><strong>query</strong></span>) írja le, hogy a felhasználó mit szeretne megtudni. A <span class="strong"><strong>lekérdezőnyelv</strong></span> (<span class="strong"><strong>query language</strong></span>) lehet egyszerűen szavak listája (pl. [MI-könyv]); vagy meg lehet adni egymás mellett álló szavakból álló kifejezést (pl. [„MI-könyv”]); logikai operátorokat tartalmazhat (pl. [MI <span class="emphasis"><em>ÉS</em></span> könyv]), nem logikai operátorokat (például [MI <span class="emphasis"><em>KÖZELBEN</em></span> könyv] vagy [MI könyv <span class="emphasis"><em>CÍM</em></span>:www.aaai.org]) foglalhat magában.</p></li><li class="listitem"><p><span class="strong"><strong>Eredményhalmaz.</strong></span> Ez a dokumentumok azon részhalmaza, amit az IR a keresés alapján <span class="strong"><strong>releváns</strong></span>nak (<span class="strong"><strong>relevant</strong></span>) ítél. <span class="emphasis"><em>Relevánson</em></span> azt értjük, hogy valószínűleg hasznos lesz a kérdést feltevő személy számára, arra a bizonyos információigényre, amelyet a lekérdezésben fogalmazott meg.</p></li><li class="listitem"><p><span class="strong"><strong>Az eredményhalmaz megjelenítése.</strong></span> Ez lehet olyan egyszerű, mint a dokumentumcímek rendezett rangsorolt listája, vagy olyan bonyolult, mint az eredményhalmaz háromdimenziós térbe vetített, forgó színes térképe.</p></li></ul></div><p>Az előző fejezet elolvasása után gondolhatunk arra, hogy egy információkereső rendszert úgy is felépíthetünk, hogy a dokumentumhalmazt elemzés után leképezzük logikai mondatok tudásbázisába, majd elemezzük a kérdéseket, és <code class="code">MEGKÉRDEZ</code>-zük a tudásbázist, hogy a válaszokat megkapjuk. Sajnos senkinek sem sikerült így működő, nagyméretű IR-rendszert készítenie. Egyszerűen túl bonyolult olyan szókincset és nyelvtant építeni, amely képes nagy dokumentumhalmazokat lefedni, így minden IR-rendszer egyszerűbb nyelvi modellt használ.</p><p>A legkorábbi IR-rendszerek a <span class="strong"><strong>Boole-kulcsszó modell</strong></span> (<span class="strong"><strong>Boolean keyword model</strong></span>) szerint működtek. A dokumentumgyűjtemény minden egyes szavát úgy kezelik, mint egy Boole-tulajdonságot, amely igaz, ha a szó előfordul a dokumentumban, és hamis, ha nem. Azaz a „visszakeresés” tulajdonság igaz erre a fejezetre, de hamis a 15. fejezetre. A lekérdezőnyelv a tulajdonságok feletti logikai kifejezések nyelve. Például az [információkeresés <span class="emphasis"><em>ÉS</em></span> lekérdezés] lekérdezés igaz erre a fejezetre, de nem igaz a 15. fejezetre.</p><p>Ez a modell rendelkezik azzal az előnnyel, hogy könnyű elmagyarázni és megvalósítani. Azonban rendelkezik néhány hátránnyal is. Először, a dokumentum relevanciája egyetlen bit, így nincs semmilyen iránymutatás arra, hogy hogyan rendezzük a megjelenítés során a releváns dokumentumokat. Másodszor, a logikai kifejezések szokatlanok lehetnek a nem programozó vagy nem logikával foglalkozó felhasználók számára. Harmadszor, még egy gyakorlott felhasználó számára is nehéz lehet a megfelelő lekérdezést megfogalmazni. Tételezzük fel, hogy az [információkeresés <span class="emphasis"><em>ÉS</em></span> modellek <span class="emphasis"><em>ÉS</em></span> optimálás] kérdést tesszük fel, és üres eredményhalmazt kapunk vissza. Megpróbálhatjuk az [információkeresés <span class="emphasis"><em>VAGY</em></span> modellek <span class="emphasis"><em>VAGY</em></span> optimálás] lekérdezést, azonban ha túl sok eredményt ad vissza, akkor nehéz megmondani, mit kell utána kipróbálni.</p><p>A legtöbb IR-rendszer a szavak előfordulási statisztikájára (és esetleg más alacsony szintű jellemezőkre) épít. Bemutatunk egy valószínűségi keretrendszert, amely jól illeszkedik a tárgyalt nyelvi modellekhez. Az alapötlet az, hogy egy adott lekérdezéshez meg akarjuk találni azokat a dokumentumokat, amelyek relevánsak. Más szavakkal, ki akarjuk számolni a:</p><p><code class="code"><em><span class="remark">P</span></em>(<em><span class="remark">R = igaz</span></em>|<em><span class="remark">D</span></em>, <em><span class="remark">Q</span></em>)</code></p><p>értéket, amelyben <span class="emphasis"><em>D</em></span> a dokumentum, <span class="emphasis"><em>Q</em></span> a lekérdezés, <span class="emphasis"><em>R</em></span> pedig egy véletlen logikai változó, amely a relevanciát fejezi ki. Ha meghatároztuk ezt az értéket, alkalmazhatjuk a valószínűségi rendezési elvet, amely szerint amennyiben be kell mutatnunk az eredményhalmazt, akkor azt csökkenő valószínűségű relevancia szerint kell tennünk.</p><p>Számos lehetőség létezik a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>R = igaz</em></span>|<span class="emphasis"><em>D</em></span>, <span class="emphasis"><em>Q</em></span>) együttes eloszlás dekomponálására. Itt az ún. <span class="strong"><strong>nyelvi modellezés</strong></span> (<span class="strong"><strong>language modeling</strong></span>) megközelítést fogjuk bemutatni, amely minden egyes dokumentumra egy nyelvi modellt becsül, majd az adott dokumentum nyelvi modellje alapján minden egyes lekérdezésre kiszámítja a lekérdezés valószínűségét. Az <span class="emphasis"><em>R </em></span>= <span class="emphasis"><em>igaz</em></span> érték jelölésére <span class="emphasis"><em>r</em></span>-t használva, a következő alakra írhatjuk át a valószínűséget:</p><p><code class="code"><em><span class="remark">P</span></em>(<em><span class="remark">r</span></em>|<em><span class="remark">D</span></em>, <em><span class="remark">Q</span></em>) = <em><span class="remark">P</span></em>(<em><span class="remark">D</span></em>, <em><span class="remark">Q</span></em>|<em><span class="remark">r</span></em>)<em><span class="remark">P</span></em>(<em><span class="remark">r</span></em>)/<em><span class="remark">P</span></em>(<em><span class="remark">D</span></em>, <em><span class="remark">Q</span></em>)	(a Bayes-szabály alapján)</code></p><p><code class="code"><em><span class="remark">	= P</span></em>(<em><span class="remark">Q</span></em>,<em><span class="remark"> D</span></em>|<em><span class="remark">r</span></em>)<em><span class="remark">P</span></em>(<em><span class="remark">D</span></em>|<em><span class="remark">r</span></em>)<em><span class="remark">P</span></em>(<em><span class="remark">r</span></em>)/<em><span class="remark">PP</span></em>(<em><span class="remark">D</span></em>, <em><span class="remark">Q</span></em>)	(a láncszabály alapján)</code></p><p><code class="code">	=<em><span class="remark"> </span></em>α<em><span class="remark">P</span></em>(<em><span class="remark">Q</span></em>|<em><span class="remark">D</span></em>,<em><span class="remark">r</span></em>)<em><span class="remark">P</span></em>(<em><span class="remark">r</span></em>|<em><span class="remark">D</span></em>)/<em><span class="remark">P</span></em>(<em><span class="remark">D</span></em>, <em><span class="remark">Q</span></em>)	(a Bayes-szabály alapján, rögzített <em><span class="remark">D</span></em>-re)</code></p><p>Azt mondtuk, hogy a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>r</em></span>|<span class="emphasis"><em>D</em></span>,<span class="emphasis"><em> Q</em></span>) értékét akarjuk maximalizálni, azonban ezzel ekvivalens, ha a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>r</em></span>|<span class="emphasis"><em>D</em></span>,<span class="emphasis"><em> Q</em></span>)/<span class="emphasis"><em>P</em></span>(¬<span class="emphasis"><em>r</em></span>|<span class="emphasis"><em>D</em></span>,<span class="emphasis"><em> Q</em></span>) valószínűségi arányt maximalizáljuk. Azaz a dokumentumokat a következő pontszám alapján rangsorolhatjuk:</p><p><span class="inlinemediaobject"><img src="math/mi-23-0004.gif" alt="Információkeresés"/></span></p><p>Ennek az az előnye, hogy kiküszöböli a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>D</em></span>, <span class="emphasis"><em>Q</em></span>) tagot. Most pedig feltételezzük, hogy az irreleváns dokumentumokra a dokumentum független a lekérdezéstől. Más szavakkal, amennyiben egy dokumentum irreleváns egy adott lekérdezésre, akkor a dokumentum ismerete nem fog segíteni a lekérdezés meghatározásában. Ezt a lekérdezést a következő egyenlet írja le:</p><p><code class="code"><em><span class="remark">P</span></em>(<em><span class="remark">D</span></em>, <em><span class="remark">Q</span></em>|¬<em><span class="remark">r</span></em>) = <em><span class="remark">P</span></em>(<em><span class="remark">D</span></em>|¬<em><span class="remark">r</span></em>)<em><span class="remark">P</span></em>(<em><span class="remark">Q</span></em>|¬<em><span class="remark">r</span></em>)</code></p><p>Ezzel a feltételezéssel azt kapjuk, hogy:</p><p><span class="inlinemediaobject"><img src="math/mi-23-0005.gif" alt="Információkeresés"/></span></p><p>A <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>r</em></span>|<span class="emphasis"><em>D</em></span>)/<span class="emphasis"><em>P</em></span>(¬<span xml:lang="it" class="emphasis"><em>r</em></span>|<span class="emphasis"><em>D</em></span>) tényező a dokumentum relevanciájának lekérdezésfüggetlen valószínűsége. Ez a dokumentum minőségének mértéke: egyes dokumentumok <span class="emphasis"><em>bármely</em></span> lekérdezéshez relevánsak, mert a dokumentum egyszerűen magas színvonalú. Akadémiai környezetben született folyóiratcikkek esetén a relevancia a hivatkozások száma alapján becsülhető, míg weboldalak esetén az oldalra mutató hiperhivatkozások számát használhatjuk. Minden esetben nagyobb súlyt adhatunk azoknak a hivatkozásoknak, amelyek maguk is magas színvonalúak. A dokumentum kora szintén szerepelhet a lekérdezésfüggetlen relevancia becslésében.</p><p>Az első tényező – a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>Q</em></span>|<span class="emphasis"><em>D</em></span>, <span class="emphasis"><em>r</em></span>) – a lekérdezés valószínűsége, feltéve egy adott releváns dokumentumot. Hogy megbecsülhessük ezt a valószínűséget, egy nyelvi modellt kell választanunk, amely megadja, hogy milyen kapcsolatban állnak a lekérdezések a releváns dokumentumokkal. Az egyik népszerű választás a dokumentumok unigram szómodellel történő reprezentálása. Ez az információkeresésben úgy is ismert, mint a <span class="strong"><strong>szózsák</strong></span> (<span class="strong"><strong>bag o</strong></span><span class="strong"><strong>f words</strong></span>) modell, mivel a szavak dokumentumon belüli előfordulási gyakorisága az, ami számít, nem a sorrendjük. Ebben a modellben a „man bites dog” és a „dog bites man” (nagyon rövid) dokumentumok azonosan fognak viselkedni.<sup>[<a id="id774772" href="#ftn.id774772" class="footnote">245</a>]</sup> Világos, hogy <span class="emphasis"><em>eltérő</em></span> jelentésűek, azonban az is igaz, hogy mindketten relevánsak a kutyákat és a harapásokat tartalmazó lekérdezésekre. Ezek után, hogy kiszámolhassuk egy lekérdezés valószínűségét egy adott dokumentum esetében, egyszerűen össze kell szoroznunk a lekérdezésben található szavak valószínűségeit a dokumentum unigram modellnek megfelelően. Ez a lekérdezés <span class="strong"><strong>naiv Bayes</strong></span>- (<span class="strong"><strong>naive Bayes</strong></span>) modellje. <span class="emphasis"><em>Q<sub>j</sub></em></span>-vel jelölve a lekérdezés <span class="emphasis"><em>j</em></span>-edik szavát, azt kapjuk, hogy:</p><p><span class="inlinemediaobject"><img src="math/mi-23-0006.gif" alt="Információkeresés"/></span></p><p>Ez lehetővé teszi a következő egyszerűsítést: </p><p><span class="inlinemediaobject"><img src="math/mi-23-0007.gif" alt="Információkeresés"/></span></p><p>Végre készen állunk, hogy ezeket a matematikai modelleket egy példára alkalmazzuk. A 23.4. ábra a [Bayes informational retrieval model] ([Bayes információkeresés modell]) lekérdezés szavainak ennek a könyvnek öt kiválasztott fejezetéből álló dokumentumgyűjtemény feletti unigram statisztikáját adja meg. Feltesszük, hogy a fejezetek azonos minőségűek, így csak azt kell kiszámolnunk, hogy mennyi a lekérdezés valószínűsége az adott dokumentum esetén, minden egyes dokumentumra. Két alkalommal tesszük ezt meg, egyszer egy <span class="emphasis"><em>D<sub>i </sub></em></span>simítatlan maximum-likelihood becslővel, majd egy <span class="inlinemediaobject"><img src="math/mi-23-0008.gif" alt="Információkeresés"/></span> adj-hozzá-egyet simító becslőjű modellel. Azt tételeznénk fel, hogy egy ilyen keresésénél ez a fejezet lesz elsőnek rangsorolva, és valóban ez így is van mindkét modell szerint.</p><div class="figure"><a id="id774842"/><p class="title"><strong>23.4. ábra - A [Bayes information retrieval model] lekérdezés-valószínűségi IR-modellje a könyv első öt fejezetét tartalmazó dokumentumgyűjtemény felett. Megadjuk a szógyakoriságot mindegyik dokumentum-szó párra, és a szavak számát (<span class="emphasis"><em>N</em></span>) az összes dokumentumra. Két dokumentummodellt alkalmazunk, <span class="emphasis"><em>D<sub>i</sub></em></span> az <span class="emphasis"><em>i</em></span>-edik dokumentumon alapuló simítatlan unigram szómodell, míg <span class="emphasis"><em>D</em></span>'<sub>i</sub> ugyanaz a modell adj-hozzá-egyet simítással, majd kiszámítjuk a lekérdezés valószínűségét minden dokumentumra mindkét modellel. A jelen (23.) fejezet az egyértelmű győztes, mindkét modell esetén több mint kétszázszor valószínűbb, mint bármely más dokumentum.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/23-04.png" alt="A [Bayes information retrieval model] lekérdezés-valószínűségi IR-modellje a könyv első öt fejezetét tartalmazó dokumentumgyűjtemény felett. Megadjuk a szógyakoriságot mindegyik dokumentum-szó párra, és a szavak számát (N) az összes dokumentumra. Két dokumentummodellt alkalmazunk, Di az i-edik dokumentumon alapuló simítatlan unigram szómodell, míg D'i ugyanaz a modell adj-hozzá-egyet simítással, majd kiszámítjuk a lekérdezés valószínűségét minden dokumentumra mindkét modellel. A jelen (23.) fejezet az egyértelmű győztes, mindkét modell esetén több mint kétszázszor valószínűbb, mint bármely más dokumentum."/></div></div></div><p>A simított modell rendelkezik azzal az előnnyel, hogy kevésbé érzékeny a zajra, és hogy nemzérus relevancia-valószínűséget képes rendelni olyan dokumentumokhoz, amelyek nem tartalmazzák az összes szót. A simítatlan modellnek az az előnye, hogy könnyű sok dokumentumot tartalmazó gyűjteményekre kiszámolni: ha elkészítünk egy olyan indexet, amely megadja, hogy az adott szót mely dokumentumok tartalmazzák, akkor gyorsan elő tudjuk állítani az eredményhalmazt ezeknek a listáknak a metszeteként, és a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>Q</em></span>|<span class="emphasis"><em>D<sub>i</sub></em></span>) értékeket csak a metszetben szereplő dokumentumokra kell kiszámolni, nem pedig mindegyikre.</p><div class="section" title="Az IR-rendszerek értékelése"><div class="titlepage"><div><div><h2 class="title"><a id="id774887"/>Az IR-rendszerek értékelése</h2></div></div></div><p>Honnan tudjuk, hogy egy IR-rendszer jól teljesít? Elvégzünk egy kísérletet, amelyben a rendszer kap egy lekérdezéshalmazt, az eredményhalmazokat pedig pontozzuk az emberi relevanciamegítélés szerint. Tradicionálisan két mértéket használunk a pontozásra: a <span class="strong"><strong>felidézés</strong></span>t (<span class="strong"><strong>recall</strong></span>) és <span class="strong"><strong>pontosság</strong></span>ot (<span class="strong"><strong>precision</strong></span>). Ezeket egy példán keresztül fogjuk bemutatni. Képzeljük el, hogy egy IR-rendszer visszaadott egy eredményhalmazt egy olyan lekérdezésre, amelyre tudjuk, hogy egy 100 dokumentumot tartalmazó korpuszból mely dokumentumok relevánsak, és melyek nem. Az egyes kategóriákba tartozó dokumentumok számát az alábbi táblázat adja meg:</p><p><span class="inlinemediaobject"><img src="kepek/961-1.png" alt="Az IR-rendszerek értékelése"/></span></p><p>A <span class="strong"><strong>pontosság</strong></span> az eredményhalmaz dokumentumai közül a ténylegesen relevánsak arányát méri. A példánkban a pontosság 30/(30 + 10) = 0,75. A hamis pozitív arány 1 – 0,75 = 0,25. A <span class="strong"><strong>felidézés</strong></span> a gyűjtemény releváns dokumentumaiból az eredményhalmazban megjelenő hányadát méri. A példánkban a felidézés 30/(30 + 20) = 0,60. A hamis negatív arány 1 – 0,60 = 0,40. Egy nagyon nagy dokumentumgyűjteményben, mint például a világhálón, a felidézés nehezen számítható, mivel nincs egyszerű módszer a web összes oldalának a relevancia szempontjából történő elemzésére. A legjobb, amit tehetünk, a felidézés becslése mintavételezéssel, vagy pedig teljesen figyelmen kívül hagyjuk a felidézést, és csak a pontosság alapján ítélünk.</p><p>A rendszer kompromisszumot köthet a pontosság és felidézés között. Extrém esetben a rendszer visszaadhatja az összes dokumentumot a dokumentumgyűjteményből az eredményhalmazban, 100%-os felidézést garantálva, azonban a pontossága kicsi lesz. Alternatívaként, a rendszer visszaadhat egyetlen dokumentumot, így a felidézés alacsony lesz, azonban tűrhető esélye van 100%-os pontosságra. A kompromisszum összefoglalásának egyik lehetséges módja az <span class="strong"><strong>ROC-görbé</strong></span>vel (<span class="strong"><strong>ROC curve</strong></span>) történhet. Az „ROC” a „<span class="strong"><strong>vevő működési karakterisztika</strong></span>” (<span class="strong"><strong>receiver operating characteristics</strong></span>) rövidítése (ami nem túlzottan felvilágosító név). Ez egy olyan grafikon, amely a hamis negatív arányt méri az <span class="emphasis"><em>y</em></span> tengelyen és a hamis pozitív arányt az <span class="emphasis"><em>x</em></span> tengelyen, ábrázolva az egyes kompromisszumos pontokat. A görbe alatti terület az IR-rendszer hatékonyságának összefoglalása.</p><p>A felidézést és pontosságot akkor definiálták, amikor az IR-kereséseket elsődlegesen könyvtárosok végezték, akik alapos, pontos találatokban voltak érdekeltek. Manapság a legtöbb (napi több százmillió) lekérdezést az internetfelhasználók végzik, akik kevésbé érdekeltek az alaposságban, sokkal inkább abban, hogy azonnal választ kapjanak. Számukra jó mérték az első releváns találat átlagos <span class="strong"><strong>reciprokrang</strong></span>ja (<span class="strong"><strong>reciprocal rank</strong></span>). Azaz, amennyiben a rendszer első találata releváns, 1-es pontszámot kap a lekérdezésre, és amennyiben az első kettő nem releváns, de a harmadik az, akkor 1/3-ot. Egy alternatív mérték a <span class="strong"><strong>válaszidő</strong></span> (<span class="strong"><strong>time to answer</strong></span>), ami azt méri, hogy mennyi ideig tart a felhasználónak a problémára kívánt választ megtalálni. Ez kerül a legközelebb ahhoz, amit mérni szeretnénk, azonban azzal a hátránnyal rendelkezik, hogy minden egyes kísérlethez új emberi tesztalanycsoportra van szükség.</p></div><div class="section" title="Az IR-rendszerek továbbfejlesztése"><div class="titlepage"><div><div><h2 class="title"><a id="id774983"/>Az IR-rendszerek továbbfejlesztése</h2></div></div></div><p>Az unigram modell az összes szót függetlenként kezeli, azonban mi tudjuk, hogy bizonyos szavak korreláltak: a „dívány” közeli kapcsolatban áll mind a „díványok”-kal, mind a „kanapé”-val. Számos IR-rendszer próbálja figyelembe venni ezeket a korrelációkat.</p><p>Például, amennyiben a lekérdezés [dívány], gyalázatos lenne kihagyni az eredményhalmazból azokat a dokumentumokat, amelyek a „DÍVÁNY” vagy a „díványok” szavakat tartalmazzák, de a „dívány”-t nem. A legtöbb IR-rendszer <span class="strong"><strong>kisbetű-nagybetű konverzió</strong></span>t (<span class="strong"><strong>case folding</strong></span>) alkalmaz, hogy a „DÍVÁNY”-t „dívány” alakká alakítsa, számos rendszer pedig <span class="strong"><strong>szótövesítő</strong></span> (<span class="strong"><strong>stemming</strong></span>) algoritmusokat, hogy a „díványok” alakot a „dívány” szótőre redukálja. Ez tipikusan a felidézés kismértékű növekedését eredményezi (az angol nyelv esetén kb. 2%-ot). Azonban ronthatja a pontosságot. Például a „stocking” szótövesítése „stock”<sup>[<a id="id775012" href="#ftn.id775012" class="footnote">246</a>]</sup><sup> </sup> alakra valószínűleg csökkenteni fogja a ruházati, valamint pénzügyi eszközökre irányuló lekérdezések pontosságát, azonban növelheti a raktározásra irányuló lekérdezések felidézését. Szabályalapú szótövesítők (például az „-ing” végződés eltávolítása az angolban) nem képesek megkerülni ezt a problémát, de a szótárakon alapuló újabb algoritmusok igen (nem kell eltávolítani az „-ing” képzőt, ha a szó már szerepel a szótárban). Bár az angol nyelv esetén a szótövesítésnek csak kis hatása van, sokkal fontosabb más nyelvek esetén. A német nyelvben gyakran találkozhatunk olyan szavakkal, mint „Lebensversicherungsgesellschattsangestellter” (életbiztosító cég alkalmazottja). Az olyan nyelvek, mint a finn, a török, az inuit vagy a jupik rekurzív morfológiai szabályokkal rendelkeznek, amelyek elméletileg korlátlan hosszúságú szavakat generálnak.</p><p>A következő lépés a <span class="strong"><strong>szinonimá</strong></span>k (<span class="strong"><strong>synonym</strong></span>s) felismerése, mint amilyen a „dívány” és a „kanapé”. A szótövesítéshez hasonlóan ez is a felidézés kismértékű növekedését eredményezheti, azonban a pontosságot veszélyezteti, ha túl agresszíven alkalmazzuk. Akik Tim Couch futballistára kíváncsiak, nem szeretnének átvergődni a kanapékról (couch – kanapé) szóló dokumentumokon. Az a probléma, hogy „a nyelv ugyanúgy irtózik az abszolút szinonimáktól, mint ahogy a természet retteg a vákuumtól” (Cruse, 1986). Azaz, amennyiben két szó azonos dolgot jelent, a nyelv beszélői törekednek a jelentés módosítására, hogy megszüntessék a zűrzavart.</p><p>Számos IR-rendszer bizonyos mértékig szó <span class="strong"><strong>bigram</strong></span>okat használ, azonban csak néhányuk valósít meg egy teljes valószínűségi bigram modellt. A <span class="strong"><strong>helyesírás-javító</strong></span> (<span class="strong"><strong>spelling c</strong></span><span class="strong"><strong>orrection</strong></span>) eljárások alkalmazhatók mind a dokumentumok, mind a lekérdezések hibáinak javítására.</p><p>Végső finomításként az IR-rendszerek tökéletesíthetők <span class="strong"><strong>metaadat</strong></span>ok (<span class="strong"><strong>metadata</strong></span>) figyelembevételével, amelyek a dokumentum szövegén kívül álló adatok, mint például emberek által megadott kulcsszavak vagy dokumentumok közötti hypertext-hivatkozások.</p></div><div class="section" title="Az eredményhalmaz prezentálása"><div class="titlepage"><div><div><h2 class="title"><a id="id775068"/>Az eredményhalmaz prezentálása</h2></div></div></div><p>A valószínűségi rendezési elv szerint vegyünk egy eredményhalmazt, és a relevancia valószínűségének megfelelően sorba rendezve prezentáljuk a felhasználónak. Ennek akkor van értelme, ha a felhasználó az összes releváns dokumentum minél hamarább történő megtalálásban érdekelt. Azonban bajba kerül, mert nem veszi figyelembe a <span class="emphasis"><em>hasznosságot</em></span>. Például ha a legrelevánsabb dokumentum két példányban szerepel a gyűjteményben, akkor az első megnézése után a második azonos relevanciájú, de zérus hasznosságú. Számos IR-rendszer rendelkezik mechanizmusokkal, amelyek eliminálják az előző találatokhoz túlzottan hasonlító eredményeket.</p><p>Az IR-rendszerek teljesítménynövelésének egyik leghatékonyabb módja a <span class="strong"><strong>relevancia-visszacsatolás</strong></span> (<span class="strong"><strong>relevance feedback</strong></span>), amely a felhasználó visszajelzése, hogy az eredeti eredményhalmazból mely dokumentumok voltak relevánsak. A rendszer ezután egy második eredményhalmazt prezentálhat, amelynek dokumentumai hasonlók a megadottakhoz.</p><p>Egy másik lehetséges megközelítés az eredményhalmaznak egy rendezett lista helyett egy <span class="emphasis"><em>címkézett faként</em></span> történő prezentálása. A <span class="strong"><strong>dokumentumosztályozás</strong></span> (<span class="strong"><strong>document classification</strong></span>) során az eredményeket egy előre definiált témakör-taxonómiának megfelelően osztályozzuk. Például újsághírekből álló gyűjteményt a következő kategóriákba lehet sorolni: külföldi, belföldi, üzleti hírek, szórakozás és sport. <span class="strong"><strong>Dok</strong></span><span class="strong"><strong>umentumklaszterezés</strong></span> (<span class="strong"><strong>document clustering</strong></span>) esetén minden eredményhalmazra teljesen új kategóriafa készül. Az osztályozás akkor használható, ha a gyűjteményben kevés számú témakör található, míg a klaszterezést a világhálóhoz hasonló széles körű gyűjtemények esetén érdemes használni. Mindkét esetben, miután a felhasználó megad egy lekérdezést, az eredményhalmazt a kategóriáknak megfelelő mappákba rendezve kapja meg.</p><p>Az osztályozás felügyelt tanítási probléma, és mint ilyen, a 18. fejezetben ismertetett bármelyik módszerrel megtámadható. Az egyik népszerű megközelítés a döntési fák alkalmazása. Amennyiben rendelkezünk a megfelelő kategóriákkal címkézett dokumentumokból álló tanító halmazzal, építhetünk egyetlen döntési fát, amelynek levelei a dokumentumot a megfelelő kategóriához rendelik. Ez akkor működik jól, ha mindössze néhány kategória van; nagyobb kategóriahalmazok esetén minden egyes kategóriára külön döntési fát építünk, amelynek a levelei megadják, hogy a dokumentum az adott kategóriába tartozik-e vagy sem. Általában az egyes csomópontokban tesztelt tulajdonságok egyedi szavak. Például a „Sport” kategóriában az egyik csomópont tesztelheti a „kosárlabda” szó meglétét. Javított teljesítményű döntési fák, naiv Bayes-modellek, valamint szupport vektor gépek mindegyikét használták szövegosztályozásra, sok esetben a hitelesség 90–98%-os volt bináris osztályozás esetén.</p><p>A klaszterezés egy felügyelet nélküli tanítási módszer. A 20.3. alfejezetben láthattuk, hogy hogyan alkalmazható az EM algoritmus a klaszterezés eredeti becslésének javítására, Gauss-modellek keverékét használva. A dokumentumok klaszterezése nehezebb feladat, mert nem tudjuk, hogy az adatokat egy barátságos Gauss-modell generálta-e, és mert egy sokkal több dimenziós térrel kell elbánnunk. Számos megközelítést dolgoztak ki.</p><p>Az <span class="strong"><strong>agglomeratív klaszterezés</strong></span> (<span class="strong"><strong>agglomerative clustering</strong></span>) klaszterekből álló fát épít, lemenve egészen az egyedi dokumentumok szintjére. A fa bármely szinten nyeshető, hogy kevesebb kategóriát kapjunk, de ezt az algoritmuson kívül vesszük figyelembe. Az elején minden dokumentumot külön klaszternek tekintünk. Ezután megkeressük azt a két klasztert, melyek egy bizonyos távolságmérték szerint legközelebb állnak egymáshoz, és összevonjuk őket. Addig ismételjük a folyamatot, amíg csak egy klaszter marad. A két dokumentum távolságát meghatározó mérték a dokumentumok szavai közti átfedés valamilyen mértéke. Például reprezentálhatjuk a dokumentumot szógyakoriságok vektoraként, ahol a távolságot a két vektor euklideszi távolságaként értelmezzük. Két klaszter távolsága a klaszterek mediánjainak távolságaként értelmezhetjük, vagy a klaszterek elemeinek átlagos távolságát vehetjük figyelembe. Az agglomeratív klaszterezés időigénye <span class="emphasis"><em>O</em></span>(<span class="emphasis"><em>n</em></span><sup>2</sup>), ahol <span class="emphasis"><em>n</em></span> a dokumentumok száma.</p><p>A <span class="strong"><strong>k-közép klaszterezés</strong></span> (<span class="strong"><strong>k-means clustering</strong></span>) pontosan <span class="emphasis"><em>k</em></span> darab kategória halmazát állítja elő. A következő elven működik:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Vegyünk véletlenszerűen <span class="emphasis"><em>k</em></span> dokumentumot a <span class="emphasis"><em>k</em></span> kategória reprezentálására.</p></li><li class="listitem"><p>Rendeljünk minden dokumentumot a legközelebbi kategóriához.</p></li><li class="listitem"><p>Számoljuk ki minden egyes kategória átlagát, és használjuk a <span class="emphasis"><em>k</em></span> átlagot a <span class="emphasis"><em>k</em></span> kategóriák új értékeinek reprezentálására.</p></li><li class="listitem"><p>Ismételjük a 2-es és 3-as lépéseket, amíg konvergálnak.</p></li></ol></div><p>A <span class="emphasis"><em>k</em></span>-közép módszer <span class="emphasis"><em>O</em></span>(<span class="emphasis"><em>n</em></span>) időigényű, ez az egyetlen előnye az agglomeratív klaszterezéshez képest. Általában kevésbé pontos, mint az agglomeratív klaszterezés, bár egyesek szerint majdnem olyan hatékony (Steinbach és társai, 2000).</p><p>Az alkalmazott klaszterezési módtól függetlenül van még egy feladat, amit el kell végeznünk, mielőtt a klaszterezést az eredményhalmaz bemutatására használhatjuk: a klaszter jó leírásának megtalálása. Az osztályozás esetén a kategóriák előre definiáltak (például „jövedelmek”), míg a klaszterezés esetén ki kell találnunk a kategórianeveket. Az egyik választás a klaszter szempontjából reprezentatív szavak listájának használata. A másik lehetőség a klaszter középpontjához közel levő egyik dokumentum címének a használata.</p></div><div class="section" title="Az IR-rendszerek megvalósítása"><div class="titlepage"><div><div><h2 class="title"><a id="id775214"/>Az IR-rendszerek megvalósítása</h2></div></div></div><p>Az eddigiekben csupán absztrakt módon definiáltuk az IR-rendszerek működését, azonban nem magyaráztuk el, hogy hogyan lehet olyan hatékonnyá tenni őket, hogy egy webes keresőgép visszaadhassa a legfelső találatokat egy több milliárd oldalas gyűjteményből egytized másodperc alatt. Minden IR-rendszer számára két kulcsfontosságú adatstruktúra szükséges: a szókincs, amely felsorolja a dokumentumok szavait, és az invertált index, amely megadja, hogy az egyes szavak hol szerepelnek a dokumentumgyűjteményben.</p><p>A <span class="strong"><strong>szókincs</strong></span> (<span class="strong"><strong>lexicon</strong></span>) egy olyan adatstruktúra, amely egy műveletet támogat: megadja, hogy egy adott szó hol szerepel az invertált indexben, amely a szó előfordulásait tárolja. Egyes megvalósítások esetén azt is visszaadja, hogy összesen hány dokumentum tartalmazza a szót. A szókincset hash-tábla vagy valamilyen hasonló adatstruktúrával ajánlott megvalósítani, amely lehetővé teszi a gyors kikeresést. Egyes esetekben kis információtartalmú gyakori szavakat kihagynak a szókincsből. Ezek a <span class="strong"><strong>tiltólistás szavak</strong></span> (<span class="strong"><strong>stop words</strong></span>) (például „a”, „egy”, „ez” stb.) helyet foglalnak az indexben, és nem javítják az eredmény rangsorolását. Az egyetlen jó indok arra, hogy mégis megtartsuk őket a szókincsben a kifejezéslekérdezést támogató rendszerek esetén áll fenn: a tiltólistás szavak szókincsbeli tárolása szükséges olyan lekérdezések kiszolgálására, mint pl. a „to be or not to be”.<sup>[<a id="id775241" href="#ftn.id775241" class="footnote">247</a>]</sup></p><p>Az <span class="strong"><strong>invertált index</strong></span><sup>[<a id="id775256" href="#ftn.id775256" class="footnote">248</a>]</sup> (<span class="strong"><strong>inverted index</strong></span>), a könyvünk végén található szójegyzékhez hasonlóan, <span class="strong"><strong>találati listá</strong></span>k (<span class="strong"><strong>hit list</strong></span>s) halmazából – az egyes szavak előfordulási helyeiből – áll. A Boole-kulcsszó modell esetén a találati lista nem más, mint a dokumentumok listája. Az unigram modell esetén egy (dokumentum, gyakoriság) párokat tartalmazó lista. A kifejezéslekérdezés támogatásához a találati listának az adott szó minden egyes dokumentumon belüli előfordulási helyeit is tartalmaznia kell.</p><p>Amennyiben a lekérdezés egyetlen szó (Silverstein szerint ilyen az esetek 26%-a (Silverstein és társai, 1998)), akkor a feldolgozás igen gyors. Egyszerűen kikeressük a szót a szókincsből, hogy megkapjuk a találati lista címét, majd egy üres prioritási sort hozunk létre. Ezután egyesével végigmegyünk a találati lista dokumentumain, és megnézzük a szó gyakoriságát a dokumentumban. Amennyiben a prioritási sor <span class="emphasis"><em>R</em></span>-nél kevesebb elemet tartalmaz (ahol <span class="emphasis"><em>R</em></span> az eredményhalmaz elvárt mérete), akkor hozzáadjuk a (dokumentum, gyakoriság) párt a sorhoz. Ellenkező esetben, ha a gyakoriság nagyobb, mint a prioritási sor legkisebb elemének gyakorisága, akkor töröljük a legkisebb elemet, és hozzáadjuk az új (dokumentum, gyakoriság) párat. Ezáltal a lekérdezés megválaszolása <span class="emphasis"><em>O</em></span>(<span class="emphasis"><em>H</em></span> + <span class="emphasis"><em>R</em></span> log <span class="emphasis"><em>R</em></span>) időt vesz igénybe, ahol <span class="emphasis"><em>H</em></span> a találati lista dokumentumainak száma. Amennyiben a lekérdezés <span class="emphasis"><em>n</em></span> szót tartalmaz, akkor <span class="emphasis"><em>n</em></span> találati listát kell összevonni, ami <span class="emphasis"><em>O</em></span>(<span class="emphasis"><em>nH +</em></span> <span class="emphasis"><em>R</em></span> log <span class="emphasis"><em>R</em></span>) időt vesz igénybe.</p><p>Azért mutattuk be az IR-rendszerek elméletét a valószínűségi modellen keresztül, mert ez a modell hasznosítja azokat az ötleteket, amelyeket más témákban is alkalmaztunk. A jelenlegi gyakorlati IR-rendszerek sokkal inkább egy másik megközelítést alkalmaznak, amelyet <span class="strong"><strong>vektortér modell</strong></span>nek (<span class="strong"><strong>vector space model</strong></span>) hívunk. Ez a modell ugyanúgy a szózsák-megközelítést alkalmazza, mint a valószínűségi modell. Minden egyes dokumentumot unigram szógyakoriságok vektoraként ábrázolunk. A lekérdezést is így ábrázoljuk, például a [Bayes information retrieval model] lekérdezést a </p><p><code class="code">[0, …, 1, 0, …, 1, 0, …, 1, 0, …, 1, 0, …]</code></p><p>vektor írja le, amelyben az ötlet az, hogy minden egyes szóhoz külön dimenzió tartozik, és a lekérdezés vektorában minden dimenzió 0 értékű, kivéve azt a négy szót, amely a lekérdezésben előfordul. A releváns dokumentumokat úgy kapjuk meg, hogy megkeressük azokat a dokumentumokat, amelyek a lekérdezés vektorának legközelebbi szomszédai a vektortérben. A hasonlóság egyik lehetséges mértéke a lekérdezés- és dokumentumvektor skaláris szorzata: minél nagyobb ez a szorzat, annál közelebb van egymáshoz a két vektor. Algebrailag ez a mérték nagy pontszámot ad azoknak a szavaknak, amelyek mind a dokumentumokban, mind a lekérdezésben gyakran előfordulnak. Geometriailag a két vektor skaláris szorzata az általuk bezárt szög koszinusza, azaz ha két ilyen vektor koszinuszát maximalizáljuk (amennyiben azonos kvadránsban találhatók), akkor az általuk bezárt szög nullához közeli lesz.</p><p>A vektortér modell ennél sokkal többre képes. A gyakorlatban számos jellemzővel, finomítással, javítással és kiegészítéssel lett kibővítve. Az az alapötlet, miszerint a dokumentumokat a vektortérbeli hasonlóságuk alapján lehet rangsorolni, lehetővé teszi, hogy új ötleteket építsünk be a numerikus sorrendező rendszerbe. Egyesek azt állítják, hogy a valószínűségi modell ezeket a módosításokat sokkal tisztább elvi alapokon állva tenné lehetővé, azonban az IR-kutatók nem fognak váltani, amíg nem látnak egyértelmű teljesítményjavulást a másik modellhez képest.</p><p>Hogy egy átlagos IR-feladat indexelési problémájának nagyságrendjét érzékeltessük, vegyünk egy szabványos TREC (Text REtrieval Conference – Szöveg-visszakeresési Konferencia) dokumentumgyűjteményt, amely 750 ezer dokumentumot tartalmaz, öszszesen 2 GB (gigabájt) szöveggel. A szókincs körülbelül 500 ezer szót tartalmaz, szótövesítés és kisbetű-nagybetű konverzió után; ennyi szó tárolása 7 és 10 MB közötti tárterületet igényel. Az invertált index a (dokumentum, gyakoriság) párokkal 324 MB területet igényel, bár tömörítési technikák alkalmazásával csak 83 MB-ot. A tömörítés tárhelyet takarít meg, a feldolgozási követelmények kismértékű növelése árán. Azonban ha a tömörítés lehetővé teszi, hogy az egész indexet a memóriában – és nem háttértáron tároljuk –, akkor jelentős eredő teljesítménynövekedést kapunk. A kifejezéslekérdezés támogatása a tárigényt 1200 MB-ra növeli tömörítetlen, illetve 600 MB-ra tömörített esetben. A webes keresőgépek háromezerszer ekkora feladattal dolgoznak. A legtöbb probléma az esetükben is hasonló, azonban nem praktikus terabájtnyi mennyiségű adatot kezelni egyetlen számítógépen, ezért az indexet <span class="emphasis"><em>k</em></span> szegmensre vágják, és minden szegmenst külön számítógép tárol. A lekérdezést mindegyik számítógép megkapja, majd a <span class="emphasis"><em>k</em></span> eredményhalmazt egy eredményhalmazba vonják össze, amelyet megjelenítenek a felhasználó számára. A webes keresőgépeknek ráadásul másodpercenként több ezer lekérdezést kell kiszolgálniuk, így a <span class="emphasis"><em>k</em></span> számítógép <span class="emphasis"><em>n</em></span> másolatára van szükség. Az idő folyamán <span class="emphasis"><em>k</em></span> és <span class="emphasis"><em>n</em></span> folyamatosan növekszik.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id774772" href="#id774772" class="para">245</a>] </sup> „Egy kutya megharapott egy embert”, illetve „egy ember megharapott egy kutyát”, jellemző újságcímstílus. (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id775012" href="#id775012" class="para">246</a>] </sup> Harisnya, illetve raktárkészlet. (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id775241" href="#id775241" class="para">247</a>] </sup> lenni vagy nem lenni (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id775256" href="#id775256" class="para">248</a>] </sup> Az „invertált index” kifejezés redundáns, sokkal jobb lenne egyszerűen az „index” kifejezést használni. Azért invertált, mert más sorrendben van, mint a szöveg szavai, de ilyen minden index. Azonban az „invertált index” a hagyományos IR-kifejezés.</p></div></div></div></body></html>
