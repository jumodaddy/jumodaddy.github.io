<?xml version="1.0" encoding="UTF-8" standalone="no"?>

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="section" title="Neurális hálók"><div class="titlepage"><div><div><h1 class="title"><a id="id743139"/>Neurális hálók</h1></div></div></div><p>A <span class="strong"><strong>neuron</strong></span> egy olyan agysejt, amelynek alapfeladata elektromos jelek összegyűjtése, feldolgozása és szétterjesztése. A <a class="xref" href="ch01s02.md#ID_42_oldal">„Neurális tudományok (1861-től napjainkig)”</a> részben az 1.2. ábra egy tipikus neuron sematikus rajzát mutatja. Azt gondoljuk, hogy az agy információfeldolgozó kapacitása elsősorban ilyen neuronok <span class="emphasis"><em>hálózatából</em></span> alakul ki. Ezért a korai MI néhány kutatása mesterséges <span class="strong"><strong>neurális háló</strong></span>k (<span class="strong"><strong>neural network</strong></span>s) létrehozására irányult. (A terület más, szintén használt elnevezései: <span class="strong"><strong>konnekcionizmus</strong></span> [<span class="strong"><strong>connectionism</strong></span>], <span class="strong"><strong>párhuzamos elosztott feldolgozás</strong></span> [<span class="strong"><strong>parallel distributed processing</strong></span>] és <span class="strong"><strong>neurális számítástechnika</strong></span> [<span class="strong"><strong>neural </strong></span><span class="strong"><strong>computation</strong></span>].) A 20.15. ábra a neuron egyszerű matematikai modelljét mutatja, ahogy McCulloch és Pitts (McCulloch és Pitts, 1943) megalkották. Elnagyolva az mondható, hogy a neuron akkor „tüzel”, amikor a bemeneti értékek súlyozott összege meghalad egy küszöböt. 1943 óta sokkal részletesebb és valósághűbb modelleket alkottak mind a neuronra, mind az agy nagyobb rendszereire, ez vezetett a <span class="strong"><strong>számítógépes idegháló-modellezés</strong></span> (<span class="strong"><strong>computational neuroscience</strong></span>) modern tudományterületének megjelenéséhez. Másrészt az MI és a statisztika kutatóinak érdeklődését felkeltették a neurális hálózatok absztraktabb tulajdonságai, mint például az elosztott számítás elvégzésére, a bemeneti zajjal szembeni érzéketlenségre és a tanulásra való képesség. Bár ma már tudjuk, hogy más rendszerek, például a Bayes-hálók is rendelkeznek ezekkel a tulajdonságokkal, de a neurális háló maradt a tanuló rendszerek egyik leghatékonyabb és legnépszerűbb formája, ezért megéri külön tárgyalni.</p><div class="figure"><a id="id743210"/><p class="title"><strong>20.15. ábra - A neuron egyszerű matematikai modellje. Az egység kimeneti aktivációja <span class="inlinemediaobject"><img src="math/mi-20-0030.gif" alt="A neuron egyszerű matematikai modellje. Az egység kimeneti aktivációja ahol aj a j-edik egység kimeneti aktivációja és Wj,i a j-től i-ig vezető összeköttetés súlya."/></span> ahol <span class="emphasis"><em>a<sub>j</sub></em></span> a <span class="emphasis"><em>j</em></span>-edik egység kimeneti aktivációja és <span class="emphasis"><em>W</em></span><sub><span class="emphasis"><em>j</em></span>,<span class="emphasis"><em>i</em></span></sub> a <span class="emphasis"><em>j</em></span>-től <span class="emphasis"><em>i</em></span>-ig vezető összeköttetés súlya.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-15.png" alt="A neuron egyszerű matematikai modellje. Az egység kimeneti aktivációja ahol aj a j-edik egység kimeneti aktivációja és Wj,i a j-től i-ig vezető összeköttetés súlya."/></div></div></div><div class="section" title="A neurális háló egységei"><div class="titlepage"><div><div><h2 class="title"><a id="id743256"/>A neurális háló egységei</h2></div></div></div><p>A neurális hálók irányított <span class="strong"><strong>kapcsolat</strong></span>okkal (<span class="strong"><strong>link</strong></span>) összekötött csomópontokból vagy <span class="strong"><strong>egy</strong></span><span class="strong"><strong>ség</strong></span>ekből (<span class="strong"><strong>unit</strong></span>) állnak. A <span class="emphasis"><em>j</em></span>-edik egységtől az <span class="emphasis"><em>i</em></span>-edik felé vezető kapcsolat hivatott az <span class="emphasis"><em>a<sub>j</sub></em></span> aktivációt <span class="emphasis"><em>j</em></span>-től az <span class="emphasis"><em>i</em></span>-ig terjeszteni. Minden egyes kapcsolat rendelkezik egy hozzá aszszociált <span class="emphasis"><em>W</em></span><sub><span class="emphasis"><em>j</em></span>,<span class="emphasis"><em>i</em></span></sub> numerikus <span class="strong"><strong>súllyal</strong></span> <span class="strong"><strong>(weight</strong></span>), ami meghatározza a kapcsolat erősségét és előjelét. Minden egyes <span class="emphasis"><em>i</em></span> egység először a bemeneteinek egy súlyozott összegét számítja ki:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0031.gif" alt="A neurális háló egységei"/></span></p><p>A kimenetét úgy kapja, hogy ezek után egy <span class="emphasis"><em>g</em></span> <span class="strong"><strong>aktivációs függvény</strong></span>t (<span class="strong"><strong>activation functio</strong></span><span class="strong"><strong>n</strong></span>) alkalmaz a kapott összegre:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0032.gif" alt="A neurális háló egységei"/></span></p><p>Figyeljük meg, hogy használtunk egy <span class="strong"><strong>eltolássúly</strong></span>t <span class="strong"><strong>(bias weight)</strong></span> <span class="emphasis"><em>W</em></span><sub>0,<span class="emphasis"><em>i</em></span></sub>-t, amelyet egy rögzített értékű <span class="emphasis"><em>a</em></span><sub>0</sub> = –1 bemenetre kapcsolunk. Rövidesen megmagyarázzuk, hogy mi a jelentősége.</p><p>Az aktivációs függvénnyel szemben két elvárásunk van. Először az, hogy az egység legyen „aktív” (+1 körüli kimenet), ha a „helyes” bemeneteket kapja, és „inaktív” (0 körüli kimenet), ha „rossz” bemeneteket kap. Másodszor az, hogy az aktiváció legyen <span class="emphasis"><em>nemlineáris</em></span>, különben az egész neurális háló egy egyszerű lineáris függvénnyé fajul (lásd 20.17. feladat). A 20.16. ábra kétféle aktivációs függvényt mutat be: a <span class="strong"><strong>küszöbfüggvény</strong></span>t (<span class="strong"><strong>threshold function</strong></span>), illetve a <span class="strong"><strong>szigmoid függvény</strong></span>t (<span class="strong"><strong>sigmoid function</strong></span>) (mely utóbbi <span class="strong"><strong>logisztikus függvény</strong></span>ként [<span class="strong"><strong>logistic function</strong></span>] is ismert). A szigmoid függvény előnye, hogy differenciálható, ami – mint később látni fogjuk – fontos a súlytanulási algoritmus szempontjából. Vegyük észre, hogy mindkét függvénynek van egy küszöbpontja (akár kemény, akár lágy) a nullánál; az eltolássúly állítja be az egység <span class="emphasis"><em>aktuális</em></span> küszöbpontját. Ez azt jelenti, hogy az egység akkor aktiválódik, ha a „valódi” bemenetek súlyozott összege <span class="inlinemediaobject"><img src="math/mi-20-0033.gif" alt="A neurális háló egységei"/></span> meghaladja <span class="emphasis"><em>W</em></span><sub>0,<span class="emphasis"><em>i</em></span></sub>-t.</p><div class="figure"><a id="id743449"/><p class="title"><strong>20.16. ábra - (a) A <span class="strong">küszöb</span> aktivációs függvény, amely 1-et ad a kimeneten, ha a bemenete pozitív, különben pedig 0-t. (Néha az előjelfüggvényt is használják ehelyett, amely ±1-et ad a bemenet előjelétől függően.) (b) A <span class="strong">szigmoid</span> függvény 1/(1+<span class="emphasis"><em>e</em></span><sup>–<span class="emphasis"><em>x</em></span></sup>).</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-16.png" alt="(a) A küszöb aktivációs függvény, amely 1-et ad a kimeneten, ha a bemenete pozitív, különben pedig 0-t. (Néha az előjelfüggvényt is használják ehelyett, amely ±1-et ad a bemenet előjelétől függően.) (b) A szigmoid függvény 1/(1+e–x)."/></div></div></div><div class="figure"><a id="id743476"/><p class="title"><strong>20.17. ábra - Megfelelő bemeneti és eltolássúlyokkal rendelkező, küszöbaktivációjú egységek képesek logikai kapuként működni</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-17.png" alt="Megfelelő bemeneti és eltolássúlyokkal rendelkező, küszöbaktivációjú egységek képesek logikai kapuként működni"/></div></div></div><p class="Tartalom3">Némi fogalmunk alakulhat ki az egyes egységek működéséről, ha összehasonlítjuk őket a logikai kapukkal. Az egyes egységek tervezésének eredeti motivációi között (McCulloch és Pitts, 1943) szerepelt az, hogy képesek az alapvető logikai függvények reprezentálására. A 20.17. ábra bemutatja, hogy az és, vagy és nem logikai függvények hogyan reprezentálhatók egy megfelelő súlyokkal rendelkező küszöbegység segítségével. Ez azért fontos, mert azt jelenti, hogy ezen egységek felhasználásával tetszőleges logikai függvény kiszámítására tudunk hálózatot építeni.</p></div><div class="section" title="Hálóstruktúrák"><div class="titlepage"><div><div><h2 class="title"><a id="id743490"/>Hálóstruktúrák</h2></div></div></div><p>A neurális hálóstruktúrák két fő csoportja: a hurokmentes vagy <span class="strong"><strong>előrecsatolt háló</strong></span>k (<span class="strong"><strong>feed-forward network</strong></span>) és a visszacsatolt vagy <span class="strong"><strong>rekurrens háló</strong></span>k (<span class="strong"><strong>recurrent network</strong></span>). Az előrecsatolt háló a pillanatnyi bemenet függvényét reprezentálja, azaz nincs semmilyen más belső állapota, csak maguk a súlyok. A rekurrens háló viszont a kimeneteit visszacsatolja a bemeneteire. Ez azt jelenti, hogy a háló aktivációs szintjei dinamikus rendszert alkotnak, elérhetnek stabil állapotot, de mutathatnak oszcillációt, sőt kaotikus viselkedést is. Ezenfelül a háló egy adott bemenetre adott válasza a kezdeti állapotától függ, amely a korábbi bemenetektől függhet. Ennélfogva a rekurrens hálók (ellentétben az előrecsatolt hálókkal) rövid távú memóriát is biztosíthatnak. Ezáltal érdekesebbé válnak mint agymodellek, de egyben nehezebben is érthetők. Ez a rész az előrecsatolt hálókra koncentrál, a fejezet végén néhány hivatkozást adunk, segítve a rekurrens hálók további tanulmányozását.</p><p>Nézzük meg közelebbről azt az állítást, hogy az előrecsatolt háló a bemeneteinek függvényét reprezentálja. Vizsgáljuk a 20.18. ábra egyszerű hálózatát, amelynek két bemeneti egysége, két <span class="strong"><strong>rejtett egység</strong></span>e (<span class="strong"><strong>hidden unit</strong></span>) és egy kimeneti egysége van. (Az egyszerűség kedvéért ebben a példában elhagytuk az eltolásegységeket.) Adott <span class="strong"><strong>x</strong></span> = (<span class="emphasis"><em>x</em></span><sub>1</sub>, <span class="emphasis"><em>x</em></span><sub>2</sub>) bemeneti vektor esetén a bemeneti egységek aktivációja (<span class="emphasis"><em>a</em></span><sub>1</sub>, <span class="emphasis"><em>a</em></span><sub>2</sub>)  = (<span class="emphasis"><em>x</em></span><sub>1</sub>, <span class="emphasis"><em>x</em></span><sub>2</sub>), és a hálózat a következő számítást végzi:</p><p><code class="code"><em><span class="remark">a</span></em><sub>5</sub> = <em><span class="remark">g</span></em>(<em><span class="remark">W</span></em><sub>3,5</sub><em><span class="remark">a</span></em><sub>3</sub> + <em><span class="remark">W</span></em><sub>4,5</sub><em><span class="remark">a</span></em><sub>4</sub>) </code></p><p><code class="code">     = <em><span class="remark">g</span></em>(<em><span class="remark">W</span></em><sub>3,5</sub><em><span class="remark">g</span></em>(<em><span class="remark">W</span></em><sub>1,3</sub><em><span class="remark">a</span></em><sub>1</sub> + <em><span class="remark">W</span></em><sub>2,3</sub><em><span class="remark">a</span></em><sub>2</sub>) + <em><span class="remark">W</span></em><sub>4,5</sub><em><span class="remark">g</span></em>(<em><span class="remark">W</span></em><sub>1,4</sub><em><span class="remark">a</span></em><sub>1</sub> + <em><span class="remark">W</span></em><sub>2,4</sub><em><span class="remark">a</span></em><sub>2</sub>))					(20.11)</code></p><p>Azaz kifejezve a rejtett egységek kimenetét, mint a <span class="emphasis"><em>saját</em></span> bemeneteik függvényét, megmutattuk, hogy az egész háló <span class="emphasis"><em>a</em></span><sub>5</sub> végső kimenete a háló bemeneteinek függvénye. Továbbá azt látjuk, hogy a háló súlyai ennek a függvénynek a <span class="emphasis"><em>paramétereiként</em></span> szolgálnak; ha <span class="strong"><strong>W</strong></span>-vel jelöljük a paramétereket, akkor a háló a <span class="emphasis"><em>h</em></span><sub>W</sub>(<span class="strong"><strong>x</strong></span>) függvényt számítja ki. Ha változtatjuk a súlyokat, akkor változik a háló által reprezentált függvény. Ez a módja a neurális hálók tanulásának.</p><p class="Tartalom3">A neurális hálót osztályozásra vagy regresszióra használhatjuk. Ha folytonos kimenete van a hálónak (pl. szigmoid egységekkel), akkor logikai osztályozás esetén hagyományosan egy kimeneti egységet használunk, és ha ennek aktivációs értéke 0,5 feletti, azt az egyik, ha 0,5 alatti, akkor a másik osztályba tartozásként interpretáljuk. Egy <span class="emphasis"><em>k</em></span> osztályos osztályozási feladatnál feloszthatjuk az egyetlen kimeneti egység értéktartományát <span class="emphasis"><em>k</em></span> részre, de megszokottabb, hogy ehelyett <span class="emphasis"><em>k</em></span> elkülönült kimeneti egységet használjunk, ahol mindegyiknek az aktivációs értéke a bemenet adott osztályba tartozásának valószínűségét reprezentálja.</p><p class="Tartalom3">Az előrecsatolt hálókat rendszerint <span class="strong"><strong>réteg</strong></span>ekbe (<span class="strong"><strong>layer</strong></span>) szervezzük oly módon, hogy minden egyes egység csak a közvetlenül megelőző réteg egységeitől kap bemeneti jelet. A következő két alfejezetben egyrészt az egyrétegű hálózatokkal foglalkozunk, amelyeknek nincsenek rejtett egységei, másrészt a többrétegű hálókkal, amelyek egy vagy több rejtett réteggel rendelkeznek.</p><div class="figure"><a id="id746244"/><p class="title"><strong>20.18. ábra - Egy nagyon egyszerű, két bemeneti egységgel, egyetlen – két egységből álló – rejtett réteggel és egy kimeneti egységgel rendelkező háló</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-18.png" alt="Egy nagyon egyszerű, két bemeneti egységgel, egyetlen – két egységből álló – rejtett réteggel és egy kimeneti egységgel rendelkező háló"/></div></div></div></div><div class="section" title="Egyrétegű előrecsatolt neurális hálók (perceptronok)"><div class="titlepage"><div><div><h2 class="title"><a id="id746254"/>Egyrétegű előrecsatolt neurális hálók (perceptronok)</h2></div></div></div><p>Azt a hálót, amelyben az összes bemenet közvetlenül a kimenetekre kapcsolódik <span class="strong"><strong>egyrétegű neurális háló</strong></span>nak (<span class="strong"><strong>single layer neural network</strong></span>) vagy <span class="strong"><strong>perceptron</strong></span> (<span class="strong"><strong>perceptron</strong></span>) hálónak nevezzük. Mivel mindegyik kimeneti egység független a többitől – mindegyik súly csak egyetlen kimenetre van hatással – vizsgálatainkat korlátozhatjuk az egykimenetű perceptronra, mint azt a 20.19. (a) ábra magyarázza.</p><p>Kezdjük annak a hipotézistérnek a tanulmányozásával, amelyet egyetlen perceptron reprezentálhat. Küszöbaktivációs függvény esetén úgy tekinthetjük a perceptront, mint ami logikai függvényt reprezentál. Az elemi logikai függvényeken (és, vagy és nem, lásd 20.17. ábra) túl a perceptron képes néhány egészen „bonyolult” logikai függvényt is nagyon tömören reprezentálni. Például a <span class="strong"><strong>többségfüggvény</strong></span>t (<span class="strong"><strong>majority function</strong></span>), amely csak akkor ad ki 1-et, ha <span class="emphasis"><em>n</em></span> bemeneteinek több mint fele 1, egy olyan perceptron reprezentál, amelynek minden súlya <span class="emphasis"><em>W<sub>j</sub> </em></span> = 1 és a küszöb <span class="emphasis"><em>W</em></span><sub>0</sub> = <span class="emphasis"><em>n/</em></span>2. Egy döntési fának <span class="emphasis"><em>O</em></span>(2<sup>n</sup>) csomópontra lenne szüksége ennek a függvénynek a reprezentálásához.</p><p class="Tartalom3">Sajnos számos olyan logikai függvény van, amelyet a küszöbfüggvényt használó perceptron nem tud reprezentálni. A (20.10) egyenletet vizsgálva látjuk, hogy a küszöbérték-perceptron akkor és csak akkor ad 1-et, ha bemeneteinek (beleértve az eltolás- bemenetet is) súlyozott összege pozitív:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0034.gif" alt="Egyrétegű előrecsatolt neurális hálók (perceptronok)"/></span></p><div class="figure"><a id="id746332"/><p class="title"><strong>20.19. ábra - (a) Egy perceptronhálózat három kimeneti egységből, amelyeknek öt közös bemenete van. Ha kiválasztunk egy kimeneti egységet (mondjuk a másodikat, vastag vonallal kiemelve), akkor azt látjuk, hogy bemeneti összeköttetései nincsenek semmilyen hatással a többi kimeneti egységre. (b) Egy kétbemenetű szigmoid aktivációs függvényű perceptronegység kimenetének ábrázolása.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-19.png" alt="(a) Egy perceptronhálózat három kimeneti egységből, amelyeknek öt közös bemenete van. Ha kiválasztunk egy kimeneti egységet (mondjuk a másodikat, vastag vonallal kiemelve), akkor azt látjuk, hogy bemeneti összeköttetései nincsenek semmilyen hatással a többi kimeneti egységre. (b) Egy kétbemenetű szigmoid aktivációs függvényű perceptronegység kimenetének ábrázolása."/></div></div></div><div class="important" title="Fontos" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Fontos</h3><p>A <span class="strong"><strong>W </strong></span>· <span class="strong"><strong>x</strong></span> = 0 egyenlet egy hipersíkot határoz meg a bemeneti térben, tehát a perceptron akkor és csak akkor ad 1-et, ha a bemenet ennek a hipersíknak az egyik oldalán van. Ezért a küszöbperceptront <span class="strong"><strong>lineáris szeparátor</strong></span>nak (<span class="strong"><strong>linear separator</strong></span>) is nevezik. A 20.20. (a) és (b) ábra mutatja a szeparáló hipersíkot (ami két dimenzióban egy egyenes) a kétbemenetű és, illetve vagy függvények perceptronreprezentációja esetén. Fekete pötty jelzi a bemeneti tér olyan pontjait, amelyekre a függvény értéke 1, fehér pötty pedig az olyan pontokat, amelyre 0 ez az érték. A perceptron azért képes reprezentálni ezt a függvényt, mert létezik olyan egyenes, ami az összes fehér pontot az összes feketétől elválasztja. Az ilyen függvényeket <span class="strong"><strong>lineárisan szeparálható</strong></span>nak (<span class="strong"><strong>linearly separable</strong></span>) nevezzük. A 20.20. (c) ábra egy olyan függvényre mutat példát, amely <span class="emphasis"><em>nem</em></span> szeparálható lineárisan – ez az xor függvény. Nyilvánvalóan nincs lehetőség arra, hogy egy küszöbperceptron megtanulja ezt a függvényt. Általánosságban elmondható, hogy <span class="emphasis"><em>egy küszöbperceptron csak lineárisan szeparálható függvények reprezentációjára képes</em></span>. Ez a függvényeknek csak kis töredékét jelenti; a 20.14. feladat azt kéri, hogy fejezze ki számszerűen, mekkora is ez a töredék. A szigmoiddal felépített perceptronok hasonlóképpen korlátozott képességűek abban az értelemben, hogy csupán „lágy” lineáris szeparátorokat reprezentálnak. (Lásd 20.19. (b) ábra.)</p></div><div class="figure"><a id="id746381"/><p class="title"><strong>20.20. ábra - Lineáris szeparálhatóság küszöbperceptronok esetén. Fekete pötty jelzi a bemeneti tér olyan pontjait, amelyekre a függvény értéke 1, fehér pötty pedig az olyan pontokat, amelyre 0 ez az érték. A perceptronkimenet az egyenes nem árnyékolt oldalán 1. A (c) esetben nincs olyan egyenes, amely jól osztályozná a bemeneteket.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-20.png" alt="Lineáris szeparálhatóság küszöbperceptronok esetén. Fekete pötty jelzi a bemeneti tér olyan pontjait, amelyekre a függvény értéke 1, fehér pötty pedig az olyan pontokat, amelyre 0 ez az érték. A perceptronkimenet az egyenes nem árnyékolt oldalán 1. A (c) esetben nincs olyan egyenes, amely jól osztályozná a bemeneteket."/></div></div></div><div class="important" title="Fontos" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Fontos</h3><p>Korlátozott kifejezőképessége ellenére a küszöbperceptronnak vannak előnyei is. Különösen is fontos, hogy <span class="emphasis"><em>létezik olyan egyszerű tanuló algoritmus, amely a küszöbperceptront tetszőleges lineárisan szeparálható adathalmazra képes illeszteni</em></span>. Mégsem mutatjuk most be ezt, inkább <span class="emphasis"><em>levezetünk</em></span> egy ehhez közel álló tanuló algoritmust a szigmoid perceptronokra.</p></div><p>Ennek az algoritmusnak az az alapgondolata (valójában a neuronháló tanuló algoritmusok legtöbbjének is ez), hogy a tanító mintahalmazon mért hiba valamilyen mértékének minimalizálása érdekében módosítjuk a neuronháló súlyait. Tehát a tanulást formálisan a <span class="strong"><strong>súlytér</strong></span>ben (<span class="strong"><strong>weight space</strong></span>) végzett optimalizálási keresésként fogalmazzuk meg.<sup>[<a id="id746413" href="#ftn.id746413" class="footnote">202</a>]</sup> A hiba „klasszikus” mértéke a <span class="strong"><strong>négyzetes hibaösszeg</strong></span>, amit a lineáris regressziónál a <a class="xref" href="ch20s02.md#ID_826_827_oldal">„Maximum-likelihood paramétertanulás: folytonos eset”</a> részben is használtunk. Egyetlen, <span class="strong"><strong>x</strong></span> bemenettel és <span class="emphasis"><em>y</em></span> kívánt kimenettel megadott példa négyzetes hibája a következőképpen írható fel:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0035.gif" alt="Lineáris szeparálhatóság küszöbperceptronok esetén. Fekete pötty jelzi a bemeneti tér olyan pontjait, amelyekre a függvény értéke 1, fehér pötty pedig az olyan pontokat, amelyre 0 ez az érték. A perceptronkimenet az egyenes nem árnyékolt oldalán 1. A (c) esetben nincs olyan egyenes, amely jól osztályozná a bemeneteket."/></span></p><p>ahol <span class="emphasis"><em>h</em></span><sub>W</sub>(<span class="strong"><strong>x</strong></span>) a perceptron kimeneti értéke.</p><p>A négyzetes hiba csökkentésére gradiensalapú optimalizálási eljárást használhatunk, ehhez az <span class="emphasis"><em>E</em></span> minden egyes súlyra vonatkozó parciális deriváltját meg kell határoznunk. Tehát:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0036.gif" alt="Lineáris szeparálhatóság küszöbperceptronok esetén. Fekete pötty jelzi a bemeneti tér olyan pontjait, amelyekre a függvény értéke 1, fehér pötty pedig az olyan pontokat, amelyre 0 ez az érték. A perceptronkimenet az egyenes nem árnyékolt oldalán 1. A (c) esetben nincs olyan egyenes, amely jól osztályozná a bemeneteket."/></span></p><p>ahol <span class="emphasis"><em>g</em></span>' az aktivációs függvény deriváltja.<sup>[<a id="id746477" href="#ftn.id746477" class="footnote">203</a>]</sup> Amikor a gradiensalapú algoritmusban <span class="emphasis"><em>csökkenteni </em></span>akarjuk <span class="emphasis"><em>E</em></span>-t, a súlyfrissítés összefüggése a következő:</p><p><code class="code"><em><span class="remark">W<sub>j</sub> </span></em>← <em><span class="remark">W<sub>j</sub> </span></em>+ <em><span class="remark">α</span></em> × <em><span class="remark">Err</span></em> × <em><span class="remark">g</span></em>'(<em><span class="remark">in</span></em>) × <em><span class="remark">x<sub>j</sub></span></em>					(20.12)</code></p><p>ahol <span class="emphasis"><em>α</em></span> a <span class="strong"><strong>bátorsági faktor</strong></span> (vagy <span class="strong"><strong>tanulási faktor</strong></span>, <span class="strong"><strong>learning rate</strong></span>). Intuitíve ez nagyon ésszerű. Ha a hiba <span class="emphasis"><em>Err</em></span> = <span class="emphasis"><em>y</em></span> – <span class="emphasis"><em>h</em></span><sub>W</sub>(<span class="strong"><strong>x</strong></span>) pozitív, akkor a háló kimenete túl kicsi, tehát a pozitív bemenetekhez tartozó súlyokat <span class="emphasis"><em>növeljük,</em></span> a negatívakhoz tartozókat pedig <span class="emphasis"><em>csökkentjük</em></span>. Ha a hiba negatív, akkor éppen ennek ellenkezője történik.<sup>[<a id="id746583" href="#ftn.id746583" class="footnote">204</a>]</sup></p><p>A teljes algoritmus a 20.21. ábrán látható. Egyesével sorban végigfuttatja a mintákat a hálón, és minden egyes példa után a hiba csökkentése érdekében kissé módosítja a súlyokat. A mintahalmaz egyszeri végigfuttatását <span class="strong"><strong>epoch</strong></span>nak (<span class="strong"><strong>epoch</strong></span>) nevezzük. Az epochokat addig ismételjük, amíg valamilyen leállási feltétel nem teljesül – tipikus, hogy akkor állunk le, amikor a súlyváltozások már nagyon kicsivé válnak. Más módszerek esetén eredő gradienst számítunk az egész tanító halmazra, egyszerűen összeadva az egyes példáknál a (20.12) származó gradienseket, és az eredő gradiens alapján frissítjük a súlyokat. A <span class="strong"><strong>sztochasztikus gradiens</strong></span> (<span class="strong"><strong>stochastic gradient</strong></span>) módszer nem ciklikusan veszi a tanító halmaz mintáit, hanem inkább véletlenszerűen választ mintákat a tanító halmazból.</p><p>A 20.22. ábra két különböző problémára bemutatja a perceptron tanulási görbéjét. A bal oldali ábrán a 11 logikai bemenetre vonatkozó többségfüggvény (tehát a kimenet akkor 1, ha 6 vagy több bemenet 1) tanulási görbéje látható. Várakozásunknak megfelelően a perceptron meglehetősen gyorsan tanulja a függvényt, mivel a többségfüggvény lineárisan szeparálható. Másrészről viszont a döntési fa tanuló nem nagyon halad a tanulással, mert a többségfüggvényt nagyon nehéz (bár nem lehetetlen) döntési fában reprezentálni. A jobb oldali ábrán az étterem példa látható. A probléma megoldása könnyen ábrázolható döntési fával, de lineárisan nem szeparálható. Az adatokra felvett legjobb szeparáló sík csak 65%-ot osztályoz helyesen.</p><div class="figure"><a id="id746644"/><p class="title"><strong>20.21. ábra - A gradiensalapú perceptron tanulási algoritmus, feltételezve, hogy a <span class="emphasis"><em>g</em></span> aktivációs függvény differenciálható. Küszöbperceptronokra elhagyjuk a <span class="emphasis"><em>g</em></span>'(<span class="emphasis"><em>in</em></span>) faktort a súlyfrissítésből. A <code class="code">NEURÁLIS-HÁLÓ-HIPOTÉZIS</code> függvény egy olyan hipotézist ad vissza, amely bármely bemenetre kiszámítja a háló válaszát.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-21.png" alt="A gradiensalapú perceptron tanulási algoritmus, feltételezve, hogy a g aktivációs függvény differenciálható. Küszöbperceptronokra elhagyjuk a g'(in) faktort a súlyfrissítésből. A NEURÁLIS-HÁLÓ-HIPOTÉZIS függvény egy olyan hipotézist ad vissza, amely bármely bemenetre kiszámítja a háló válaszát."/></div></div></div><p>Az eddigiekben úgy tekintettük a perceptronokat, mint olyan determinisztikus függvényeket, amelyeknek valószínűleg hibával terhelt a kimenete. Lehetőségünk van, hogy a szigmoid perceptron kimenetét valószínűségként interpretáljuk – annak valószínűségeként, hogy adott bemenetek esetén a valós kimenet 1. Ezzel az interpretációval úgy használhatjuk a szigmoidot, mint a Bayes-hálók feltételes eloszlásainak kanonikus reprezentációját (lásd 14.3. alfejezet). Levezethetünk egy tanuló algoritmust is, a standard módszernek megfelelően maximalizálva az adatok (feltételes) log likelihood értékét, amint ezt a fejezet korábbi részében ismertettük. Lássuk, hogyan is működik ez.</p><div class="figure"><a id="id746670"/><p class="title"><strong>20.22. ábra - A perceptronok és döntési fák teljesítményének összehasonlítása. (a) A perceptronok jobbak a 11 bemenetű többségfüggvény tanulásában. (b) A döntési fák jobbak az étterem példában a <span class="emphasis"><em>VárjunkE</em></span> predikátum tanulásában.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-22.png" alt="A perceptronok és döntési fák teljesítményének összehasonlítása. (a) A perceptronok jobbak a 11 bemenetű többségfüggvény tanulásában. (b) A döntési fák jobbak az étterem példában a VárjunkE predikátum tanulásában."/></div></div></div><p>Vegyünk egyetlen tanító példát, amelynek kívánt kimeneti értéke <span class="emphasis"><em>T</em></span>, és legyen erre a példára a perceptron válasza <span class="emphasis"><em>p</em></span>. Ha <span class="emphasis"><em>T = </em></span>1, akkor az adat feltételes valószínűsége <span class="emphasis"><em>p</em></span>, ha <span class="emphasis"><em>T = </em></span>0, akkor a feltételes valószínűség (1 – <span class="emphasis"><em>p</em></span>). Egy egyszerű trükk alkalmazásával a log likelihoodot differenciálható formában írhatjuk fel. A trükk az, hogy ha a 0/1 változót egy kifejezés kitevőjébe írjuk, akkor <span class="strong"><strong>indikátorváltozó</strong></span>ként (<span class="strong"><strong>indicator variable</strong></span>) viselkedik: <span class="emphasis"><em>p<sup>T</sup></em></span>akkor <span class="emphasis"><em>p</em></span>, ha <span class="emphasis"><em>T = </em></span>1, egyébként 1; hasonlóképpen (1 – <span class="emphasis"><em>p</em></span>)<sup>(1–<span class="emphasis"><em>T</em></span>)</sup> akkor (1 – <span class="emphasis"><em>p</em></span>), ha <span class="emphasis"><em>T = </em></span>0, különben 1. Ezek szerint az adat log likelihood értékét felírhatjuk, mint:</p><p><code class="code"><em><span class="remark">L</span></em> = log <em><span class="remark">p<sup>T</sup></span></em>(1 – <em><span class="remark">p</span></em>)<sup>(1 – <em><span class="remark">T</span></em>)</sup> = <em><span class="remark">T </span></em>log <em><span class="remark">p</span></em> + (1 – <em><span class="remark">T</span></em>) log(1 – <em><span class="remark">p</span></em>)					(20.13)</code></p><p>A szigmoid függvény tulajdonságainak hála, a gradiens rendkívül egyszerű formára hozható (20.16. feladat):</p><p><span class="inlinemediaobject"><img src="math/mi-20-0037.gif" alt="A perceptronok és döntési fák teljesítményének összehasonlítása. (a) A perceptronok jobbak a 11 bemenetű többségfüggvény tanulásában. (b) A döntési fák jobbak az étterem példában a VárjunkE predikátum tanulásában."/></span></p><div class="important" title="Fontos" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Fontos</h3><p>Vegyük észre, hogy <span class="emphasis"><em>szigmoid perceptronok esetén a maximum-likelihood tanulás súlyfrissítési vektorát megadó egyenlete alapvetően azonos a négyzetes hiba minimalizálásán alapuló frissítés vektorával</em></span>. Tehát azt mondhatjuk, hogy a perceptronnak még akkor is van valószínűségi interpretációja, ha a tanulási szabályt determinisztikus megközelítéssel származtattuk.</p></div></div><div class="section" title="Többrétegű előrecsatolt neurális hálók"><div class="titlepage"><div><div><h2 class="title"><a id="id746803"/>Többrétegű előrecsatolt neurális hálók</h2></div></div></div><p>Vizsgáljuk most a rejtett neuronokkal rendelkező hálókat. A legelterjedtebb esetben egy rejtett réteget<sup>[<a id="id746809" href="#ftn.id746809" class="footnote">205</a>]</sup> szoktak használni, ezt mutatja 20.24. ábra. A rejtett réteg hozzáadásának az az előnye, hogy kiterjeszti a háló által reprezentálható hipotézisek terét. Gondoljunk minden egyes rejtett neuronra úgy, mint ami egy lágy küszöbfüggvényt reprezentál a bemeneti térben – lásd a 20.19. (b) ábrát. Ezek után gondoljunk úgy egy kimeneti neuronra, mint ami számos ilyen függvény lineáris kombinációjának lágy küszöbfüggvénye. Például összeadva két – egymással szemben álló – lágy küszöbfüggvényt, és küszöbözve az eredményt, a 20.23. (a) ábrán látható „hegygerinc” függvényt kapjuk. Egymásra derékszögben álló két ilyen hegygerinc kombinálásával (tehát 4 rejtett neuron kimenetének kombinálásával) a 20.23. (b) ábrán látható „dudort” kapjuk.</p><p>Több rejtett neuronnal különböző helyeken több, eltérő méretű dudort tudunk létrehozni. Valójában egyetlen, megfelelően nagy rejtett réteggel a bemenetek tetszőleges folytonos függvénye tetszőleges pontossággal reprezentálható, sőt két réteggel még nemfolytonos függvények is reprezentálhatók.<sup>[<a id="id746818" href="#ftn.id746818" class="footnote">206</a>]</sup> Sajnos egy <span class="emphasis"><em>egyedi</em></span> neurális struktúra esetén nemigen lehet megmondani, hogy milyen függvények reprezentálhatók, és milyenek nem.</p><p>Tegyük fel, hogy az étterem problémára akarunk konstruálni egy egy-rejtett-réteggel rendelkező hálót. Minden példát 10 attribútum ír le, tehát egy 10 bemenetű hálóra lesz szükség. Hány rejtett neuron kell? A 20.24. ábrán bemutatunk egy négy rejtett neuronnal felépített hálót. Az derült ki, hogy ez nagyjából megfelelő ehhez a problémához. A rejtett neuronok számának előzetes meghatározása még napjainkban sem jól megoldott probléma. (Lásd <a class="xref" href="ch20s05.md#ID_856_857_oldal">„Neurális hálóstruktúrák tanulása”</a> részben.)</p><div class="figure"><a id="id746843"/><p class="title"><strong>20.23. ábra - (a) Két – egymással szemben álló – lágy küszöbfüggvény kombinációjának eredménye: egy hegygerinc. (b) Két hegygerinc kombinációjának eredménye a dudor.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-23.png" alt="(a) Két – egymással szemben álló – lágy küszöbfüggvény kombinációjának eredménye: egy hegygerinc. (b) Két hegygerinc kombinációjának eredménye a dudor."/></div></div></div><p class="Tartalom3">A többrétegű háló tanuló algoritmusa hasonló a 20.21. ábrán bemutatott perceptrontanulási algoritmushoz. Egy kisebb különbség, hogy több kimenet is lehet, így nem egy skalár kimeneti értékünk, hanem egy <span class="bold"><strong>h<sub>W</sub></strong></span>(<span class="strong"><strong>x</strong></span>) kimeneti vektorunk van, és minden egyes példához is egy <span class="strong"><strong>y</strong></span> kívánt kimeneti vektor tartozik. Fontosabb különbség, hogy míg a kimeneti rétegben a hiba nyilvánvalóan <span class="strong"><strong>y </strong></span>–<span class="strong"><strong> h</strong></span><span class="bold"><strong><sub>W</sub></strong></span>, addig a rejtett rétegben a hiba misztikusnak tűnik, hiszen a tanító minták nem mutatják, hogy minek kellene lennie a rejtett csomópontok értékének. Kiderül, hogy a hibát <span class="strong"><strong>viszszaterjeszt</strong></span>hetjük (<span class="strong"><strong>back-propagate</strong></span>) a kimeneti rétegről a rejtett rétegekre. A hiba-visszaterjesztési eljárás (back-propagation) közvetlenül kiadódik a teljes hibagradiens levezetéséből. Először egy intuitív bizonyítással mutatjuk be az eljárást, majd megmutatjuk a levezetést is.</p><div class="figure"><a id="id746897"/><p class="title"><strong>20.24. ábra - Többrétegű neurális háló egy rejtett réteggel és 10 bemeneti egységgel, alkalmas az étterem problémához</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-24.png" alt="Többrétegű neurális háló egy rejtett réteggel és 10 bemeneti egységgel, alkalmas az étterem problémához"/></div></div></div><p class="Tartalom3">A kimeneti rétegre a súlyfrissítési szabály azonos a (20.12) egyenlettel. Több kimenetünk van, legyen <span class="emphasis"><em>Err<sub>i</sub></em></span> az <span class="strong"><strong>y </strong></span>–<span class="strong"><strong> h</strong></span><span class="bold"><strong><sub>W</sub></strong></span> hibavektor <span class="emphasis"><em>i</em></span>-edik komponense. Hasznos lesz, ha bevezetjük a módosított hibát, Δ<span class="emphasis"><em><sub>i</sub> </em></span>=<span class="emphasis"><em> Err<sub>i</sub></em></span> × <span class="emphasis"><em>g</em></span>'(<span class="emphasis"><em>in<sub>i</sub></em></span>)-t, így a súlyfrissítési szabály:</p><p><code class="code"><em><span class="remark">W</span></em><sub><em><span class="remark">j</span></em>,<em><span class="remark">i</span></em></sub> ← <em><span class="remark">W</span></em><sub><em><span class="remark">j</span></em>,<em><span class="remark">i</span></em></sub> + <em><span class="remark">α</span></em> × <em><span class="remark">a<sub>j</sub></span></em> · Δ<sub>i 										</sub>(20.14)</code></p><p>Ahhoz, hogy a bemeneti neuronok és a rejtett neuronok közti összeköttetések frissítését megoldjuk, a kimeneti csomópontok hibájához hasonló mennyiséget kell definiálnunk. Ez az a pont, ahol a hiba-visszaterjesztést végezzük. A gondolat az, hogy a <span class="emphasis"><em>j</em></span> rejtett csomópont valamilyen arányban „felelős” minden egyes – vele összeköttetésben lévő – kimeneti csomópont Δ<sub>i</sub> hibájáért. Így a Δ<sub>i</sub> értékeket a rejtett csomópont és a kimeneti csomópont közötti összeköttetés erőssége alapján osztjuk és visszaterjesztjük, hogy megkapjuk a rejtett réteg Δ<sub>j</sub> értékeit. A Δ értékek terjesztési szabálya a következő:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0038.gif" alt="Többrétegű neurális háló egy rejtett réteggel és 10 bemeneti egységgel, alkalmas az étterem problémához"/></span></p><p>Ezek után a bemenetek és a rejtett réteg közötti súlyok frissítési szabálya szinte azonos a kimeneti réteg frissítési szabályával:</p><p><code class="code"><em><span class="remark">W<sub>k,j</sub></span></em> ← <em><span class="remark">W<sub>k,j</sub></span></em> + α × <em><span class="remark">a<sub>k</sub></span></em> × Δ<sub>j</sub></code></p><p class="Tartalom3">A hiba-visszaterjesztési algoritmus a következő módon foglalható össze:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Számítsuk ki a kimeneti neuronokra a Δ értékeket a megfigyelt hiba alapján.</p></li><li class="listitem"><p>A kimeneti réteggel kezdve ismételjük a következő lépéseket minden rétegre, amíg a legelső rejtett réteget el nem érjük:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Terjesszük vissza a Δ értékeket a megelőző rétegre.</p></li><li class="listitem"><p>Frissítsük a két réteg közötti súlyokat.</p></li></ul></div></li></ul></div><p>Az algoritmust a 20.25. ábra mutatja be részleteiben.</p><div class="figure"><a id="id747071"/><p class="title"><strong>20.25. ábra - A többrétegű hálókra kidolgozott hiba-visszaterjesztéses tanulási algoritmus</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-25.png" alt="A többrétegű hálókra kidolgozott hiba-visszaterjesztéses tanulási algoritmus"/></div></div></div><p class="Tartalom3">A matematika iránt vonzalmat érzők kedvéért most az alapegyenletekből levezetjük a hiba-visszaterjesztési algoritmust. Egyetlen mintára a négyzetes hiba definíciója:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0039.gif" alt="A többrétegű hálókra kidolgozott hiba-visszaterjesztéses tanulási algoritmus"/></span></p><p>ahol az összegzés a kimeneti réteg csomópontjaira vonatkozik. Egy bizonyos <span class="emphasis"><em>W</em></span><sub><span class="emphasis"><em>j</em></span>,<span class="emphasis"><em>i</em></span></sub> súlyra vett gradiens kiszámításához csak az <span class="emphasis"><em>a<sub>i</sub></em></span> aktivációt kell deriválnunk, mivel az összeg összes többi tagja független <span class="emphasis"><em>W</em></span><sub><span class="emphasis"><em>j</em></span>,<span class="emphasis"><em>i</em></span></sub>-től:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0040.gif" alt="A többrétegű hálókra kidolgozott hiba-visszaterjesztéses tanulási algoritmus"/></span></p><p>ahol Δ<sub>i</sub>-t az előzőkkel megegyezően definiáltuk. Ahhoz, hogy a bemeneti réteget és a rejtett réteget összekötő <span class="emphasis"><em>W</em></span><sub><span class="emphasis"><em>k</em></span>,<span class="emphasis"><em>j</em></span></sub> súlyokra vonatkozó gradienst megkapjuk, meg kell tartanunk az <span class="emphasis"><em>i</em></span> feletti teljes összegzést, hiszen az összes kimeneti <span class="emphasis"><em>a<sub>i</sub></em></span> értékre hatással lehetnek <span class="emphasis"><em>W<sub>k,j</sub></em></span> változásai. Az <span class="emphasis"><em>a<sub>j</sub></em></span> aktivációkat szintén mind ki kell fejtenünk. Aprólékosan bemutatjuk a levezetést, mivel érdekes megfigyelni, ahogy a differenciáló operátor visszaterjed hálón keresztül:</p><p><span class="inlinemediaobject"><img src="math/mi-20-0041.gif" alt="A többrétegű hálókra kidolgozott hiba-visszaterjesztéses tanulási algoritmus"/></span></p><p>ahol a Δ<sub>j</sub>-t az előzőkkel megegyezően definiáltuk. Tehát megkaptuk azt a frissítési szabályt, amelyet már korábban megkaptunk intuitív úton is. Az is nyilvánvaló, hogy az eljárás folytatható több mint egy rejtett rétegű hálókra is, ami igazolja a 20.25. ábrán bemutatott általános algoritmust.</p><p>Keresztülverekedvén magunkat (vagy átugorva) a matematikai levezetésen lássuk most, hogy milyen teljesítményt nyújt egy egy-rejtett-rétegű háló az étterem problémán. A 20.26. ábrán két görbét mutatunk be. Az első a <span class="strong"><strong>tanítási görbe</strong></span> (<span class="strong"><strong>training curve</strong></span>), amely a súlyfrissítés során az átlagos négyzetes hiba alakulását mutatja egy adott 100 elemű étterem példahalmazon mérve. Ez jól demonstrálja, hogy a háló valóban konvergál a tanító mintákra való tökéletes illeszkedéshez. A második görbe az étteremadatok standard tanulási görbéje. A neurális háló jól tanul, bár nem annyira gyorsan, mint a döntési fa tanulás. Ez talán nem meglepő, hiszen az adatokat egy egyszerű döntési fával generáltuk.</p><div class="figure"><a id="id747197"/><p class="title"><strong>20.26. ábra - (a) Az étterem probléma egy adott példahalmazán felvett tanulási görbe, ami a súlyok számos epoch során történő módosításával elért fokozatos hibacsökkenést mutatja. (b) Összehasonlító tanulási görbék, amelyek azt mutatják, hogy a döntési fa tanulás valamivel jobb teljesítményt ad, mint a többrétegű háló hiba-visszaterjesztéses tanulása.</strong></p><div class="figure-contents"><div class="mediaobject"><img src="kepek/20-26.png" alt="(a) Az étterem probléma egy adott példahalmazán felvett tanulási görbe, ami a súlyok számos epoch során történő módosításával elért fokozatos hibacsökkenést mutatja. (b) Összehasonlító tanulási görbék, amelyek azt mutatják, hogy a döntési fa tanulás valamivel jobb teljesítményt ad, mint a többrétegű háló hiba-visszaterjesztéses tanulása."/></div></div></div><p class="Tartalom3">A neurális hálók természetesen messze bonyolultabb tanulási feladatokra képesek, bár meg kell jegyeznünk, hogy szükség van némi babrálásra ahhoz, hogy megfelelő hálóstruktúrát kapjunk, és a súlytérben valahol a globális optimum közelébe konvergáljunk. A szó szoros értelmében tízezerszám vannak publikált neurális háló alkalmazások. A 20.7. alfejezet alaposabban bemutat egyet.</p></div><div class="section" title="Neurális hálóstruktúrák tanulása"><div class="titlepage"><div><div><h2 class="title"><a id="id747210"/>Neurális hálóstruktúrák tanulása</h2></div></div></div><a id="ID_856_857_oldal"/><p>Az eddigiekben adott hálóstruktúra mellett történő súlytanulással foglalkoztunk. A Bayes-hálókhoz hasonlóan azt is meg kell értenünk, hogy hogyan találhatjuk meg a legjobb hálóstruktúrát. Ha túl nagy hálót használunk, akkor az egy nagy táblázatot kialakítva képes lesz memorizálni az összes példát, de nem feltétlenül lesz képes olyan bemenetekre jól általánosítani, amelyeket nem látott korábban.<sup>[<a id="id747219" href="#ftn.id747219" class="footnote">207</a>]</sup><sup> </sup>Más szavakkal a neurális háló – éppúgy, mint az összes statisztikus modell – hajlamos a <span class="strong"><strong>túlilleszkedés</strong></span>re (<span class="strong"><strong>overfitting</strong></span>), ha túl sok modellparaméter van. Ezt bemutattuk a 18.1. ábrán (<a class="xref" href="ch18s02.md#ID_752_oldal">„Induktív tanulás”</a> rész), ahol a (b) és (c) sokparaméteres modell jól illeszkedett az adatokra, de nem volt képes olyan jó általánosításra, mint a kevés paraméterrel rendelkező (a) és (d) modellek.</p><p>Ha ragaszkodunk a teljesen összekötött hálókhoz, akkor egyedül a rejtett rétegek számára és méretére korlátozódnak a választási lehetőségeink. A szokásos megközelítés, hogy sok struktúrát kipróbálunk, és megtartjuk a legjobbat. A 18. fejezetben ismertetett <span class="strong"><strong>keresztvalidáció</strong></span>s (<span class="strong"><strong>cross-validation</strong></span>) technikára van szükségünk, ha el akarjuk kerülni a teszthalmazra való <span class="strong"><strong>kukucskálás</strong></span>t (<span class="strong"><strong>peeking</strong></span>). Azaz azt a hálóarchitektúrát választjuk, amely a validációs halmazon a legnagyobb jóslási pontosságot adja.</p><p>Ha figyelembe akarunk venni nem teljesen összekötött hálókat is, akkor szükségünk van egy hatékony módszerre, amely a lehetséges összeköttetési topológiák nagyon nagy terében keres. Az <span class="strong"><strong>optimális agykárosodás</strong></span> (<span class="strong"><strong>optimal brain damage</strong></span>) módszere egy teljesen összekötött hálóból indul ki, és összeköttetéseket távolít el belőle. Miután a hálót első menetben tanítottuk, egy információelméleti megközelítés segítségével meghatározzuk az eltávolítható összeköttetések optimális készletét. A hálót ezek után újratanítjuk, és ha teljesítménye nem csökkent, az eljárást megismételjük. Az összeköttetések eltávolításán felül olyan neuronokat is eltávolíthatunk, amelyek nem sokkal járulnak hozzá a megoldáshoz.</p><p>Rengeteg algoritmust javasoltak arra, hogy egy kisebb hálóból nagyobbat növesszenek. Egyikük, a <span class="strong"><strong>csempézés</strong></span> (<span class="strong"><strong>tiling</strong></span>), a döntési fa tanulásra emlékeztet. Az ötlet az, hogy kezdjünk egyetlen neuronnal, amely a legjobbját nyújtja, hogy annyi tanító mintára adjon helyes választ, ahányra csak lehet. További neuronokat adunk hozzá, hogy megoldjuk azokat a példákat, amelyekre az első neuron rossz választ adott. Az algoritmus csak annyi neuront ad hozzá, amennyi az összes minta megoldásához szükséges.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.id746413" href="#id746413" class="para">202</a>] </sup> A folytonos terekben használható általános optimalizálási technikákat lásd a 4.4. alfejezetben.</p></div><div class="footnote"><p><sup>[<a id="ftn.id746477" href="#id746477" class="para">203</a>] </sup> Szigmoid függvény esetén ez a derivált <span class="emphasis"><em>g</em></span>' = <span class="emphasis"><em>g</em></span>(1 – <span class="emphasis"><em>g</em></span>).</p></div><div class="footnote"><p><sup>[<a id="ftn.id746583" href="#id746583" class="para">204</a>] </sup> Küszöbperceptronokra, ahol <span class="emphasis"><em>g</em></span>'(<span class="emphasis"><em>in</em></span>) nem definiált, a Rosenblatt (Rosenblatt, 1957) által kidolgozott eredeti <span class="strong"><strong>perceptron tanulási szabály</strong></span> (<span class="strong"><strong>perceptron learning rule</strong></span>) megegyezik a (20.12) egyenlettel, leszámítva, hogy a <span class="emphasis"><em>g</em></span>'(<span class="emphasis"><em>in</em></span>) kimarad. Mivel <span class="emphasis"><em>g</em></span>'(<span class="emphasis"><em>in</em></span>) minden súlyra azonos, elhagyása az egyes mintáknál összességében csak a súlyfrissítés nagyságát változtatja meg, az irányát nem.</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id746809" href="#id746809" class="para">205</a>] </sup> Egyesek ezt háromrétegű hálózatnak nevezik, mások kétrétegűnek (mivel a bemenetek nem „igazi” neuronok). A zűrzavar elkerülése érdekében mi „egy-rejtett-rétegű háló”-nak nevezzük.</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id746818" href="#id746818" class="para">206</a>] </sup> A bizonyítás bonyolult, de legfőbb pontja az, hogy a bemenetek számával exponenciálisan nő a szükséges rejtett neuronok száma. Például <span class="emphasis"><em>n</em></span> bemenetű logikai függvények kódolására 2<span class="emphasis"><em><sup>n</sup>/n</em></span> rejtett neuron kell.</p></div><div class="footnote"><p><sup>[<a id="ftn.id747219" href="#id747219" class="para">207</a>] </sup> Azt figyelték meg, hogy a nagyon nagy hálók <span class="emphasis"><em>mindaddig</em></span> jól általánosítanak, <span class="emphasis"><em>amíg a súlyaikat kis értéken tartjuk</em></span>. Ez a megszorítás az aktivációs értékeket a <span class="emphasis"><em>g</em></span>(<span class="emphasis"><em>x</em></span>) szigmoid függvény <span class="emphasis"><em>lineáris</em></span> tartományában tartja, ahol <span class="emphasis"><em>x</em></span> közel nulla. Ez viszont azt jelenti, hogy a háló úgy viselkedik, mint egy sokkal kevesebb paraméterrel rendelkező lineáris függvény (lásd 20.17. feladat).</p></div></div></div></body></html>
