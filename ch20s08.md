<?xml version="1.0" encoding="UTF-8" standalone="no"?>

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="section" title="Összefoglalás"><div class="titlepage"><div><div><h1 class="title"><a id="id748121"/>Összefoglalás</h1></div></div></div><p>A statisztikai tanulás módszerei széles skálán helyezkednek el: az egyszerű átlagszámításoktól a bonyolult modellek – mint például a Bayes-hálók vagy neurális hálók – konstruálásáig. Alkalmazási területük a számítógép-tudományra, a mérnöki alkalmazásokra, a neurobiológiára, a pszichológiára és a fizikára is kiterjed. Ebben a fejezetben bemutattunk néhány alapelvet, és ízelítőt adtunk a matematikai tárgyalásból. A következő fő pontok szerepeltek:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>A <span class="strong"><strong>Bayes-tanulás</strong></span>i (<span class="strong"><strong>Bayesian learning</strong></span>) módszerek a tanulást valószínűségi következtetésként fogalmazzák meg, a megfigyelések alapján frissítve a hipotézisek a priori<span class="emphasis"><em> </em></span>eloszlásait. Ez a megközelítés jó eszköz az Ockham borotvája elv megvalósítására, de bonyolult hipotézisterek esetén hamar kezelhetetlenné válik.</p></li><li class="listitem"><p>A <span class="strong"><strong>maximum a posteriori</strong></span> (<span class="strong"><strong>MAP</strong></span>) tanulás az adatok alapján választ ki egyetlen, a legvalószínűbb hipotézist. A hipotézis priort itt is használjuk, ez a módszer gyakran jobban kezelhető, mint a tiszta Bayes-tanulás.</p></li><li class="listitem"><p>A <span class="strong"><strong>maximum-likelihood</strong></span> tanulás egyszerűen azt a hipotézist választja, amely maximálja az adatok likelihood értékét. Megfelel egy egyenletes prior mellett végrehajtott MAP-tanulásnak. Egyszerű esetekben, mint a lineáris regresszió és a teljesen megfigyelhető Bayes-hálók, a maximum-likelihood megoldás könnyen előállítható zárt alakban. A <span class="strong"><strong>naiv Bayes</strong></span>- (<span class="strong"><strong>naive Bayes</strong></span>) tanulás különösen hatékony technika, amely különböző bonyolultságú feladatokra is jól illeszthető.</p></li><li class="listitem"><p>Amikor a változók közt van néhány rejtett (nem megfigyelhető), akkor az <span class="strong"><strong>EM</strong></span> algoritmussal lokális maximum-likelihood megoldásokat találhatunk. Az alkalmazások kiterjednek a kevert Gauss-jelek osztályozására, a Bayes-hálók tanulására és a rejtett Markov-modellek tanulására.</p></li><li class="listitem"><p>A <span class="strong"><strong>modellválasztás</strong></span>ra (<span class="strong"><strong>model selection</strong></span>) ad példát a Bayes-hálók struktúrájának tanulása. Ez rendszerint egy, a struktúrák terében végzett diszkrét keresést foglal magában. Szükség van valamilyen módszerre a modell bonyolultsága és az illeszkedés mértéke közti kompromisszum létrehozásához.</p></li><li class="listitem"><p>A <span class="strong"><strong>példányalapú modell</strong></span>ek (<span class="strong"><strong>instance-based model</strong></span>) a tanító példányok gyűjteményének eloszlását reprezentálják. Így a paraméterek száma a tanító halmaz méretével nő. A <span class="strong"><strong>legközelebbi-szomszéd</strong></span> (<span class="strong"><strong>nearest neighbor</strong></span>) módszerek a kérdéses mintapont közelében lévő példányokat nézik, míg a <span class="strong"><strong>kernel</strong></span>módszerek az összes példány távolsággal súlyozott kombinációját.</p></li><li class="listitem"><p>A <span class="strong"><strong>neurális háló</strong></span>k (<span class="strong"><strong>neural network</strong></span>s) nem mások, mint sok paraméterrel rendelkező, komplex nemlineáris függvények. Paramétereiket zajos adatok alapján tanulhatják meg. Több ezer alkalmazásban használták már őket.</p></li><li class="listitem"><p>A <span class="strong"><strong>perceptron</strong></span> egy előrecsatolt neurális háló, amelynek nincs rejtett rétege, és csak <span class="strong"><strong>lineárisan szeparálható</strong></span> (<span class="strong"><strong>linearly separable</strong></span>) függvények reprezentálására alkalmas. Ha az adatok lineárisan szeparálhatók, akkor egy egyszerű súlyfrissítési szabály alkalmazásával az adatokra való pontos illeszkedést tudunk elérni.</p></li><li class="listitem"><p>A <span class="strong"><strong>többrétegű előrecsatolt</strong></span> (<span class="strong"><strong>multilayer feed-forward</strong></span>) neurális hálók – ha kellő számú neuronjuk van – tetszőleges függvények reprezentálására képesek. A <span class="strong"><strong>hiba-visszaterjesztés</strong></span>i (<span class="strong"><strong>back-propagation</strong></span>) algoritmus a kimeneti hiba minimalizálása érdekében gradiensalapú csökkentést valósít meg a paramétertérben.</p></li></ul></div><p class="Tartalom3">A statisztikai tanulás továbbra is igen aktív kutatási terület. Mind az elmélet, mind a gyakorlat hatalmas lépésekkel haladt, míg elértünk addig a pontig, hogy szinte bármely modell megtanulható, ha megvalósítható rá egzakt vagy közelítő következtetés.</p><div class="section" title="Irodalmi és történeti megjegyzések"><div class="titlepage"><div><div><h2 class="title"><a id="id750582"/>Irodalmi és történeti megjegyzések</h2></div></div></div><p>Az MI korai éveiben a statisztikai tanuláselmélet a kutatás aktívan művelt területe volt (Duda és Hart, 1973), de elkülönült az MI fősodrától, ahogy ez utóbbi egyre inkább a szimbolikus módszerekre koncentrált. Különböző formákban folytatódott – egyesek explicit módon valószínűségiek, mások nem – olyan területeken, mint az <span class="strong"><strong>alakzatfelismerés</strong></span> (<span class="strong"><strong>pattern recognition</strong></span>) (Devroye és társai, 1996) és az <span class="strong"><strong>információkeresés</strong></span> (<span class="strong"><strong>information retrieval</strong></span>) (Salton és McGill, 1983). Nem sokkal a Bayes-háló modellek bevezetése után, az 1980-as évek végén az érdeklődés ismét erősen ráirányult, nagyjából ugyanebben az időben jelent meg a neurális hálók statisztikai megközelítése. Az 1990-es évek végén a gépi tanulás, a statisztika és a neuronhálók területén is az érdeklődés középpontjába kerültek az adatok alapján nagy valószínűségi modelleket létrehozó módszerek.</p><p>A naiv Bayes-modell egyike a legrégebbi és legegyszerűbb Bayes-hálóknak, megjelenése egészen az 1950-es évekig követhető vissza. Eredetüket megemlítettük a 13. fejezet záró megjegyzéseiben. Részleges magyarázat található Domingos és Pazzani publikációjában (Domingos és Pazzani, 1997). A naiv Bayes-tanulás turbózott változata nyerte az első KDD Cup adatbányászati versenyt (Elkan, 1997). Heckerman kitűnő bevezetését adja a Bayes-háló tanulás általános problematikájának (Heckerman, 1998). Spiegelharter és társai a Bayes-hálók Bayesi paramétertanulását tárgyalták Dirichlet-priorok esetére (Spiegelharter és társai, 1993). A <code class="code">BUGS</code> szoftvercsomag (Gilks és társai, 1994) számos gondolatot megtestesített ezek közül, nagyon hatékony eszközt biztosított az összetett valószínűségi modellek felállítására és tanulására. A Bayes-hálóstruktúra tanulásának első algoritmusai feltételes függetlenségi teszteket használtak (Pearl, 1988; Pearl és Verma, 1991). Spirtes és társai hasonló elvek alapján dolgozták ki átfogó megközelítésüket, valamint a Tetrad csomagot Bayes-hálóstruktúra tanulás céljaira (Spirtes és társai, 1993). Az azóta végrehajtott algoritmikus javítások a 2001-es KDD Cup adatbányászati versenyen egy Bayes-háló tanulási algoritmus (Cheng és társai, 2002) meggyőző győzelméhez vezettek. (Itt a speciális megoldandó feladat egy 139 351 tulajdonsággal leírt bioinformatikai probléma volt!) Cooper és Herskovits egy likelihood maximalizáláson alapuló struktúratanulási megközelítést fejlesztett ki (Cooper és Herskovits, 1992), ezt Heckerman és társai fejlesztették tovább (Heckerman és társai, 1994). Friedman és Goldszmidt mutatták ki a lokális feltételes eloszlások reprezentációjának a megtanult struktúrára gyakorolt hatását (Friedman és Goldszmidt, 1996).</p><p>A rejtett változókkal és a hiányzó adatokkal való valószínűségi modell tanulás általános problematikáját az EM algoritmussal kísérelték meg kezelni (Dempster és társai, 1977). Ezt számos meglévő módszerből absztrahálták, amelyek közt található a rejtett Markov-modell (HMM) tanulásra szolgáló Baum–Welch-algoritmus is (Baum és Petrie, 1966). (Maga Dempster az EM algoritmust inkább sémának tekinti, nem algoritmusnak, mivel jó adag elméleti matematikai munkára lehet szükség mielőtt egy új eloszláscsaládra alkalmazható lenne.) Manapság az EM egyike a tudományos kutatásban legelterjedtebben használt algoritmusoknak, McLachlan és Krishnan egy teljes könyvet szenteltek neki és tulajdonságainak (McLachlan és Krishnan, 1997). A kevert modellek – beleértve a kevert Gauss-modellek – tanulásának speciális problémáit Titterington és társai tárgyalták (Titterington és társai, 1985). Az <code class="code">AUTOCLASS</code> volt az első sikeres rendszer az MI-n belül, amely az EM-et alkalmazta kevert modellezésre (Cheeseman és társai, 1988; Cheeseman és Stutz, 1996). Az <code class="code">AUTOCLASS</code>-t egy sor valós tudományos osztályozási feladatra alkalmazták; ezek közül kettő: spektrális tulajdonságok alapján új csillagtípusok felfedezése (Goebel és társai, 1989); új fehérje- és intronosztályok felfedezése DNS/fehérjeszekvencia adatbázisokban (Hunter és States, 1992).</p><p>A rejtett változókkal rendelkező Bayes-hálók tanulására kifejlesztett EM algoritmus Lauritzen munkája (Lauritzen, 1995). Mind a Bayes-hálók, mind a dinamikus Bayes-hálók esetén a gradiensalapú eljárások is hatékonynak bizonyultak (Russell és társai, 1995; Binder és társai, 1997a). A strukturális EM algoritmus kifejlesztése Friedman nevéhez fűződik (Friedman, 1998). A Bayes-hálók struktúrájának megtanulhatósága szoros kapcsolatban van a <span class="emphasis"><em>kauzális</em></span> kapcsolatok adatokból történő visszanyerésének kérdésével. Azaz lehetséges-e Bayes-hálókat úgy megtanulni, hogy az előállított hálóstruktúra valós kauzális hatásokat jelezzen? A statisztikusok hosszú évek óta elkerülték ezt a kérdést, azt hitték, hogy a megfigyelt adatok (ellentétben a kísérletek során előálltakkal) csak korrelációs információt hordoznak. Végül is bármely két változóra, amelyek egymással kapcsolatban állónak tűnnek, lehet, hogy valójában inkább egy harmadik – mindkettőre kauzális hatást gyakorló – ismeretlen változó hatása alatt állnak, nem pedig egymásra gyakorolnak közvetlen hatást. Ennek ellenkezőjére Pearl adott meggyőző érveket (Pearl, 2000). Megmutatta, hogy valójában számos eset van, amikor a kauzalitás kideríthető, és <span class="strong"><strong>kauzális háló</strong></span> (<span class="strong"><strong>causal network</strong></span>) formalizmus alakítható ki az oksági kapcsolatok, a beavatkozás hatásának, valamint a szokásos feltételes valószínűségek beépítésére.</p><p>A legközelebbi-szomszéd modellek legalább Fix és Hodges (Fix és Hodges, 1951) munkájáig nyúlnak vissza, és azóta a statisztika és alakfelismerés standard eszközei. Az MI-n belül Stanfill és Waltz népszerűsítették ezeket a modelleket (Stanfill és Waltz, 1986), ők a távolságmetrika adatokhoz történő adaptálási módszereivel foglalkoztak. Hastie és Tibshirani kifejlesztettek egy módszert, amellyel a tér egyes pontjaihoz kötötték az ezen pont körüli adateloszlástól függő metrikát (Hastie és Tibshirani, 1996). A legközelebbi-szomszédok hatékony indexelési sémával történő megtalálásával az algoritmusokat kutató közösség foglalkozott (pl. Indyk, 2000). A kernelsűrűség-becslést, amelyet <span class="strong"><strong>Parzen ablak</strong></span> (<span class="strong"><strong>Parzen window</strong></span>) sűrűségbecslésnek is neveznek, kezdetben Rosenblatt és Parzen tanulmányozta (Rosenblatt, 1956; Parzen, 1962). Azóta óriási az irodalma a különböző becslők tulajdonságai vizsgálatának. Devroye alapos bevezetést nyújt ehhez a témához (Devroye, 1987).</p><p>A neurális hálók irodalma túl nagy ahhoz (napjainkig kb. 100 000 publikáció), hogy részletesen bemutathassuk. A korai fejleményekről Cowan és Sharp készített összefoglalót (Cowan és Sharp, 1988b; 1988a), McCulloch és Pitts munkásságával kezdve az áttekintést (McCulloch és Pitts, 1943). Norbert Wiener – a kibernetika és a szabályozáselmélet egyik úttörője (Wiener, 1948) – együtt dolgozott McCullochkal és Pitts-szel, és nagy hatást gyakorolt egy sor fiatal kutatóra, például Marvin Minskyre, aki valószínűleg elsőként fejlesztett ki működő neurálisháló-hardvert 1951-ben (Minsky és Papert, 1988, pp. ix–x.) Ezalatt Nagy-Britanniában W. Ross Ashby (szintén a kibernetika egyik úttörője; Ashby, 1940), Alan Turing, Grey Walter és mások megalakították a Ráció Klubot (Ratio Club) azok számára, akik „rájöttek Wiener gondolataira, még mielőtt Wiener könyve megjelent”. Ashby <span class="emphasis"><em>Az agy felépítése</em></span> (<span class="emphasis"><em>Design for a Brain</em></span>, 1948, 1952) című könyvében vetette fel, hogy stabil adaptív viselkedést létrehozó alkalmas visszacsatoló hurkokkal rendelkező <span class="strong"><strong>homeostatikus</strong></span><sup>[<a id="id750664" href="#ftn.id750664" class="footnote">210</a>]</sup> (<span class="strong"><strong>homeostatic</strong></span>) eszközök segítségével intelligenciát lehetne létrehozni. Turing egy kutatási jelentést írt <span class="emphasis"><em>Intelligens Gépek</em></span> (<span class="emphasis"><em>Intelligent Machinery</em></span>) címen (Turing, 1948), amely a következő mondattal kezdődik: „Javaslom megvizsgálni azt a kérdést, hogy vajon lehetséges-e az, hogy a gépek intelligens viselkedést mutassanak”, majd leírja a rekurrens neurális hálózatokat, amelyeket „B típusú nem szervezett gépek” néven vezet be, és megadja tanításuknak egy lehetséges megközelítését. Sajnos ezt a jelentést 1969-ig nem is publikálták, és napjainkig lényegében figyelmen kívül hagyták.</p><p>Frank Rosenblatt (Rosenblatt, 1957) nevéhez fűződik a modern „perceptron” felfedezése, és ő bizonyította be a perceptronkonvergencia tételt (Rosenblatt, 1960), bár ezt már a neurális hálók területén kívül eső, tisztán matematikai munkák is előrevetítették (Agmon, 1954; Motzkin és Schoenberg, 1954). Volt némi, a többrétegű hálózatokra irányuló korai kutatás is, amelynek eredményei például a <span class="strong"><strong>Gamba-perceptron</strong></span>ok (Gamba és társai, 1961) és a <span class="strong"><strong>madaline</strong></span>-ok (Widrow, 1962). A <span class="emphasis"><em>Learning Machines</em></span> (Nilsson, 1965) c. könyv áttekintést ad a korai kutatás legnagyobb részéről. A korai perceptronkutatások halálát siettette – a szerzők későbbi állítása szerint csak magyarázta – a <span class="emphasis"><em>Perceptrons</em></span> c. könyv (Minsky és Papert, 1969), amelyben a terület matematikai precizitásának hiányát panaszolták fel. A könyv rámutatott, hogy egyrétegű perceptronokkal csak lineárisan szeparálható helyzetek reprezentálhatók, és felhívta a figyelmet a többrétegű hálók hatékony tanuló algoritmusainak hiányára.</p><p>A San Diegóban, 1979-ben tartott konferencia publikációira alapozott kiadvány (Hinton és Anderson, 1981) tekinthető a konnekcionizmus újjáéledése jelének. Nagy figyelmet keltett a kétrészes „PDP” (Párhuzamos elosztott feldolgozás – Parallel Distributed Processing) antológia (Rumelhart és társai, 1986a), illetve a <span class="emphasis"><em>Nature</em></span>-ben megjelent rövid cikk (Rumelhart és társai, 1986b). A neurális hálókkal foglalkozó cikkek száma az 1980–1984 közötti publikációk számáról 200-szorosára nőtt 1990–1994-re. A mágneses spin üvegek fizikai elméletének felhasználásával elvégzett neurális háló analízis (Amit és társai, 1985) nem csupán szorosabb kapcsolatot hozott a statisztikus mechanika és neurális hálók elmélete közt, hanem <span class="emphasis"><em>tekintélyt</em></span> is adott a területnek. A hiba-visszaterjesztés (back-propagation) technikáját viszonylag hamar kitalálták (Bryson és Ho, 1969), de több alkalommal újra felfedezték (Werbos, 1974; Parker, 1985).</p><p>Az 1990-es években megjelent szupport vektor gépeknek (Cortes és Vapnik, 1995) napjainkban gyorsan növekvő az irodalmuk, amely olyan tankönyveket is magában foglal, mint Cristianini és Shawe-Taylor könyve (Cristianini és Shawe-Taylor, 2000). Nagyon népszerűnek és bizonyos feladatokra nagyon hatékonynak bizonyultak, ilyenek például a szövegkategorizálás (Joachims, 2001), a bioinformatikai kutatás (Brown és társai, 2000), a természetes nyelvű szöveg feldolgozása, mint a kézzel írt számjegyek DeCoste és Schölkopf által megvalósított felismerése (DeCoste és Schölkopf, 2002). A szavazó perceptron szintén egy olyan technika, amely a kerneltrükköt alkalmazza az exponenciális tulajdonságtér implicit reprezentációjára (Collins és Duffy, 2002).</p><p>Számos forrás adható meg a neurális hálók valószínűségi interpretációjára, például (Baum és Wilczek, 1988), valamint (Bridle, 1990). A szigmoid függvény szerepét Jordan tárgyalja (Jordan, 1995). MacKay javasolta a neurális hálók Bayes-i paraméterbecslését (MacKay, 1992), amelyet Neal fejlesztett tovább (Neal, 1996). A neurális hálók függvényreprezentációs képességeit Cybenko vizsgálta (Cybenko, 1988; 1989), aki megmutatta, hogy két rejtett réteg elegendő tetszőleges függvény reprezentációjához, tetszőleges <span class="emphasis"><em>folytonos</em></span> függvény reprezentációjához pedig elég egy réteg. A haszontalan összeköttetések eltávolítását célzó „optimális agykárosodás” módszer LeCun és társai eredménye (LeCun és társai, 1989), míg Sietsma és Dow mutatták meg, hogyan kell a felesleges neuronokat eltávolítani (Sietsma és Dow, 1988). A nagyobb struktúrák növesztéssel való előállítására szolgáló csempézési algoritmus Mézard és Nadal munkája (Mézard és Nadal, 1989). A kézzel írt számjegyek felismerésével foglalkozó algoritmusokról LeCun és társai írtak áttekintő publikációt (LeCun és társai, 1995). Azóta jobb hibaarányt értek el Belongie és társai (2002) az alakillesztési eljárás (Belongie és társai, 2002), valamint DeCoste és Schölkopf a virtuális szupport gép alkalmazásával (DeCoste és Schölkopf, 2002).</p><p>A számítógépes tanulás elmélete területén tevékenykedő kutatók foglalkoztak a neurális háló tanulás komplexitásával. Az első számítási eredményeket Judd kapta (Judd, 1990), aki megmutatta, hogy egy példahalmazzal konzisztens súlyhalmaz megtalálásának általános problémája – még nagyon erősen korlátozó feltételek esetén is – NP-teljes. A mintakomplexitásra vonatkozó eredmények közül néhány Baum és Haussler munkájához fűződik, akik megmutatták, hogy <span class="emphasis"><em>W</em></span> súly esetén a hatékony tanításhoz szükséges mintaszám <span class="emphasis"><em>W </em></span>log <span class="emphasis"><em>W</em></span> arányában nő (Baum és Haussler, 1989).<sup>[<a id="id750740" href="#ftn.id750740" class="footnote">211</a>]</sup> Azóta Anthony és Bartlett egy sokkal fejlettebb elméletet fejlesztettek ki (Anthony és Bartlett, 1999), amely magában foglalja azt a fontos eredményt, hogy a háló reprezentációs képessége a súlyok<span class="emphasis"><em> nagyságrendjétől</em></span> és számától egyaránt függ.</p><p>Az általunk nem tárgyalt legnépszerűbb neurális háló a <span class="strong"><strong>radiális bázisfüggvény</strong></span> (<span class="strong"><strong>RBF</strong></span>) (<span class="strong"><strong>radial basis function</strong></span>) háló. A radiális bázisfüggvény kernelek súlyozott kombinációját (természetesen rendszerint Gauss-kernelekét) alkalmazza függvényapproximációra. Az RBF-hálókat két fázisban taníthatjuk: először egy nem ellenőrzött osztályozással tanítjuk a Gauss-függvények paramétereit (az átlagokat és varianciákat), mint a 20.3. alfejezetben láttuk. A második fázisban a Gauss-függvények relatív súlyát határozzuk meg. Ez egy lineáris egyenletrendszer megoldása, amiről tudjuk, hogy közvetlenül hogyan oldható meg. Így az RBF-tanítás mindkét fázisának vonzó tulajdonságai vannak: az első fázis nem ellenőrzött, tehát nincs szükségünk hozzá címkézett mintákra, a második ugyan felügyelt, de hatékonyan elvégezhető. A részleteket lásd Bishop publikációjában (Bishop, 1995).</p><p>A <span class="strong"><strong>rekurrens háló</strong></span>kat (<span class="strong"><strong>recurrent network</strong></span>), amelyekben a neuronok hurkokba vannak kapcsolva, említettük ugyan a fejezetben, de nem részleteztük. A legjobban megértett rekurrens háló osztályt valószínűleg a <span class="strong"><strong>Hopfield-háló</strong></span>k (<span class="strong"><strong>Hopfield network</strong></span>s) (Hopfield, 1982) alkotják. A Hopfield-háló kétirányú kapcsolatokat használ <span class="emphasis"><em>szimmetrikus</em></span> súlyokkal (azaz <span class="emphasis"><em>W</em></span><sub><span class="emphasis"><em>i</em></span>,</sub><span class="emphasis"><em><sub>j</sub> = W<sub>j</sub></em></span><sub>,<span class="emphasis"><em>i</em></span></sub>), minden neuron bemeneti és egyben kimeneti egység is, a <span class="emphasis"><em>g</em></span> aktivációs függvény az előjelfüggvény, az aktivációs szint pedig csak a ±1 lehet. A Hopfield-háló <span class="strong"><strong>asszociatív memória</strong></span>ként működik: miután egy mintahalmazon tanítottuk, egy új bemeneti stimulus hatására egy olyan aktivációs mintára áll be, amely a tanító példák közül a <span class="emphasis"><em>leginkább emlékeztet</em></span> az új bemenetre. Ha például a tanító halmaz egy halom fénykép, az új bemenet pedig az egyik fénykép egy kis darabja, akkor aktivációs szintjeivel a háló vissza fogja állítani az adott darabból a fényképet. Figyeljük meg, hogy a fényképek nincsenek elkülönülten tárolva a hálóban: mindegyik súly az összes fénykép egy részleges kódja. Érdekes elméleti eredmény, hogy az <span class="emphasis"><em>N</em></span> neuronból álló Hopfield-háló legfeljebb 0,138<span class="emphasis"><em>N</em></span> tanító mintát képes megbízhatóan tárolni.</p><p>A <span class="strong"><strong>Boltzmann-gép</strong></span>ek is szimmetrikus súlyokat használnak, de tartalmaznak rejtett egységeket is (Hinton és Sejnowski, 1983; 1986). Ráadásul aktivációs függvényük <span class="emphasis"><em>sztochasztikus:</em></span> a kimenet 1 értékének valószínűsége a teljes súlyozott bemenetnek valamilyen függvénye. A Boltzmann-gépek ennek megfelelően a szimulált lehűtés keresési eljárásra (lásd 4. fejezet) emlékeztető állapotátmenetek során jutnak el a tanító halmazt a legjobban közelítő konfigurációhoz. Kimutatható, hogy a Boltzmann-gépek nagyon közeli rokonságban vannak bizonyos speciális Bayes-hálókkal, amelyeket sztochasztikus szimulációs algoritmussal értékelünk ki. (Lásd 14.5. alfejezet.)</p><p>A kernelgépek alapötletének első alkalmazása Aizerman és társai munkájához fűződik (Aizerman és társai, 1964, de a szupport vektor gépek felé mutató, teljes elméleti kidolgozás Vlagyimir Vapniknak és kollégáinak köszönhető (Boser és társai, 1992; Vapnik, 1998). A precíz elméleti tárgyalás megtalálható Cristianini és Shawe-Taylor, illetve Schölkopf és Smola könyvében (Cristianini és Shawe-Taylor, 2000; Schölkopf és Smola, 2002), valamint egy barátságosabb kifejtés található Cristianini és Schölkopf <span class="emphasis"><em>AI Magazine</em></span>-ban megjelent cikkében.</p><p>Ennek a fejezetnek az anyaga a statisztika, alakfelismerés és neurális hálók kutatásában elért eredményeket integrálja, tehát a történetet sokszor, sokféle módon elmondták már. A Bayes-statisztikáról jó publikációkat találunk, ilyenek például a (DeGroot, 1970), a (Berger, 1985), továbbá a (Gelman és társai, 1995). A statisztikus tanulás elméletének kiváló tárgyalása található a (Hastie és társai, 2001) munkában. Az alakosztályozás témakörében Duda és Hart könyve számít klasszikusnak (Duda és Hart, 1973), melynek nemrég új kiadása is megjelent (Duda és társai, 2001). A neurális hálókról a (Bishop, 1995) és a (Ripley, 1996) a legfontosabb könyvek. A számítógépes neurális tudományt a (Dayan és Abbott, 2001) könyv tárgyalja. A neurális hálók és hozzájuk kapcsolódó témák legfontosabb konferenciái az évente megrendezett NIPS- (Neural Information Processing Conference) konferenciák, melyek kiadványait az <span class="emphasis"><em>Advances in Neural Information Processing Systems</em></span> sorozatban jelentetik meg. A Bayes-hálók tanulásáról szóló írások az <span class="emphasis"><em>Uncertainty in AI</em></span> és a <span class="emphasis"><em>Machine Learning</em></span> konferenciákon jelennek meg, továbbá számos statisztikával foglalkozó konferencián. A neurális hálókkal foglalkozó újságok között érdemes megemlíteni a <span class="emphasis"><em>Neural Computation</em></span>t, a <span class="emphasis"><em>Neural Networks</em></span>öt és az <span class="emphasis"><em>IEEE Transaction on Neural Networks</em></span>öt.</p></div><div class="section" title="Feladatok"><div class="titlepage"><div><div><h2 class="title"><a id="id750872"/>Feladatok</h2></div></div></div><p><span class="strong"><strong>20.1.	</strong></span></p><p>A 20.1. ábrán használt adatokat úgy tekinthetjük, mintha <span class="emphasis"><em>h</em></span><sub>5</sub> generálta volna őket. A másik négy hipotézis mindegyikére generáljon egy-egy 100 hosszúságú adathalmazt, rajzolja fel a megfelelő <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>h<sub>i</sub></em></span>|<span class="emphasis"><em>d</em></span><sub>1</sub>,…, <span class="emphasis"><em>d<sub>m</sub></em></span>) és <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>D<sub>m</sub></em></span><sub>+1</sub> = <span class="emphasis"><em>citrom</em></span>|<span class="emphasis"><em>d</em></span><sub>1</sub>,…, <span class="emphasis"><em>d<sub>m</sub></em></span>) görbéket! Értékelje az eredményeket.</p><p><span class="strong"><strong>20.2.	</strong></span></p><p>Ismételje meg a 20.1. feladatot úgy, hogy a <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>D</em></span><sub><span class="emphasis"><em>m</em></span>+1</sub> = <span class="emphasis"><em>citrom</em></span>|<span class="emphasis"><em>h</em></span><sub>map</sub>,…, <span class="emphasis"><em>d<sub>m</sub></em></span>), illetve <span class="emphasis"><em>P</em></span>(<span class="emphasis"><em>D</em></span><sub><span class="emphasis"><em>m</em></span>+1</sub> = <span class="emphasis"><em>citrom</em></span>|<span class="emphasis"><em>h</em></span><sub>ml</sub>) görbéket rajzolja fel.</p><p><span class="strong"><strong>20.3.	</strong></span></p><p>Tegyük fel, hogy Anna számára a meggycukorkák hasznossága <span class="emphasis"><em>c<sub>A</sub></em></span>, a citromcukorkáké <span class="emphasis"><em>ℓ<sub>A</sub></em></span>, míg Béla számára a hasznosságok rendre <span class="emphasis"><em>c<sub>B</sub></em></span> és <span class="emphasis"><em>ℓ<sub>B</sub></em></span>. (De ha Anna kibontott egy cukorkát, akkor azt Béla már nem fogja megvásárolni tőle.) Ha Béla sokkal jobban szereti a citromízű cukorkát, mint Anna, akkor Anna feltehetőleg bölcsen teszi, ha eladja a cukros zacskóját, amikor már kellően biztos a citromízűek arányában. Másrészről viszont, ha Anna túl sok cukrot kibontott már az arány eldöntése során, akkor a zacskó értéktelenné válik. Vizsgálja meg a cukroszacskó-eladás optimális pillanatának meghatározását. Határozza meg az optimális eljárás várható hasznosságát, a 20.1. alfejezet a priori eloszlásainak feltételezésével.</p><p><span class="strong"><strong>20.4.	</strong></span></p><p>Két statisztikus elmegy az orvoshoz, és mindkettőről ugyanazt a diagnózist állítja fel az orvos: 40% eséllyel a halálos <span class="emphasis"><em>A</em></span> betegségben, 60% eséllyel a szintén végzetes <span class="emphasis"><em>B</em></span> betegségben szenvednek. Szerencsére van az <span class="emphasis"><em>A</em></span> és <span class="emphasis"><em>B</em></span> betegségnek is olcsó, 100%-ban hatásos, mellékhatás nélküli gyógyszere. A statisztikusoknak lehetőségük van az <span class="emphasis"><em>A</em></span> elleni, a <span class="emphasis"><em>B</em></span> elleni vagy mindkét gyógyszert szedni, de dönthetnek úgy is, hogy egyiket sem szedik. Mit fog az első statisztikus – aki elszánt Bayes-hívő – választani? Mit tesz a második, aki mindig a maximum-likelihood hipotézist választja?</p><p> Az orvos némi kutatás után felfedezi, hogy a <span class="emphasis"><em>B</em></span> betegségnek két változata van, a dextro-<span class="emphasis"><em>B</em></span> és a levo-<span class="emphasis"><em>B</em></span>, amelyek egyforma valószínűséggel lépnek fel, és egyformán jól kezelhetők az anti-<span class="emphasis"><em>B</em></span> gyógyszerrel. Mit fog csinálni a két statisztikus most, hogy három hipotézis van?</p><p><span class="strong"><strong>20.5.	</strong></span></p><p>Magyarázza meg, hogyan alkalmazható a 18. fejezetben tárgyalt turbózás módszere a naiv Bayes-tanulásra. Tesztelje a kapott algoritmust az étterem tanulási problémán.</p><p><span class="strong"><strong>20.6.	</strong></span></p><p>Vegyen <span class="emphasis"><em>m</em></span> darab (<span class="emphasis"><em>x<sub>j</sub></em></span>, <span class="emphasis"><em>y<sub>j</sub></em></span>) adatpontot, az <span class="emphasis"><em>x<sub>j</sub></em></span>-ből a (20.5) egyenlet alapján generálja<span class="emphasis"><em> y<sub>j</sub></em></span>-t. Keresse meg azokat a <span class="emphasis"><em>θ</em></span><sub>1</sub>, <span class="emphasis"><em>θ</em></span><sub>2</sub> és <span class="emphasis"><em>σ</em></span> értékeket, amelyek maximálják az adatok feltételes log likelihood értékét.</p><p><span class="strong"><strong>20.7.	</strong></span></p><p>Vizsgálja a láz 14.3. alfejezetben bemutatott zajos-VAGY modelljét. Magyarázza meg, hogyan alkalmazható a maximum-likelihood tanulás arra, hogy egy teljes adathalmazra illesszük egy ilyen modell paramétereit. (<span class="emphasis"><em>Segítség:</em></span> a parciális deriváltakra használja a láncszabályt.)</p><p><span class="strong"><strong>20.8.	</strong></span></p><p>Ebben a feladatban a (20.6) egyenlettel definiált béta-eloszlások tulajdonságait vizsgáljuk.</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>A [0, 1] tartomány feletti integrálás alapján mutassa meg, hogy a béta[<span class="emphasis"><em>a</em></span>,<span class="emphasis"><em>b</em></span>] eloszlás normalizáló faktorát <span class="emphasis"><em>α</em></span> = Γ(<span class="emphasis"><em>a + b</em></span>)/ Γ(<span class="emphasis"><em>a</em></span>) Γ(<span class="emphasis"><em>b</em></span>) adja, ahol Γ(<span class="emphasis"><em>x</em></span>) az úgynevezett <span class="strong"><strong>gamma-függvény</strong></span>, amelynek definíciója: Γ(<span class="emphasis"><em>x + </em></span>1) = <span class="emphasis"><em>x</em></span>  × Γ(<span class="emphasis"><em>x</em></span>) és Γ(1) = 1. (Egész <span class="emphasis"><em>x</em></span>-ekre Γ(<span class="emphasis"><em>x + </em></span>1) = <span class="emphasis"><em>x</em></span>!)</p></li><li class="listitem"><p>Mutassa meg, hogy az átlagérték <span class="emphasis"><em>a/</em></span>(<span class="emphasis"><em>a + b</em></span>).</p></li><li class="listitem"><p>Állítsa elő a modus(oka)t (a legvalószínűbb <span class="emphasis"><em>θ</em></span> értéke(ke)t).</p></li><li class="listitem"><p>Jellemezze a béta[<span class="emphasis"><em>ε</em></span>, <span class="emphasis"><em>ε</em></span>] eloszlást nagyon kis<span class="emphasis"><em> ε</em></span> esetén. Mi történik, ha egy ilyen eloszlást frissítünk?</p></li></ol></div><p><span class="strong"><strong>20.9.	</strong></span></p><p>Vegyen egy tetszőleges Bayes-hálót, egy ehhez a hálóhoz tartozó teljes adathalmazt és az adathalmaznak a háló által megadott likelihood-értékét. Adjon egyszerű bizonyítást arra, hogy az adathalmaz likelihood-értéke nem csökkenhet, ha a hálóhoz hozzáadunk egy új kapcsolatot, majd újraszámoljuk a maximum-likelihood paramétereket.</p><p><span class="strong"><strong>20.10.	</strong></span></p><p>Vizsgálja meg az EM alkalmazását arra a problémára, amikor a 20.10. (a) ábrán látható háló paramétereit akarjuk tanulni, miközben az igazi paraméterértékeketa (20.7) egyenlet adja.</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Magyarázza meg, hogy miért nem működne az EM algoritmus, ha csak két attribútum volna, és nem három.</p></li><li class="listitem"><p>Végezze el az első iterációra vonatkozó számítást a (20.8) egyenletből kiindulva.</p></li><li class="listitem"><p>Mi történik, ha induláskor az összes paramétert ugyanarra a <span class="emphasis"><em>p</em></span> értékre állítjuk? (<span class="emphasis"><em>Segítség:</em></span> hasznos lehet, ha empirikusan megvizsgálja, mielőtt az általános eredményt megpróbálná levezetni.)</p></li><li class="listitem"><p>Írja fel a <a class="xref" href="ch20s03.md#ID_836_oldal">„Rejtett változókkal felépített Bayes-hálók tanulása”</a> részben található adattáblázatra a log likelihoodnak a paraméterekkel kifejezett összefüggését. Számítsa ki minden egyes paraméterre a parciális derivált értékét! Vizsgálja meg a (c) részben rögzített pont jellegét.</p></li></ol></div><p><span class="strong"><strong>20.11.	</strong></span></p><p>Hozzon létre manuálisan egy olyan neurális hálót, amely két bemenetének az xor függvényét számítja ki. Bizonyosodjon meg arról, helyesen specifikálta-e azt, hogy milyen egységeket kell használni.</p><p><span class="strong"><strong>20.12.	</strong></span></p><p>Hozzon létre egy olyan szupport vektor gépet, amely az xor függvényt számítja ki. Kényelmesebb lesz, ha mind a bemeneteknél, mind a kimenetnél –1-et és +1-et használ 0 és +1 helyett. Ennek megfelelően egy minta például ([–1, 1], 1) vagy ([–1, –1], –1) lesz. Tipikus, hogy az <span class="strong"><strong>x</strong></span> bemenetet egy ötdimenziós térre képezzük le, ahol kettő az eredeti <span class="emphasis"><em>x</em></span><sub>1</sub> és <span class="emphasis"><em>x</em></span><sub>2</sub> dimenzió, a másik három pedig <span class="emphasis"><em>x</em></span><sub>1</sub><sup>2</sup>, <span class="emphasis"><em>x</em></span><sub>2</sub><sup>2</sup>, illetve <span class="emphasis"><em>x</em></span><sub>1</sub> <span class="emphasis"><em>x</em></span><sub>2</sub> kombinációi. Ebben a feladatban viszont csak két dimenziót használunk: <span class="emphasis"><em>x</em></span><sub>1</sub>-et és <span class="emphasis"><em>x</em></span><sub>1</sub> <span class="emphasis"><em>x</em></span><sub>2</sub>-t. Rajzolja fel ebben a térben a négy bemeneti pontot és a maximális tartalékkal rendelkező osztályozót. Mekkora a tartalék? Rajzolja meg a határoló vonalat az eredeti, euklideszi térben.</p><p><span class="strong"><strong>20.13.	</strong></span></p><p>Egy egyszerű perceptron nem képes az xor függvény (vagy általánosabban a paritásfüggvény) ábrázolására. Mutassa be, hogy hogyan alakulnak egy négybemenetű, ugrásfüggvényt használó perceptron súlyai, amikor sorban a paritásfüggvényből származó minták érkeznek (kezdetben minden súly 0,1 értékű volt).</p><p><span class="strong"><strong>20.14.	</strong></span></p><p>Idézzük fel a 18. fejezetből, hogy <span class="emphasis"><em>n</em></span> bemenet esetén 2<sup>2 </sup> különböző logikai függvény létezik. Hányat tud reprezentálni ezek közül az ugrásfüggvényt használó perceptron?</p><p><span class="strong"><strong>20.15.	</strong></span></p><p>Vegyük a következő – hat bemeneti értéket (<span class="emphasis"><em>I</em></span><sub>1</sub>–<span class="emphasis"><em>I</em></span><sub>6</sub>) és egy, ezekhez tartozó kívánt kimeneti értéket (<span class="emphasis"><em>T</em></span>) megadó – mintahalmazt.</p><p><span class="inlinemediaobject"><img src="kepek/871-1.png" alt="Feladatok"/></span></p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Futassa a perceptron tanulási szabályt erre az adathalmazra, és adja meg a végső súlyokat.</p></li><li class="listitem"><p>Futassa a döntési fa tanulási algoritmust, és adja meg az eredményül kapott döntési fát.</p></li><li class="listitem"><p>Értékelje az eredményeket.</p></li></ol></div><p><span class="strong"><strong>20.16. </strong></span></p><p>A (20.13) egyenletből kiindulva mutassa meg, hogy ∂<span class="emphasis"><em>L/</em></span>∂<span class="emphasis"><em>W<sub>j</sub></em></span>  = <span class="emphasis"><em>Err </em></span>·<span class="emphasis"><em> x<sub>j</sub></em></span>.</p><p><span class="strong"><strong>20.17. </strong></span></p><p>Tegyük fel, hogy egy lineáris aktivációs függvényeket használó neurális hálónk van. Azaz minden neuron kimenete a bemenetek súlyozott összegének <span class="emphasis"><em>c</em></span>-szerese, ahol <span class="emphasis"><em>c</em></span> egy konstans.</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Tegyük fel, hogy a hálónak egy rejtett rétege van. Írja fel a súlyok egy adott <span class="strong"><strong>W</strong></span> értékkészletére azokat az egyenleteket, amelyek megadják a kimeneti réteg neuronjainak kimeneti értékeit <span class="strong"><strong>W</strong></span> és a bemeneti réteg <span class="strong"><strong>I</strong></span> értékeinek függvényében – anélkül hogy explicit módon megjelennének az egyenletekben a rejtett neuronok kimeneti értékei. Mutassa meg, hogy létezik olyan háló, amelynek nincs rejtett rétege, de ugyanezt a függvényt valósítja meg.</p></li><li class="listitem"><p>Ismételje meg az (a) rész alatti feladatot, de tetszőleges számú rejtett réteg esetére. Milyen következtetést vonhat le a lineáris aktivációs függvényekre?</p></li></ol></div><p><span class="strong"><strong>20.18.	</strong></span></p><div class="informalexample"><p/><p>Hozzon létre egy adatstruktúrát rétegekbe szervezett, előrecsatolt neurális hálók leírására, amely tartalmazza az előreterjesztéshez és a hiba-visszaterjesztéshez szükséges információt is. Ezt használva írjon egy <code class="code">NEURÁLIS-HÁLÓ-KIMENET</code> nevű programot, amely egy mintát és egy neurális hálót kap bemenetként, és kiszámítja a neurális hálónak a mintára adott kimeneti válaszát.</p><p/></div><p><span class="strong"><strong>20.19.	</strong></span></p><p>Tegyük fel, hogy egy tanító halmaz csupán egyetlen példát tartalmaz, de azt 100-szor. A 100 esetből 80-ban az egyetlen kimeneti érték 1; a másik 20-ban 0. Mit ad erre a példára egy hiba-visszaterjesztéssel tanított háló, ha tanítottuk, és elérte a globális optimumot? (<span class="emphasis"><em>Segítség: </em></span>a globális optimum megtalálásához differenciálja a hibafüggvényt, és keresse a nullahelyét.)</p><p><span class="strong"><strong>20.20.	</strong></span></p><p>A 20.24. ábrán látható hálónak négy rejtett neuronja van. Ezt a neuronszámot némiképpen ötletszerűen választottuk. Végezzen szisztematikus kísérleteket, hogy különböző számú rejtett neuronnal rendelkező hálókra lemérje a tanulási görbét. Mi az optimális neuronszám? Lehetséges lenne keresztvalidációs módszerrel megtalálni a legjobb hálót még a kísérletek előtt?</p><p><span class="strong"><strong>20.21.	</strong></span></p><p>Vegyük azt a problémát, amikor <span class="emphasis"><em>N</em></span> adatpontot akarunk lineáris osztályozóval szétválasztani pozitív és negatív példákra. Nyilvánvaló, hogy <span class="emphasis"><em>N = </em></span>2 pont esetén ez egy <span class="emphasis"><em>d = </em></span>1 dimenziós egyenesen mindig megtehető, függetlenül attól, hogy a pontok hol helyezkednek el, és hogy vannak címkézve (kivéve, ha ugyanazon a helyen vannak).</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Mutassa meg, hogy a szeparálás mindig elvégezhető <span class="emphasis"><em>N = </em></span>3 pontra egy <span class="emphasis"><em>d = </em></span>2 dimenziós síkon, ha a pontok nem egy egyenesre esnek.</p></li><li class="listitem"><p>Mutassa meg, hogy nem lehet mindig elvégezni a szeparálást <span class="emphasis"><em>N = </em></span>4 pontra egy <span class="emphasis"><em>d = </em></span>2 dimenziós síkon.</p></li><li class="listitem"><p>Mutassa meg, hogy a szeparálás mindig elvégezhető <span class="emphasis"><em>N = </em></span>4 pontra egy <span class="emphasis"><em>d = </em></span>3 dimenziós térben, ha a pontok nem esnek egy síkra.</p></li><li class="listitem"><p>Mutassa meg, hogy nem lehet mindig elvégezni a szeparálást <span class="emphasis"><em>N </em></span> = 5 pontra egy <span class="emphasis"><em>d = </em></span>3 dimenziós térben.</p></li><li class="listitem"><p>Egy törekvő diák kitűzheti maga elé, hogy bebizonyítja: <span class="emphasis"><em>N </em></span>– 1 dimenziós térben általános helyzetben található <span class="emphasis"><em>N</em></span> pont lineárisan szeparálható (de <span class="emphasis"><em>N</em></span> + 1 nem). Ebből következik, hogy az <span class="emphasis"><em>N </em></span>– 1 dimenziós lineáris félterek <span class="strong"><strong>VC-dimenzió</strong></span>ja (lásd 18. fejezet) <span class="emphasis"><em>N</em></span>.</p></li></ol></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id750664" href="#id750664" class="para">210</a>] </sup> <span class="emphasis"><em>Homeosztázis</em></span>: egy szervezet különböző, de egymással kölcsönhatásban álló elemei vagy elemek csoportjai között fennálló stabil egyensúly vagy egyensúly felé való törekvés. Gyakran biológiai összefüggésben használt kifejezés. (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id750740" href="#id750740" class="para">211</a>] </sup> Ez nagyjából igazolta „Bernie bácsi” törvényét: a szabályt Bernie Widrowról nevezték el, aki azt javasolta, hogy nagyjából tízszer annyi mintát használjanak, mint a súlyok száma.</p></div></div></div></body></html>
