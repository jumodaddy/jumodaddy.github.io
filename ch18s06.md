<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="section" title="Összefoglalás"><div class="titlepage"><div><div><h1 class="title"><a id="id727774"/>Összefoglalás</h1></div></div></div><p>Ebben a fejezetben determinisztikus függvények példák alapján való induktív tanulására koncentráltunk. A főbb pontok a következők voltak:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>A tanulásnak számos formája van, amely a cselekvő alrendszer jellegétől, a javítani kívánt komponenstől és a rendelkezésre álló visszacsatolástól függ.</p></li><li class="listitem"><p>Ha akár egy tanár, akár a környezet lehetővé teszi a minták helyes értékének visszacsatolását, akkor <span class="strong"><strong>ellenőrzött tanulás</strong></span>i (<span class="strong"><strong>supervised learning</strong></span>) problémáról beszélünk. A feladat, amelyet <span class="strong"><strong>induktív tanulás</strong></span>nak (<span class="strong"><strong>inductive learning</strong></span>) is nevezhetünk, abban áll, hogy egy függvényt kell megtanulnunk annak bemeneti és kimeneti mintái alapján. Diszkrét értékkészletű függvény tanulását <span class="strong"><strong>osztályozás</strong></span>nak (<span class="strong"><strong>classificatio</strong></span><span class="strong"><strong>n</strong></span>), folytonos értékű függvény tanulását pedig <span class="strong"><strong>regresszió</strong></span>nak (<span class="strong"><strong>regression</strong></span>) nevezzük.</p></li><li class="listitem"><p>Az induktív tanulás magában foglalja, hogy egy, a példákkal <span class="strong"><strong>konzisztens</strong></span> hipotézist kell találnunk. Az <span class="strong"><strong>Ockham borotvája</strong></span> (<span class="strong"><strong>Ockham’s razor</strong></span>) elv értelmében célszerű a legegyszerűbb konzisztens hipotézis választása. Ennek a feladatnak a nehézségét a választott reprezentáció döntően befolyásolja.</p></li><li class="listitem"><p>A <span class="strong"><strong>döntési fá</strong></span>k (<span class="strong"><strong>decision tree</strong></span>s) alkalmasak tetszőleges Boole-függvény reprezentálására. Az <span class="strong"><strong>információnyereség</strong></span>re (<span class="strong"><strong>information gain</strong></span>) alapozó heurisztika hatékony módszert biztosít egyszerű, konzisztens döntési fák konstruálására.</p></li><li class="listitem"><p>A tanulási algoritmus teljesítményét a <span class="strong"><strong>tanulási görbé</strong></span>n (<span class="strong"><strong>learning curve</strong></span>) mérhetjük le, amely a <span class="strong"><strong>teszthalmaz</strong></span>on (<span class="strong"><strong>test set</strong></span>) mért predikciós pontosságot mutatja a <span class="strong"><strong>tanító halmaz</strong></span> (<span class="strong"><strong>training set</strong></span>) méretének függvényében.</p></li><li class="listitem"><p>Az együttes tanulási módszerek, például a <span class="strong"><strong>turbózás</strong></span> (<span class="strong"><strong>boosting</strong></span>), gyakran jobb eredményt érnek el, mint az egyedi módszerek.</p></li><li class="listitem"><p>A <span class="strong"><strong>tanulás számítási elmélete</strong></span> (<span class="strong"><strong>computational learning theory</strong></span>) az induktív tanulás minta komplexitásának és számítási komplexitásának analízisére koncentrál. Kompromisszumot kell kötnünk a hipotézis nyelv kifejezőképessége és a tanulás nehézsége között.</p></li></ul></div><div class="section" title="Irodalmi és történeti megjegyzések"><div class="titlepage"><div><div><h2 class="title"><a id="id727935"/>Irodalmi és történeti megjegyzések</h2></div></div></div><p>Az 1. fejezet felvázolta az induktív tanulás filozófiai vizsgálatának történetét. William of Ockham (1280–1349) volt korának legnagyobb hatású filozófusa és a középkori ismeretelmélet, a logika és a metafizika egyik nagy alakja. Neki tulajdonítják azt a mondást, ami „Ockham borotvája” néven rögzült a köztudatban. Latinul: <span class="emphasis"><em>Entia non sunt multiplicanda praeter necessitatem,</em></span> ami azt jelenti magyarul, hogy „A dolgokat nem kell a szükségesnél jobban bonyolítani”. Sajnos ez a dicséretes mondás sehol sem található meg a műveiben pontosan így megfogalmazva.</p><p>Az EPAM (Elementary Perceiver And Memorizer, Elemi észlelő és megjegyző) volt az első rendszerek egyike, amely döntési fákat (<span class="strong"><strong>diszkriminációs háló</strong></span>kat, <span class="strong"><strong>discrimination </strong></span><span class="strong"><strong>net</strong></span>s) használt (Feigenbaum, 1961). Az EPAM létrehozásának célja az emberi fogalom-tanulás kognitív-szimulációs modelljének megalkotása volt. A CLS-rendszer (Hunt és társai, 1979) heurisztikus előretekintő eljárást használt a döntési fák konstrukciójára. Az ID3 (Quinlan, 1979) hozta azt a kulcsfontosságú ötletet, hogy a heurisztikus függvény használja az információtartalmat. Az információelméletet Claude Shannon fejlesztette ki a kommunikáció tanulmányozására (Shannon és Weaver, 1949). (Shannon hozzájárult a gépi tanulás területéhez is, az egyik legkorábbi példát szolgáltatva mechanikus egerével, amely egy útvesztőben navigált a kísérlet-kudarc elvet használva.) A döntési fák <span class="emphasis"><em>χ</em></span><sup>2</sup> metszését Quinlan írta le először (Quinlan, 1986). Az ipari felhasználásra alkalmas C4.5 döntési fa programcsomag is Quinlan munkáiban található meg (Quinlan, 1993). A döntési fa tanulásnak egy, az előzőktől független hagyománya alakult ki a statisztikusok körében. A <span class="emphasis"><em>Classification and Regression Trees</em></span> (Breiman és társai, 1984), amelyet röviden „CART könyv”-nek neveznek, az alapvető irodalom e tekintetben.</p><p>A tanulás számos másik algoritmikus megközelítését is vizsgálták. A <span class="strong"><strong>pillanatnyilag-</strong></span><span class="strong"><strong>legjobb-hipotézis</strong></span> (<span class="strong"><strong>current-best-hypothesis</strong></span>) megközelítés egyetlen hipotézissel foglalkozik, specializálva, ha túl tágnak bizonyul, általánosítva, ha túl szűk. Ez a filozófiában már régóta ismert elv (Mill, 1843). A kognitív pszichológia korai munkájában szintén ezt javasolták, mint az emberi fogalom tanulás természetes formáját (Bruner és társai, 1957). Az MI-területen ez a megközelítés elsősorban Patrick Winston munkájához köthető, aki PhD-disszertációjában (Winston, 1970) a komplex objektumok leírásának tanulásával foglalkozott. A <span class="strong"><strong>verziótér</strong></span> (<span class="strong"><strong>version space</strong></span>) módszer (Mitchell, 1977; 1982) eltérő megközelítésen alapul, az összes konzisztens hipotézissel egyszerre foglalkozik, elhagyva azokat, amelyek az új példákkal inkonzisztenciát mutatnak. Ezt a megközelítést a <code class="code">META-DENDRAL</code> kémiai szakértő rendszerben használták (Buchanan és Mitchell, 1978), majd később Mitchell <code class="code">LEX</code> rendszerében (Mitchell, 1983), ami matematikai analízis problémák tanulással történő megoldását célozta. A harmadik nagyhatású irányzat kialakítása Michalski és társai munkájához köthető, akik az AQ algoritmusok sorozatával foglalkoztak, amelyek logikai szabályok halmazát tanulták (Michalski, 1969; Michalski és társai, 1986b).</p><p>Az együttes tanulás a tanuló algoritmusok teljesítménynövelésének egyre népszerűbb módszere. A <span class="strong"><strong>zsákolás</strong></span> (<span class="strong"><strong>bagging</strong></span>)<sup>[<a id="id728014" href="#ftn.id728014" class="footnote">187</a>]</sup> (Breiman, 1966) az első hatékony módszer, amely többféle <span class="strong"><strong>indító</strong></span> (<span class="strong"><strong>bootstrap</strong></span>) adathalmaz alapján megtanult hipotézisek kombinációját hozza létre. Ezeket az adathalmazokat az eredeti alulmintavételezésével állítják elő. A fejezetben ismertetett <span class="strong"><strong>turbózás</strong></span> (<span class="strong"><strong>boosting</strong></span>) módszere eredetileg Schapire elméleti munkájából (Schapire, 1990) származik. Az AdaBoost algoritmust Freund és Schapire dolgozta ki (Freund és Schapire, 1996), és Schapire adta meg elméleti analízisét (Schapire, 1999). Friedman és társai statisztikai alapon tárgyalják a turbózás módszerét (Friedman és társai, 2000).</p><p>A tanulási algoritmusok elméleti vizsgálata Gold  munkájával kezdődött (Gold, 1967) az <span class="strong"><strong>identifikáció határátmenet</strong></span>ben (<span class="strong"><strong>identification in the limit</strong></span>) probléma tanulmányozásával. Ez a megközelítés ugyan részben tudományfilozófiai felfedezésből eredt (Popper, 1962), de alkalmazásának legfőbb területe nyelvtanok példamondatok alapján történő tanulása volt (Osherson és társai, 1986).</p><p>Míg az identifikáció határátmenetben megközelítés a végső konvergenciára koncentrál, addig a <span class="strong"><strong>Kolmogorov-komplexitás</strong></span> (<span class="strong"><strong>Kolmogorov complexity</strong></span>) vagy más néven <span class="strong"><strong>algoritmikus komplexitás</strong></span> (<span class="strong"><strong>algorithmic complexity</strong></span>), amelyet egymástól függetlenül Solomonoff (1964) és Kolmogorov (1965) fejlesztett ki, formális definíciót próbál adni az Ockham borotvája elvben használt egyszerűségnek. Hogy valahogy kimeneküljenek abból a csapdából, hogy az egyszerűség függ az információ reprezentációjának módjától, azt javasolták, hogy az egyszerűséget annak a legrövidebb programnak a hosszával mérjék, amely egy általános Turing-gépen helyesen adja vissza a megfigyelt adatokat. Bár sok különböző általános Turing-gépet lehet létrehozni, és így több különböző „legrövidebb” program lehetséges, ezek hossza legfeljebb csak egy konstansban tér el, amely független az adatok mennyiségétől. Ezt a gyönyörű eredményt, amely betekintést nyújt abba, hogy <span class="emphasis"><em>bármely</em></span> előzetes reprezentációs eltérést végül maguk az adatok győznek le, csupán az teszi tönkre, hogy a legrövidebb program hosszának kiszámítása eldönthetetlen problémára vezet. Közelítő mértékeket lehet alkalmazni, például a <span class="strong"><strong>legrövidebb leíró hossz</strong></span>t (<span class="strong"><strong>minimum description length</strong></span>) vagy LLH-t (Rissanen, 1984), amivel kimagasló gyakorlati eredményeket értek el. Li és Vitányi írása a Kolmogorov komplexitás legjobb összefoglalása (Li és Vitányi, 1993).</p><p>A tanulás számítási elméletét – azaz a VKH-tanulás elméletét – Lesli Valiant vezette be (Valiant, 1984). Valiant munkája a számítási komplexitásra és a mintakomplexitásra helyezte a fő hangsúlyt. Michael Kearnsszel együtt Valiant megmutatta, hogy számos olyan fogalomosztály van, amely VKH-tanulással nem kezelhető probléma, még akkor sem, ha a példák elegendő információt nyújtanak. Bizonyos problémaosztályokban, például döntési listáknál, elértek néhány pozitív eredményt (Rivest, 1987).</p><p>A mintakomplexitás vizsgálatának ettől független tradícióját találhatjuk a statisztikusok körében, amely az <span class="strong"><strong>egyenletes konvergencia elméleté</strong></span>nek (<span class="strong"><strong>uniform convergence t</strong></span><span class="strong"><strong>heory</strong></span>) vizsgálatával kezdődött (Vapnik és Cservonenkis, 1971). Az úgynevezett <span class="strong"><strong>VC-dimenzió</strong></span> nagyjából a VKH tanulásból származó  mértékhez hasonló – bár annál általánosabb – mértéket ad. A VC-dimenzió, ellentétben a VKH-analízissel, folytonos függvényosztályokra is alkalmazható. A VKH-analízis és a VC elmélet között először a „négy német”, Blumer, Ehrenfeucht, Haussler és Warmuth (1989) teremtett kapcsolatot (akik közül valójában egyik sem német). A VC elmélet további fejlődése vezetett a <span class="strong"><strong>szupport vektorgé</strong></span><span class="strong"><strong>p</strong></span> vagy <span class="strong"><strong>SVM</strong></span><sup>[<a id="id728819" href="#ftn.id728819" class="footnote">188</a>]</sup> (<span class="strong"><strong>support vector machine</strong></span>) kidolgozásához (Boser és társai, 1992; Vapnik, 1998). A szupport vektorgéppel a 20. fejezetben foglalkozunk.</p><p>Nagyon sok, a gépi tanulással foglalkozó fontos publikációt gyűjtöttek egybe a <span class="emphasis"><em>Readings in Machine Learning</em></span> c. kötetben (Shavlik és Dietterich, 1990). A kétkötetes <span class="emphasis"><em>Machine Learning 1 </em></span>(Michalski és társai, 1983), illetve <span class="emphasis"><em>Machine Learning 2</em></span> (Michalski és társai, 1986a) is sok fontos közlést tartalmaz, továbbá hatalmas bibliográfiát. Weiss és Kulikowski a függvény tanulás áttekinthető bevezetését adja gépi tanulási, statisztikai és neurális alapokon (Weiss és Kulikowski, 1991). A <code class="code">STATLOG</code> projektben (Michie és társai, 1994) végezték a tanuló algoritmusok teljesítményének messze legkimerítőbb összehasonlítását. A jelenleg is folyó, a gépi tanulással foglalkozó fontos kutatási eredmények az International Conference on Machine Learning éves kiadványaiban, a Neural Information Processing Systems konferencián, a <span class="emphasis"><em>Machine Learning</em></span> és a <span class="emphasis"><em>Journal of Machine Learning Research</em></span> folyóiratokban, továbbá a fontosabb MI-újságokban jelennek meg. A tanulás számítási elméletének eredményei megjelennek az éves ACM Workshop on Computational Learning Theory (COLT) kiadványokban, valamint Kearns és Vazirani (1994), továbbá Anthony és Bartlett (1999) publikációiban.</p></div><div class="section" title="Feladatok"><div class="titlepage"><div><div><h2 class="title"><a id="id728856"/>Feladatok</h2></div></div></div><p><span class="strong"><strong>18.1.</strong></span></p><p>Vizsgálja meg a beszélni, illetve egy nyelvet megérteni tanuló gyerek problémáját! Magyarázza meg, hogy ez a folyamat hogyan illeszkedik az általános tanulási modellhez, és megfelelően azonosítsa a modell egyes komponenseit!</p><p><span class="strong"><strong>18.2.	</strong></span></p><p>Ismételje meg a 18.1. feladatot a tenisz (vagy valamilyen ön által ismert sport) tanulásának esetére! Ez felügyelt vagy megerősítéses tanulás?</p><p><span class="strong"><strong>18.3.	</strong></span></p><p>Rajzoljon fel egy döntési fát arra a problémára, hogy az útkereszteződésben elinduljunk-e előre, ha a lámpa éppen most váltott zöldre!</p><p><span class="strong"><strong>18.4.	</strong></span></p><p>Soha nem teszteljük kétszer ugyanazt az attribútumot a döntési fa egy útvonala mentén. Miért?</p><p><span class="strong"><strong>18.5.	</strong></span></p><p>Tegyük fel, hogy egy döntési fa segítségével generálunk egy tanító mintahalmazt, majd döntési fa tanulást alkalmazunk erre a halmazra. A tanulási algoritmus végül is a helyes döntési fát fogja visszaadni, ha a tanító halmaz mérete a végtelenhez tart? Miért, vagy miért nem?</p><p><span class="strong"><strong>18.6.	</strong></span></p><p>Egy jó „butácska” tanulási algoritmus a következő: készítsünk egy táblázatot az összes tanítópéldából. Vizsgáljuk meg, hogy milyen kimenet szerepel a legtöbbször a tanítópéldákban: jelöljük ezt <span class="emphasis"><em>d</em></span>-vel. Ezek után, ha olyan minta jelenik meg a bemeneten, ami nincs a táblázatban, akkor adjunk vissza <span class="emphasis"><em>d</em></span>-t. Olyan bemenetekre, amelyek megtalálhatók a táblában, adjuk vissza a táblázatban a bemenethez asszociált kimeneti értéket (vagy ha egynél több kimeneti érték van azonos bemenethez, akkor a leggyakrabban előfordulót). Implementálja ezt az algoritmust, és vizsgálja meg egy példának választott területen (például az étterem problémán) azt, hogy mennyire működik jól! Ennek alapján fogalmat alkothatunk a tanulás területének alapszintjéről – a minimális elvárható teljesítményről, amelyet minden tanuló algoritmusnak el kell érnie.</p><p><span class="strong"><strong>18.7.	</strong></span></p><p>Tegyük fel, hogy egy új algoritmussal tanulási kísérletet folytat. Egy adathalmazt használ, amiben 25-25 példa van az előforduló két osztályra. Azt tervezi, hogy a hagyj-ki-egyet keresztvalidációs módszert fogja használni. Összehasonlítási alapként egy egyszerű többségi szavazót használ. (A többségi szavazónak megadva egy tanító halmazt, a bemenetektől függetlenül mindig azt a kimenetet adja, amely kimeneti érték a halmazban legtöbbször előfordul.) Azt várta, hogy a többségi szavazó, a hagyj-ki-egyet keresztvalidációban nagyjából 50%-ot fog elérni, de meglepetésére 0% az eredmény. Meg tudja magyarázni, hogy miért?</p><p><span class="strong"><strong>18.8.	</strong></span></p><p>A döntési fák rekurzív előállítása során néha előfordul, hogy pozitív és negatív példák vegyes halmaza marad egy levélcsomópontban, még akkor is, ha az öszszes attribútumot használtuk már. Tegyük fel, hogy <span class="emphasis"><em>p</em></span> pozitív és <span class="emphasis"><em>n</em></span> negatív példánk van.</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Mutassa meg, hogy a <code class="code">DÖNTÉSI-FA-TANULÁS</code> algoritmusban használt megoldás, amely a többségi osztályozást választja, minimalizálja a példahalmazra vonatkozó abszolút hibát a levélnél!</p></li><li class="listitem"><p>Mutassa meg, hogy a <span class="emphasis"><em>p</em></span>/(<span class="emphasis"><em>p</em></span> + <span class="emphasis"><em>n</em></span>) <span class="strong"><strong>osztály-valószínűség</strong></span> (<span class="strong"><strong>class probability</strong></span>) eredményként való visszaadása minimalizálja négyzetes hiba összegét!</p></li></ol></div><p><span class="strong"><strong>18.9.	</strong></span></p><p>Tegyük fel, hogy egy tanulási algoritmus konzisztens hipotézist keres, és az osztályozandó példákat véletlen módon generáljuk. A példákat egyenletes eloszlással választjuk az <span class="emphasis"><em>n</em></span> Boole-attribútum alapján kialakított 2<span class="emphasis"><em>n</em></span> példa lehetőségből. Számítsa ki, hány példa kell ahhoz, hogy egy ellentmondás felmerülésének a valószínűsége 0,5 legyen!</p><p><span class="strong"><strong>18.10.	</strong></span></p><p>Tegyük fel, hogy egy attribútum a példák <span class="emphasis"><em>E</em></span> halmazát <span class="emphasis"><em>E<sub>i</sub></em></span> részhalmazokra bontja, és mindegyik részhalmazban <span class="emphasis"><em>p<sub>i</sub></em></span> pozitív és <span class="emphasis"><em>n<sub>i</sub></em></span> negatív példa van. Mutassa meg, hogy ha a <span class="emphasis"><em>p<sub>i</sub></em></span>/(<span class="emphasis"><em>p<sub>i</sub></em></span> + <span class="emphasis"><em>n<sub>i</sub></em></span>) arány nem egyforma minden <span class="emphasis"><em>i</em></span>-re, akkor az attribútum információnyeresége biztosan pozitív!</p><p><span class="strong"><strong>18.11.	</strong></span></p><p>Módosítsa a <code class="code">DÖNTÉSI-FA-TANULÁS</code> algoritmust úgy, hogy tartalmazza a <span class="emphasis"><em>χ</em></span><sup>2</sup> metszést! A részleteket megtalálhatja Quinlan írásában (Quinlan, 1986).</p><p><span class="strong"><strong>18.12.	</strong></span></p><div class="informalexample"><p/><p>A fejezetben leírt standard <code class="code">DÖNTÉSI-FA-TANULÁS</code> algoritmus nem képes azon esetek kezelésére, amelyekben néhány példa esetén hiányoznak attribútumértékek.</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Először is valamilyen módszerre van szükségünk, amellyel egy adott döntési fa alapján be tudunk sorolni példákat akkor is, ha a fában olyan attribútumokra vonatkozó tesztek szerepelnek, amelyek értéke hiányozhat egyes példáknál. Tegyük fel, hogy az <span class="emphasis"><em>X</em></span> példa <span class="emphasis"><em>A</em></span> attribútumra vonatkozó értéke hiányzik, és a döntési fa teszteli <span class="emphasis"><em>A</em></span>-t egy olyan csomópontban, amit <span class="emphasis"><em>X</em></span> elér. Ennek az esetnek egyik kezelési lehetősége, hogy úgy teszünk, mintha a példa az összes lehetséges attribútumértékkel rendelkezne, de súlyozzuk az egyes értékeket azzal a gyakorisággal, amelyet az összes olyan példán mérünk, amely eléri a döntési fa ezen csomópontját. A besorolási algoritmusnak minden olyan csomópont összes ágát követnie kell, amelyben egy érték hiányzik, és mindegyik út mentén össze kell szoroznia a súlyokat. Írja meg azt a módosított döntési fa algoritmust, amely rendelkezik ezzel a tulajdonsággal!</p></li><li class="listitem"><p>Módosítsa az információnyereség számítást a következő módon: a fa építésének fázisában egy adott csomópontba jutó tetszőleges <span class="emphasis"><em>C</em></span> tanító példahalmaznál azok a példák, amelyeknek hiányzik bármely hátralevő (még nem vizsgált) attribútumhoz tartozó értéke, a <span class="emphasis"><em>C</em></span> halmazban ezen attribútumra előforduló értékgyakoriság szerint kapjanak „mint-ha” értéket! </p></li></ol></div><p/></div><p><span class="strong"><strong>18.13.	</strong></span></p><p>A 18. fejezetben megmutattuk, hogy azok az attribútumok, amelyeknek nagyon sokféle lehetséges értékük van, problémát jelenthetnek az információnyereség számításánál. Ezek az attribútumok jó eséllyel nagyon sok kis osztályra, akár egyelemű osztályokra bontják a halmazt, ezért úgy tűnik a nyereség számításánál, hogy nagyon fontosak az adott csomópontban. A <span class="strong"><strong>nyereségarány</strong></span> (<span class="strong"><strong>gain ratio</strong></span>) kritérium az attribútumokat az általuk hozott információnyereség és a saját belső információtartalmuk arányával méri. A belső információtartalom arra a kérdésre adott válasz, hogy „Mi az értéke ennek az attribútumnak?”. A nyereségarány kritérium ennek megfelelően azt próbálja mérni, hogy mennyire hatékony információt biztosít a példa helyes osztályozásához ez az attribútum. Alkossa meg az attribútum információtartalmának matematikai kifejezését, és módosítsa a <code class="code">DÖNTÉSI-FA-TANULÁS</code> algoritmust nyereségarány-alapúra!</p><p><span class="strong"><strong>18.14.	</strong></span></p><p>Egy együttes tanulási algoritmust vizsgál, amely M megtanult hipotézis eredményének egyszerű többségi szavazását használja. Tegyük fel, hogy az összes hipotézisnek  a hibája, és az egyes hipotézisek által elkövetett hibák függetlenek a többiek hibájától. Adja meg <span class="emphasis"><em>M</em></span> és <span class="emphasis"><em>ε</em></span> függvényében azt az összefüggést, amelylyel az együttes tanulással előállított eszköz hibája számítható, és számítsa ki <span class="emphasis"><em>M</em></span> = 5, 10 és 20, illetve <span class="emphasis"><em>ε </em></span>= 0,1, 0,2 és 0,4 esetén! Ha feladjuk a függetlenségre vonatkozó feltételezést, akkor előfordulhat-e, hogy az együttes hibája <span class="emphasis"><em>rosszabb</em></span> lesz, mint <span class="emphasis"><em>ε</em></span>?</p><p><span class="strong"><strong>18.15.	</strong></span></p><p>Ez a feladat a döntési listák kifejező erejével foglalkozik (lásd 18.5. alfejezet).</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Mutassa meg, hogy egy döntési lista képes bármely Boole-függvény reprezentálására, ha nem korlátozzuk a tesztek méretét!</p></li><li class="listitem"><p>Mutassa meg, hogy ha egy teszt legfeljebb <span class="emphasis"><em>k</em></span> literálist tartalmazhat, akkor a döntési lista minden olyan függvény reprezentálására képes, amely egy <span class="emphasis"><em>k</em></span> mélységű döntési fával reprezentálható!</p></li></ol></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id728014" href="#id728014" class="para">187</a>] </sup> A <span class="strong"><strong>bagging</strong></span> név eredetileg a „bootstrap aggregating” rövidítéseként jelent meg, de az angol „bag” szó jelentését nagyrészt átvette, ezért fordítottuk „zsákolásnak”. (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p><sup>[<a id="ftn.id728819" href="#id728819" class="para">188</a>] </sup> Magyarul is az SVM rövidítés terjedt el. (<span class="emphasis"><em>A ford.</em></span>)</p></div></div></div></body></html>
