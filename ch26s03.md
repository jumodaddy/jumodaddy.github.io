<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/></head><body><div class="section" title="A mesterséges intelligencia fejlesztésének etikai kérdései és kockázatai"><div class="titlepage"><div><div><h1 class="title"><a id="id797858"/>A mesterséges intelligencia fejlesztésének etikai kérdései és kockázatai</h1></div></div></div><p>Mindeddig arra összpontosítottunk, hogy <span class="emphasis"><em>képesek vagyunk-e</em></span> kifejleszteni egy mesterséges intelligenciát, most azt is meg kell vizsgálnunk, hogy <span class="emphasis"><em>kell-e </em></span>ezt tennünk. Amennyiben az MI-technológiák hatásai többségében inkább negatívak, mint pozitívak lennének, akkor morális felelőssége lenne az ezen a területen dolgozóknak, hogy más területekre helyezzék kutatásukat. Sok új technológia járt akaratlanul is negatív mellékhatásokkal: a belső égésű motor a légszennyezést hozta és azt, hogy még az Édenkertet is leaszfaltozták, a maghasadás felfedezése pedig a csernobili és a Three Mile Island-i<sup>[<a id="id797871" href="#ftn.id797871" class="footnote">283</a>]</sup> atomkatasztrófákat hozta, és a globális pusztulás veszélyének fenyegetését. Minden tudósnak és mérnöknek szembe kell néznie a munkájukkal kapcsolatos etikai kérdésekkel: mely projekteket szabad befejezni, és melyeket nem, és hogyan kell ezeket a projekteket kezelni. Még egy <span class="emphasis"><em>Ethics of Computing</em></span> (Berleur és Brunnstein, 2001) c. kézikönyv is létezik. A mesterséges intelligencia azonban, úgy tűnik, néhány új problémát is felvet, azon túl, hogy olyan hidakat akarunk építeni, amelyek nem dőlnek össze:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Az emberek az automatizáció miatt elveszíthetik a munkájukat.</p></li><li class="listitem"><p>Az embereknek túl sok (vagy túl kevés) szabadidejük marad.</p></li><li class="listitem"><p>Az emberek elveszíthetik az egyediségérzésüket.</p></li><li class="listitem"><p>Az emberek elveszíthetik a személyiségi jogaik egy részét.</p></li><li class="listitem"><p>Az MI-rendszerek alkalmazása megszüntetheti a felelősségre vonhatóságot.</p></li><li class="listitem"><p>A mesterséges intelligencia sikere az emberi faj végét jelentheti.</p></li></ul></div><p>Sorra vesszük mindegyik felvetett problémát.</p><p><span class="emphasis"><em>Az emberek az automatizáció miatt elveszíthetik a munkájukat. </em></span>A modern ipari gazdaság általában véve függővé vált a számítógépektől, sőt néhány különleges MI-programtól is. A gazdaság nagy része például, különösen az Egyesült Államokban, a fogyasztói hiteltől függ. A hitelkártya-kérelmek elbírálását, a lehívások engedélyezését és a visszaélések felderítését napjainkban mesterséges intelligencia programok végzik. Azt is mondhatná valaki, hogy ezek a programok több ezer dolgozót tettek munkanélkülivé, de valójában, ha elvennénk ezeket a mesterséges intelligencia programokat, nem is léteznének ilyen állások, mert az emberi munka elviselhetetlen többletköltséget róna ezekre a tranzakciókra. A mesterséges intelligenciát használó gépesítés mindeddig több állást hozott létre, mint ahányat megszüntetett, és ezek az új állások érdekesebbek, és jobban fizetnek. Ma már, amikor a mesterséges intelligencia programokat az embereket segítő „intelligens ágenseknek” tekintik, kevesebben félnek a munkahelyük elvesztésétől, mint amikor a mesterséges intelligencia célja az embereket helyettesítő „szakértői rendszerek” létrehozása volt.</p><p><span class="emphasis"><em>Az embereknek túl sok (vagy túl kevés) szabadidejük marad.</em></span> Alvin Toffler a <span class="emphasis"><em>Future Shock</em></span>-ban<span class="emphasis"><em> </em></span>(Toffler, 1970) ezt írta: „A századforduló óta a munkahét 50%-kal csökkent. Nem lóg ki a sorból ha azt jósoljuk, hogy 2000-re ismét felével csökken.” Arthur C. Clarke (Clarke, 1968b) azt írta, hogy 2001-ben az emberek talán már a „teljes unalommal néznek szembe, ahol az élet legnagyobb problémája a több száz tv-csatorna közti választás lesz”. Az egyetlen ezen jóslatok közül, amelyik közel áll a megvalósuláshoz, az a tv-csatornák száma (Springsteen, 1992). Valójában a tudásintenzív iparágakban dolgozó emberek egy 24 órában működő, integrált számítógépesített rendszer részévé válnak, és ahhoz, hogy lépést tartsanak, <span class="emphasis"><em>hosszabb</em></span> munkaórákra lettek kényszerítve. Az ipari gazdaságban a jutalom közelítőleg egyenesen arányos a befektetett idővel; 10%-kal több munka többé-kevésbé 10%-os bevételnövekedést jelent. Az információs gazdaságban, amelyet a nagy sávszélességű kommunikáció és a szellemi tulajdon könnyű replikációja jellemez (ezt nevezi Frank és Cook „a-győztes-mindent-visz társadalom”-nak) (Frank és Cook, 1996), nagy jutalom jár azért, ha valaki csak egy kicsit is jobb a versenyben: 10%-kal több munka akár 100%-os bevételnövekedést is jelenthet. Ezért egyre növekvő nyomás nehezedik mindenkire, hogy keményebben dolgozzon. A mesterséges intelligencia növeli a technológiai innováció ütemét, tehát hozzájárul ehhez az általános trendhez, de egyben a mesterséges intelligencia tartalmazza annak ígéretét is, hogy az automatizált ágensek kicsit átvállalják a teendőket és egy kis időhöz juttatnak minket.</p><p><span class="emphasis"><em>Az emberek elveszíthetik az egyediségérzésüket. </em></span>Weizenbaum, az <code class="code">ELIZA</code> program szerzője, <span class="emphasis"><em>Computer Power and Human Reason </em></span>(Weizenbaum, 1976) c. művében rámutat néhány potenciális veszélyre, amelyeket a mesterséges intelligencia jelent a társadalom számára. Weizenbaum egyik fő érve az, hogy a mesterséges intelligencia kutatása lehetővé teszi annak elképzelését, hogy az emberek automaták volnának, amely elgondolás az autonómia, vagy akár a humanitás érzésének megszűnéséhez vezet. Vegyük észre azonban, hogy ez az elképzelés jóval régebb óta van jelen, mint a mesterséges intelligencia: legalábbis a <span class="emphasis"><em>L’Homme Machine</em></span> (La Mettrie, 1748) c. könyvig vezethető vissza. Azt is vegyük észre, hogy az emberiség túlélte már az egyediségérzésnek más csökkenéseit is: A <span class="emphasis"><em>De Revolutionibus Orbium Coelestium </em></span>(Kopernikusz, 1543) kimozdította a Földet a Naprendszer központjából, és a <span class="emphasis"><em>Descent of Man </em></span>(Darwin, 1871) pedig a <span class="emphasis"><em>Homo sapienst</em></span> egy szintre helyezte a többi fajjal. A mesterséges intelligencia, amenynyiben széles körben sikeres lesz, éppen úgy veszélyt jelenthet a 21. század morális feltételezéseire, ahogyan Darwin evolúciós elmélete fenyegette a 19. század morális feltételezéseit.</p><p><span class="emphasis"><em>Az emberek elveszíthetik a személyiségi jogaik egy részét. </em></span>Weizenbaum arra is rámutatott, hogy a beszédfelismerési technológia a lehallgatás elterjedéséhez, és így a polgári jogok veszteségéhez vezethet. Nem láthatta előre azt a világot, ahol a terrorista fenyegetettség megváltoztatja, hogy az emberek mennyi megfigyelést hajlandók elfogadni, azt azonban helyesen ismerte fel, hogy a mesterséges intelligencia a tömeges megfigyelés eszközévé válhat. Jóslata talán már valóra is vált: az Egyesült Államok kormányának titkos Echelon-rendszere „felvevőállomások, antennamezők és radarállomások hálózatából áll, a rendszert nyelvek közti fordítást, beszédfelismerést és kulcsszavas keresést használó számítógépek támogatják, amelyek a telefon-, az e-mail, a fax- és a telexforgalmat vizsgálják végig.”<sup>[<a id="id797964" href="#ftn.id797964" class="footnote">284</a>]</sup> Néhányan elfogadják, hogy a számítógépesítés a magánszféra veszteségéhez vezet. Scott McNealy, a Sun Microsystems vezetője azt mondta: „Amúgy is nulla a magánszférád. Felejtsd el.” Mások nem értenek ezzel egyet: Louis Brandeis bíró<sup>[<a id="id797973" href="#ftn.id797973" class="footnote">285</a>]</sup> ezt írta 1890-ben: „A magánszférához való jog minden jogok legalapvetőbbike (…) a jog az ember saját személyiségéhez.”</p><p><span class="emphasis"><em>Az MI-rendszerek alkalmazása megszüntetheti a felelősségre vonhatóságot. </em></span>Az Egyesült Államokban ma uralkodó pereskedő közhangulat fontos kérdéssé tette a jogi felelősséget. Amikor egy orvos a diagnózis felállításakor egy orvosi szakértői rendszer ítéletére hagyatkozik, ki tehető felelőssé a diagnózis hibájáért? Szerencsés módon, és ez részben a döntéselméleti megközelítés orvoslásra gyakorolt egyre növekvő befolyásának köszönhető, ma már elfogadott alapelv, hogy az orvos, aki végrehajtja a nagy <span class="emphasis"><em>várható</em></span> hasznossági értékű beavatkozásokat, akkor sem vádolható hanyagsággal, ha ezeknek a beavatkozásoknak katasztrofálisak a <span class="emphasis"><em>tényleges</em></span> következményei a páciensnél. A kérdés ezek után a következő: „Kinek a hibája, ha a diagnózis nem plauzíbilis?” Mindeddig a bíróságok úgy tartották, hogy az orvosi szakértői rendszerek ugyanazt a szerepet töltik be, mint az orvosi tankönyvek és kézikönyvek: az orvosoknak felelőssége, hogy megértsék a döntések indoklását, és saját megítélésük alapján kell határozniuk, hogy elfogadják-e a rendszer javaslatát. Tehát ha az orvosi szakértői rendszereket ágensekként tervezzük, akkor cselekvéseiket nem úgy kell tekinteni, mint ami közvetlenül kihat a páciensre, hanem mint ami befolyásolja az orvos viselkedését. Ha a szakértői rendszerek megbízhatóbban pontosabbak lesznek, mint a diagnózisokat felállító emberek, akkor az orvosok akár jogilag is felelősek lehetnek, ha <span class="emphasis"><em>nem</em></span> használják fel a rendszer javaslatait. Gawande (Gawande, 2002) ezt a feltételezést térképezi fel.</p><p>Hasonló kérdések kezdenek megjelenni az interneten használt intelligens ágensekkel kapcsolatban. Már elértek egy kis haladást kényszerfeltételek beépítésével az ágensekbe, hogy például ne okozhassanak károkat más felhasználók állományaiban (Weld és Etzioni, 1994). Amikor pénz is gazdát cserél, a probléma már nagyobb. Amikor egy pénzügyi tranzakció során egy intelligens ágens „valaki nevében” jár el, felelős-e ez a személy a keletkező adósságokért? Lehetségessé válhat-e, hogy egy intelligens ágensnek pénzügyi kintlévősége legyen, és a saját nevében eljárva elektronikus tranzakciókat hajtson végre? Mindeddig nem látszanak világosnak ezek a kérdések. Tudomásunk szerint eddig egy program sem kapta meg azt a jogi státust, hogy individuumként pénzügyi tranzakciókat hajthasson végre, és jelenleg ez nem is látszik indokoltnak. A valódi autópályákon sem tekintik a közlekedési szabályok betartatásakor „vezetőnek” a programokat. A kaliforniai jogban legalábbis semmilyen jogi szankció nincsen, amely megakadályozhatná, hogy egy automata jármű túllépje a sebességhatárt, noha baleset esetén felelőssé tehető a jármű vezérlőmechanizmusának tervezője. Csakúgy, mint az emberi megtermékenyítési technológia esetén, a jog még nem vette fel a lépést az új fejleményekkel.</p><p><span class="emphasis"><em>A mesterséges intelligencia sikere az emberi faj végét jelentheti. </em></span>Gyakorlatilag bármely technológiában benne rejlik a lehetőség, hogy kárt okozzon rossz kezekben, de a mesterséges intelligencia és a robotika esetében ezek a rossz kezek akár magához a technológiához is tartozhatnak. Számtalan sci-fi szól figyelmeztető jelként arról, hogy robotok vagy robot-ember kiborgok ámokfutást rendeznek. Marry Shelley <span class="emphasis"><em>Frankenstein, or the Modern Prometheus </em></span>(Shelley, 1818)<sup>[<a id="id798009" href="#ftn.id798009" class="footnote">286</a>]</sup> c. műve és Karel Capek <span class="emphasis"><em>R.U.R. </em></span>c. drámája, amelyben a robotok meghódítják a világot, korai példái az ilyen történeteknek. Mozifilmek is szólnak erről: a <span class="emphasis"><em>The Terminator</em></span> (1984) a robotok-leigázzák-a-világot kliséit az időutazással ötvözi, a <span class="emphasis"><em>The Matrix</em></span> (1999) pedig ugyanezt az agyak-a-tartályban-nal kombinálja.</p><p>Úgy tűnik, legtöbb esetben a robotok azért főszereplői olyan sok világ-leigázása történetnek, mert az ismeretlent jelképezik, csakúgy, mint a korábbi mesék boszorkányai és szellemei. Jelentenek-e a boszorkányoknál és a szellemeknél komolyabb veszélyt? Valószínűleg nem: ha a robotokat megfelelően, azaz olyan ágensekként tervezik, amelyek a gazdáik céljait teljesítik, akkor a jelenlegi tervezés lépésenkénti előrehaladásából származó robotok szolgálni fognak, nem pedig leigázni. Az emberek azért használják agresszíven az intelligenciájukat, mert a természetes kiválasztódás miatt velük született agresszivitással rendelkeznek. De a gépek, amiket magunk építünk, nem születnek agresszívnak, hacsak nem döntünk úgy, hogy ilyennek építjük őket. Másrészt viszont lehetséges, hogy a számítógépek meghódítanak minket abban az értelemben, hogy szolgálatukkal elengedhetetlenné válnak, csakúgy, mint az autók meghódították (ebben az értelemben) az iparosodott világot. Egy forgatókönyv részletesebb tanulmányozást érdemel. I. J. Good (Good, 1965) írta ezt:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p>Definiáljuk az ultraintelligens gépet olyan gépként, amely messze túlhaladja a lehető legintelligensebb ember intellektuális tevékenységét is. Mivel a gépek tervezése az intellektuális tevékenységek egyike, egy ultraintelligens gép még jobb gépeket tud tervezni; nem kérdés, hogy egy „intelligenciarobbanás” történne, ami messze lehagyja az emberi intelligenciát. Az ultraintelligens gép így egyben az emberiség utolsó szükséges felfedezése, feltéve persze, hogy a gép elég engedelmes, és elmondja, hogyan tarthatjuk ellenőrzésünk alatt.</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">I. J. Good</span></td></tr></table></div><p>Az „intelligenciarobbanás”-t <span class="strong"><strong>technológiai szingularitás</strong></span>nak (<span class="strong"><strong>technological singularity</strong></span>) is nevezte a matematika-professzor és sci-fi író Vernor Vinge, aki így fogalmaz (Vinge, 1993): „Harminc éven belül rendelkezni fogunk a technológiai eszközökkel egy emberfeletti intelligencia létrehozására. Röviddel ezután befejeződik az ember korszaka.” Good és Vinge (és még sokan mások) jól figyelik meg, hogy a technológiai fejlődés jelenleg az exponenciális görbe szerint nő (gondoljunk csak a Moore-törvényre). Azonban ebből csak egy előreugrással lehet arra következtetni, hogy ez a görbe így fog folytatódni a közel végtelen növekedés szingularitásához. Eddig minden más technológia egy S alakú görbét követett, ahol az exponenciális növekedés végül lecsengett.</p><p>A bekövetkező szingularitásról író Vinge-et rémíti ez a lehetőség, de más számítógéptudósok és futuristák örömmel várják. Hans Moravec a <span class="emphasis"><em>Robot: Mere Machine to Transcendent Mind </em></span>c. írásában azt jósolja, hogy a robotok ötven éven belül elérik az emberi intelligenciát, majd pedig meghaladják azt. Ezt írja:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td valign="top"> </td><td valign="top"><p>Egész gyorsan kiszorítanak minket a létezésből. Másokkal szemben engem ez a lehetőség nem tölt el aggodalommal, én ezeket a jövőbeli gépeket a leszármazottainknak, „elmebeli gyermekeink”-nek tartom, akiket képünkre és hasonlatosságunkra építettünk, önmagunkként egy jóval nagyobb képességű alakban. A korábbi generációk biológiai gyermekeihez hasonlóan az emberiség hosszú távú jövőről alkotott legjobb reményét testesítik meg. Belső kötelességünk minden előnyt megadni nekik és ellépni útjukból, ha már többet nem tudunk segíteni.</p></td><td valign="top"> </td></tr><tr><td valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">(Moravec, 2000)</span></td></tr></table></div><p>A <span class="emphasis"><em>The Age of Spiritual Machines </em></span>(Kurzweil, 2000) c. művében Ray Kurzweil azt jósolja, hogy 2000-re már „erős trend lesz összekapcsolni az emberi gondolkodást az eredetileg az emberi faj teremtette gépek világával”. Még egy új szó is van: <span class="strong"><strong>transzhumanizmus</strong></span> (<span class="strong"><strong>transh</strong></span><span class="strong"><strong>umanism</strong></span>), amely az ezt a jövőt váró aktív társadalmi mozgalmat jelöli. Elegendő csak annyit mondani, hogy az ilyen kérdések kihívást jelentenek a legtöbb mai erkölcsi gondolkodónak, akik az emberi élet és az emberi faj megőrzését jó dolognak tartják.</p><p>Gondoljunk bele végül a robotok nézőpontjába. Ha a robotok tudatossá válnak, akkor immorális lehet puszta „gépként” kezelni őket (például darabokra szedni). A robotoknak maguknak is morálisan kell cselekedniük: beléjük kell programozni a jó és a rossz elméletét. A sci-fi írók, kezdve Isaac Asimovval (Asimov, 1942), már el is kezdtek foglalkozni a robotjogok és robotfelelősségek kérdéseivel. A jól ismert – <span class="emphasis"><em>Mesterséges intelligencia</em></span> (A.I<span class="emphasis"><em>.</em></span>)<span class="emphasis"><em> </em></span>(Spielberg, 2001) c. mozifilm Brian Aldiss történetén alapul, amelyben egy intelligens robot, akit arra programoztak, hogy embernek képzelje magát, képtelen feldolgozni, hogy nem kell tulajdonos-anyjának. A történet (és persze a film) a robotok polgárjogi mozgalmának megalapozottságáról győzhet meg egyeseket.</p><div class="footnotes"><br/><hr/><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id797871" href="#id797871" class="para">283</a>] </sup> Az Egyesült Államok eddigi legsúlyosabb atombalesetének helyszíne Pennsylvania államban. Az 1979-ben történt baleset ugyan rendkívül megrázta az amerikai közvéleményt, de káros egészségügyi következményeit tekintve nem mérhető a csernobili esethez. (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id797964" href="#id797964" class="para">284</a>] </sup> Lásd „Eavesdropping on Europe”, <span class="emphasis"><em>Wired</em></span> hírmagazin, 9/30/1998 és a hivatkozott EU-jelentéseket.</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id797973" href="#id797973" class="para">285</a>] </sup> Amerikai jogász és jogi közíró, a múlt század első felében a Legfelsőbb Bíróság tagja. (<span class="emphasis"><em>A ford.</em></span>)</p></div><div class="footnote"><p class="footnote text"><sup>[<a id="ftn.id798009" href="#id798009" class="para">286</a>] </sup> Charles Babbage-ra is hatással volt fiatalemberként a <span class="emphasis"><em>Frankeinstein</em></span> olvasása.</p></div></div></div></body></html>
